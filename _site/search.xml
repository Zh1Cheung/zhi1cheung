<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title>单源最短路径总结</title>
      <url>/algorithms/2018/02/14/GraphSummary/</url>
      <content type="text">在早些时候学习最短路径算法时，心里就一直有个疑问，如果一个图仅仅是存在负权，但不构成负权回路，又该如何？我们一个一个看。

单源最短路径总结
</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Graph </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>﻿排序总结</title>
      <url>/algorithms/2018/02/11/SortSummary/</url>
      <content type="text">我并未把前面几篇文章所涉及的所有排序算法都列入表格，因为在实际生活中，我们所用的无外乎上面的5种排序，所以我们只需关注这5种算法足矣。

排序总结

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Sort </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>基数排序</title>
      <url>/algorithms/2018/02/06/Sort4/</url>
      <content type="text">基数排序与前面所述的排序方法都不同，它不需要比较关键字的大小。

基数排序

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Sort </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>数据结构</title>
      <url>/algorithms/2018/02/04/data-structure/</url>
      <content type="text">﻿1. 基础

　　数据结构：是相符之间存在一种或多种特定关系到数据元素的集合。
1.1 逻辑结构： 数据对象中数据元素之间的相互关系

　　1.1.1 集合结构：集合结构的数据元素除同属于一个集合外，它们之间没有其他的关系；

　　1.1.2 线性结构：数据元素之间是一一对应的；

　　 1.1.3 树形结构：数据元素之间存在一种一对多多层次关系；

　　 1.1.4 图形结构：数据元素是多对多多关系；

1.2 物理结构：数据的逻辑结构在计算机中的存储形势

　　 1.2.1 顺序存储结构：把数据元素存放在地址连续的存储单元里，其逻辑关系和物理关系一致（数组）；

　　 1.2.2 链式存储结构：数据元素存放在任意的存储单元里，这组存储单元可以联系也可不连续；

1.3 抽象数据类型

　　数据类型：一组性质相同的值的集合及定义在此集合上的一些操作的总称

　　类型就是用来说明变量或表达式的取值范围和所能进行的操作

　　  抽象：取出事物具有普遍性的本质；
1.3.1 抽象数据类型：指一个数学模型及定义在该模型上的一组操作；

  算法


　　　是解决特定问题求解步骤等描述，在计算机中表现为指令等有限序列，并且每条指令表示一个或多个操作；

　　特性：输入输出，

　　　　　有穷性：执行有限步骤之后，自动结束而不会出现无限循环，并且每一个步骤在可接受的时间内完成；

　　　　　确定性：算法的每一步骤具有确定的含义，不会出现二意性；

　　　　　可行性：算法的每一步都必须可行，每一步都能够通过执行有限次数完成；

　　　　　正确性，可读性，      健壮性：对不合法的输入做出相关处理；

　　　　　时间效率高，存储量低；

　　2.7 算法效率的度量方法

　　　　事前分析估算方法：在计算机程序编制前，依据统计方法对算法进行估算；

　　　　函数的渐进增长：给定两个函数f(n)和g(n)，如果存在一个整数N，使得对于n&amp;gt;N，f(n)和总比g(n)大，那么，我们说f(n)的增长渐进快于g(n)

　　2.8 算法时间复杂度

　　　　：语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n变化的情况并确定T(n)的数量级。算法的时间亮度，记作：T(n)＝O(f(n))。它表示随着问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐进时间复杂度，简称时间复杂度。集中f(n)是问题规模n的某个函数。

　　　　O(1)  &amp;lt; O(lgn)  &amp;lt;  O(n) &amp;lt;  O(nlgn)  &amp;lt; O(n2)&amp;lt; O(n3)&amp;lt;O(2n)  &amp;lt; O(n!) &amp;lt; O(nn)

　　2.12 算法的空间复杂度

　　　　S(n)＝O(f(n))：n为问题规模，f(n)为语句关于n所占存储空间的函数；


  线性表


　　线性表元素个数定义为线性表长度，n＝0，为空表；

　　线性表的顺序存储结构：用一段地址连续的存储单元依次存储线性表的数据元素（一维数组）

　　3.4.3 数组长度：存储空间的长度；   线性表的长度：线性表中数据元素的个数；

　　存储器中的每个单元都有自己的编号，称为地址；

　　Loc(ai)＝Loc(a1) ＋(i－1)＊c     时间复杂度：存取时间性能O(1) －－－随机存储结构

　　3.5.4 优点：无须为逻辑关系增加额外存储空间，可以快速存取表中任意位置；

　　　　   缺点：插入删除需移动大量元素，线性表长度变化难以确定存储空间，存储空间“碎片”

　　3.6 线性表的链式存储结构

　　一个节点：数据（数据域）＋指针（指针域）

　　单链表：每个结点只包含一个指针域

　　头指针：链表中第一个结点的存储位置；   线性链表的最后一个结点指针为空（NULL）

　　头结点：单链表的第一个结点前设的一个结点；数据域一般无意义（可存储链表长度）

　　头指针不为空；头结点不一定是链表必须要素

　　3.8.1 单链表的插入,将s插入到p后: s-&amp;gt;next=p-&amp;gt;next, p-&amp;gt;next=s(赋值顺序不能调换，否则出错)

　　3.9 单链表整表创建：r-&amp;gt;next＝p(将新建p结点放在r后面)，r＝p(p为最后结点赋给r)，p-&amp;gt;＝NULL

　　3.11 单链表结构优点：插入删除时间O(1)，不需要预分配；

　　确定：查找O(n)

　　3.12 静态链表：用数组描述的链表；

　　优点：插入删除只需修改游标；

　　缺点：表长依然难以确定，失去顺序存储结构的随机性；

　　3.13 循环链表：将单链表中终端结点的指针端由空指针改为头指针；

　　3.14 双向链表：在单链表的每个节点中，再设置一个指向其前驱结点的指针域；(空间换时间)

　　　　插入时需要保证p-&amp;gt;next的赋值在四个操作中最后进行

4 栈

　　限定仅在表尾进行插入和删除操作的线性表；

　　后进先出，操作在栈顶进行，后进先出（LIFO结构）；

　　进栈，压栈：插入操作

　　出栈：删除操作

　　4.6.1 栈的链式存储结构，链栈；

　　链栈：空间大小可不确定 ；      顺序栈：空间大小确定

　　栈的作用：有效解决递归问题

　　递归：直接调用自己或通过一系列的语句间接调用自己的函数；

　　迭代：循环结构；  递归：选择结构；

　　后缀表达式：逆波兰；

　　中缀表达式：标准四则运算表达式；

　　4.9.3 中缀转后缀：从左到右遍历中缀表达式每个数字和符号，若是数字就输出，即成为后缀表达式的一部分；若是符号，则判断其与栈顶符号的优先级，是右括号或优先级低于栈顶符号则栈顶元素依次出栈并输出，并将当前符号进栈，一直到最终输出后缀表达式为止；

　　4.10 队列：允许在一段进行插入操作，在另一端进行删除操作的线性表；

　　　　first in first out(FIFO)

　　队尾：允许插入；  队头：允许删除；

　　队列顺序存储不足，删除队头，需要移动这个数组O(n);

　　front指向队头元素，rear指向队尾元素；

　　front ＝ rear 空队列

　　循环队列：头尾相接；设置flag，以区别front ＝ rear时为空还是满；

　　4.13 队列等链式存储结构

　　就是线性表的单链表，但只能尾进头出，链队列；

　　空队列：front和rear指向头结点；


  串


　　是由零个或多个组成的有限序列，字符串；

　　空格串：只包含空格的串；  空串：零个字符串；

　  模式匹配算法，克努特－莫里斯－普拉斯算法（KMP模式）

　　　　http://blog.csdn.net/joylnwang/article/details/6778316


  树


　　n(n≥0)个结点的有限集。n＝0时称为空树。在任意一颗非空树中：有且仅有一个特定的称为根(Root)的结点；当n&amp;gt;1时，其余结点可分为m(m&amp;gt;0)个互不相交的有限集T1,T2…Tn，其中每一个集合本身又是一颗树，并且称为根的子树(SubTree)。

　　结点拥有的子树的数称为结点的度(Degree)。度为0度结点称为叶结点(Leaf)或终端结点；度不为0的结点称为非终端结点或分支结点，也称为内部结点。树的度是树内各结点的度的最大值。

　　结点子树的根称为该结点的孩子(Child)，该结点称为孩子的双亲(Parent)。同一个双亲的孩子之间互称兄弟(Sibling)。结点的祖先是从根到该结点所经分支上的所有结点。

　　结点的层次从根开始定义，根为第一层，根的孩子为第二层。树中结点的最大层次称为树的深度(Deoth)或高度。

　　如果将树中结点的各子树看成从左至右是有次序的，不能互换的，则称该树为有序树，否则称为无序树。森林是棵互不相交的树的集合。

　　6.5 二叉树(Binary Tree)：n(n≥0)个结点的有限集合，该集合或者为空集，或者由一个根结点和两棵互不相交的，分别为根结点的左子树和右子树的二叉树组成。

　　特点：每个节结点最多两棵子树，即度不大于2，左右子树次序一定；

　　五种基本形态：空二叉树，只有一个根结点，根结点只有左子树，根结点只有右子树，根结点既有左子树又有右子树；

　　6.5.2 斜树：所有结点都只有左子树为左斜树，只有右子树为右斜树，这两种统称斜树；

　　满二叉树：所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上；

　　完全二叉树：一个有n个结点的二叉树按层序编号，如果编号为i的结点与同样深度的满二叉树中编号为i的结点在二叉树中位置完全相同，则这棵二叉树称为完全二叉树；

　　满二叉树一定是完全二叉树，但完全二叉树不一定是满二叉树；

　　完全二叉树特点：叶子结点只能出现在最下两层；最下层的叶子一定集中在左部连续；倒数二层若有叶子结点，一定都在右部连续位置；当结点度为1，则该结点只有左孩子；同样结点树的二叉树，完全二叉树的深度最小；

　　二叉树性质

　　　　1：在二叉树的第i层上至多有2^(i－1)个结点(i≧1)；

　　　　2：深度为k的二叉树至多有(2^k)－1个结点(k≧1)；

　　　　3：任意一棵二叉树T，如果终端结点数为n0，度为2的结点数为n2，则n0=n2+1；

　　　　4：具有n个结点的完全二叉树深度为「㏒2(n) 」+1（「x」表示不大于x的最大整数）

　　　　5：如果对一棵有n个结点的完全二叉树的结点按层序编号（从第1层到第「㏒2(n) 」+1层），对任意一结点有：　　

　　　　　　如果i＝1，则结点i是二叉树的根，无双亲；i≧1，则其双亲是结点「i／2」；

　　　　　　如果2&amp;gt;n，则结点i无左孩子(结点i为叶子结点)；否则其左孩子是结点2i；

　　　　　　如果2*i&amp;gt;n，则结点i无右孩子；否则其右孩子是结点2*i＋1；

　　6.7 二叉树的存储结构

　　二叉链表：链表中结点设计一个数据域和两个指针域（表示两个孩子）

　　6.8 二叉树都遍历：

　　　　从根结点出发，按照某种次序依次访问二叉树中所有结点，使得每个节点被访问一次且仅被访问一次；

　　　　前序遍历：若二叉树为空，则空操作返回，否则先访问根结点，然后前序遍历左子树，再前序遍历右子树；

　　　　中序遍历：若树为空，则空操作返回，否则从根结点开始（并不是先访问根结点），中序遍历根结点左子树，然后访问根结点，最后中序遍历右子树；

　　　后序遍历：若树为空，则空操作返回，否则从左到右先叶子后结点到方式遍历访问左右子树，最后访问根结点；

　　　　层序遍历：若树为空，则空操作返回，否则从树第一层，也就是根结点开始访问，从上而下逐层遍历，同一层从左到右顺序访问；

　　6.8.6 二叉树遍历性质

　　　　已知前序遍历序列和中序遍历序列可以唯一确定一棵二叉树；

　　　　已知后序遍历序列和中序遍历序列可以唯一确定一棵二叉树；

　　6.9 二叉树的建立

　　　　扩展二叉树：将二叉树的每个结点的空指针引出一个虚结点，其值为一特定值；

　　6.10 线索二叉树

　　　　指向前驱和后继的指针称为线索，加上线索的二叉链表称为线索链表，相应的二叉树称为线索二叉树；

　　　　线索化：对二叉树以某种次序遍历使其变为线索二叉树的过程；

　　6.12 赫夫曼编码

　　　　带权路径长度WPL最小的二叉树称作赫夫曼树；


  图


　　由顶点的有穷非空集合和顶点之间边的集合组成，通常表示为：G(V,E)，其中，G表示一个图，V是图G中顶点的集合，E是图G中边的集合；

　　图中数据元素称为顶点；

　　图结构中不允许没有顶点；

　　任意两点之间都可能有关系，顶点之间的逻辑关系用边来表示，边集可以为空；

7.2.1 各种图定义

　　无向边：顶点V1和Vi之间的边没有方向，则称这条边为无向边（Edge），用无序偶对（Vi Vj）来表示；

　　如果图中任意两个顶点之间的边都是无向边，则称该图为无向图；

　　有向边：若顶点从V1到Vi的边有方向，则称这条边有方向，也称为弧（Arc），用有序偶

表示，Vi称为弧尾（Tail），Vj为弧头（Head）；

　　若图中任意两个顶点之间的边都是有向边，则称该图为有向图；如：顶点A到D的有向边，A是弧尾，D是弧头，&amp;lt;A,D&amp;gt;表示弧；

　　简单图：若不存在顶点到其自身的边且同一条边不重复出现；

　　无向完全图：在无向图中任意两个顶点都存在边；含有n个顶点的完全图有n*(n-1)/2条边；

　　有向完全图：有向图中任意两个顶点之间都存在方向互为相反的两天弧，有n*(n-1)条边；

　　有很少条边或弧度图称为稀疏图，反之称为稠密图；

　　图的边或弧相关的树叫做权（Weight），带权的图称为网（Network）；

　　假设图G=(V,{E})，图G'=(V',{E'})，如果V'⊆V且E'⊆E,则称G'为G的子图（Subgraph）；

　　对于无向图G=(V,{E})，如果边(v,v')∈E，则称顶点v和v'互为邻接点，即v和v'相领接边(v,v')依附于顶点v和v'，顶点v的度是和v相关联的边的数目，记为TD(v)；

　　边数就是各顶点度数和道一半：e＝ 0.5* **∑**_TD_(vi)  (i=1,2,3...n)

　　对于有向图G=(V,{E})，以顶点v为头的弧度数目称为v的入度，记为ID(v)，以v为尾的弧的数目称为v的出度，记为OD(v);顶点v的度为TD(v)=ID(v)+OD(v);

　　无向图中从顶点v到顶点v'的路径是一个顶点序列；有向图的路径也是有向的；

　　路径的长度是路径上的边或弧度数目；

　　第一个顶点到最后一个顶点相同的路径称为换或回路，序列中不重复出现的路径称为简单路径；

7.2.3 连通图

　　无向图中，从顶点v到v‘有路径则称为v和v’是连通的；如果对于图中任意两点都是连通的，则称图是连通图；

　　无向图中的极大连通子图称为连通分量；

　　　　连通分量条件：子图／子图连通／连通子图含有极大顶点树／具有极大顶点数的连通子图包含依附于这些顶点的所有边；

　　在有向图G中，如果每一对v，v‘∈V，v≠v’，从v到v‘和从v’到v都存在路径，则称G是强连通图；有向图中的极大强连通子图称作有向图的强连通分量；

　　一个连通图的生成树是一个极小的连通子图，它含有图中全部的n个顶点，但只有足以构成一棵树的n－1条边；

　　如果一个有向图恰有一个顶点的入度为0，其余顶点的入度均为1，则是一棵有向树；

　　一个有向图的生成森林由若干棵有向树组成，含有图中全部顶点，但只有足以构成若干棵不相交的有向树的弧；

7.4 图的存储结构

　　7.4.1 邻接矩阵：一个一维数组存储图中顶点信息，一个二维数组存储图中的边或弧度信息；

　　　　二维数组就是矩阵形式存储，v\[i\]\[j\]表示顶点i到j的边或弧；

　　　　n个顶点和e条边的无向网图创建时间复杂度O(n*n+n+e);

　　7.4.2 邻接表：数组与链表相结合的存储方式

　　　　顶点右一位数组存储，每个数据元素存储指向第一个领接点的指针，每个顶点的所有领接点构成一个线性表；

　　　　有向图的逆邻接表：对每个顶点vi建立一个链接为vi为弧头的表；

　　7.4.3 十字链表

　　　　将邻接表和你邻接表结合起来；

　　　　结点存储数据／入边表头指针／出边表头指针；

　　7.4.4 邻接多重表

　　7.4.5 边集数组

　　　　由两个一维数组构成，一个是存储顶点的信息；另一个存储边的信息，这个边数组每个数据元素由一条边的起点下表，终点下表和权组成；

7.5 图的遍历

　　从图中某一顶点出发遍历图中其余顶点，且每个顶点仅被访问一次，称为图的遍历；

　　深度优先遍历：从某顶点v出发，访问该顶点，然后从v的未被访问邻接点出发深度优先遍历图，直到图中所有和v有路径相同的顶点都被访问；

　　7.5.2 广度优先遍历

　　　　与深度优先遍历时间复杂度相同；（类似树的层序遍历）

7.6 最小生成树

　　构造连通网的最小代价生成树称为最小生成树；

　　7.6.1 普里姆(Prim)算法

　　　　时间复杂度：O(n*n);

　　7.6.2 克鲁斯卡尔(Kruskal)算法

　　　　时间复杂度O(e*log e)

7.7 最短路径

　　迪杰斯特拉算法：时间复杂度O(n*n);

　　弗洛伊德算法：时间复杂度O(n\*n\*n);

7.8 拓扑排序

　　AOV网：在一个表示工程的有向图中，用顶点表示活动，用弧表示活动间的优先关系；

　　拓扑序列：有向图G，满足从顶点vi到vj有一条路径，则在顶点序列中顶点vi必在vj之前；

　　拓扑排序：对一个有向图构造拓扑序列对过程；

　　　　时间复杂度：O(n+e)

　　AOE网：在一个表示工程的带权有向图中，用顶点表示事件，用有向边表示活动，用边上的权值表示活动的持续时间，

7.9 关键路径：

　　从源点到汇点具有最大路径；

8. 查找

　　根据给定某个值，在查找表中确定一个其关键字等于给定值的数据元素(或记录)；

　　查找表：由同一类型的数据元素构成的集合；

　　关键字：数据元素中某个数据项的值，又称键值；

　　主关键字：此关键字可以唯一表示一条记录；

　　数据项对应数据码；

　　查找：根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素（或记录）；

　　静态查找表：只做查找操作的查找表；

　　动态查找表：在查找过程中同时插入不存在的数据元素，或者从查找表中删除已经存在的某个数据元素

8.3 顺序表查找

　　顺序查找／线性查找：从表中第一个（或最后一个）记录开始，逐个进行记录的关键字和给定值比较，若相等则查找成功，直到最后一个（或第一个）记录，不等则查找不成功；

顺序查找优化：将给定值赋予a\[0\]，从尾部遍历，循环条件为是否等于关键字，省去判断越界环节；

8.4 有序表查找

　　二分查找／折半查找：在有序表中，取中间记录作为比较对象，若给定值与关键字相等则成功，小于则在左半区查找，大于在右半区查找，直到成功或查找所有区域无记录而查找失败（前提为线性表中记录必须是关键码有序，通常从小到大，且为顺序结构）；

　　　　时间复杂度O(log n)；

　　插值查找：根据要查找的关键字key与查找表中最大最小记录的关键字比较后查找，将二分查找的mid设为mid = low + (key - a\[low\])/(a\[high\] - a\[low\]) * (high - low)

　　斐波那契查找：利用斐波那契函数给mid赋值，mid=low+F\[k-1\]-1；

　　　　时间复杂度O(log n);

8.5 线性索引查找

　　索引就是把一个关键字与它对应的记录相关联的过程；

　　线性索引：将索引项集合组织为线性结构，也称索引表；

　　8.5.1稠密索引

　　　　在线性索引中，将数据集中的每个记录对应一个索引项；

　　　　索引项一定是按照关键码有序排列；

　　8.5.2分块索引

　　　　分块有序，是把数据集的记录分成若干块，并且这些快需要满足，块内无序，块间有序；

　　　　块间有序：要求第二块所有记录关键字均大于第一块中所有记录的关键字；

　　　　最佳分块索引情况为块m＝√￣n（n为记录数），此时平均查找长度L＝（√￣n）＋1；

　　8.5.3倒叙索引

　　　　记录号表存储具有相同次关键字的所有记录的记录号（可以是指向记录的指针或者是该记录的主关键字），由属性值来确定记录的位置；

8.6 二叉排序树

　　二叉查找树／二叉排序树：

　　　　　　　　若它的左子树不空，则左子树上所有结点的值均小于它的根结构的值，

　　　　　　　　若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值，

　　　　　　　　它的左右子树也分别为二叉排序树；

　　二叉排序树查找：利用递归在二叉链表中递归查找；

　　二叉排序树插入操作：利用查找函数将key插入到最终查找到合适结点到子树上；

　　二叉排序树构建：利用插入函数构建（根结点，将之后元素与结点对比，小的在左树中去对比，大的在右树中去对比，直到结点没有孩子，则插入）；

　　二叉排序树删除：找到删除的结点的直接前驱，用该前驱替换删除的结点；

　　二叉排序树以链接的方式存储

8.7 平衡二叉树

　　－－是一种二插排序树，其中每一个节点的左子树和右子树高度差至多等于1；

　　平衡因子：左子树与右子树深度差值；

　　最小不平衡子树：距离插入节点最近的，且平衡因子的绝对值大于1的结点为根的子树；

8.8 多路查找树（B树）

　　每一个结点孩子树可以多于两个，且每一个结点处可以存储多个元素；

　　2-3树：

　　　　每个结点有两个2个孩子（2结点）或3个孩子（3结点）；

　　　　一个2结点包含一个元素和两个孩子（或没有孩子）；

　　　　一个3结点包含一小一大两个元素和3个孩子（或没有孩子）；

　　　　所有叶子在同一层次上；

　　2-3-4树：

　　　　2-3树的扩展，包括4结点；

　　　　一个4结点包括小中大3个元素和4个孩子（或没有孩子）；

　　B树（B－tree）：一种平衡的多路查找树，结点最大的孩子数目称为B树的结；（2-3树是3阶B树）

　　　　如果根结点不是叶结点，则至少有两棵子树；

8.9 散列查找

　　散列技术：在记录的存储位置和它的关键字之间建立一个确定的对应关系f，使得每个关键字k对应一个存储位置；散列函数（哈西函数）

　　K1≠K2，但f（K1）＝f（K2），此时称为冲突，K1和K2称为这个散列函数的同义词；

8.10 散列函数的构造方法

　　直接定值；数字分析法；平方取中；折叠法；除留余数法；

8.11 处理散列冲突

　　开放定值法：一旦发生冲突，就去寻找下一个空的散列地址；

　　再散列函数法：发生冲突，更换散列函数进行计算；

　　链地址法：发生冲突，在当前位置给单链表增加结点；

　　公共溢出法：给发生冲突的关键字重新建立一个溢出表；

8.12 散列表查找

9. 排序

　　似的序列成为一个按关键字有序的序列；

　　排序稳定：Ki＝Kj，且排序前Ri领先于Rj，排序后任然领先；

　　排序不稳定：Ki＝Kj，且排序前Ri领先于Rj，排序后Rj领先Ri；

　　内排序：排序过程待排序所有记录放置在内存中；

　　外排序：整个排序过程需要在内外存之间切换；

　　性能影响：

　　　　1 时间性能：尽可能少的关键字比较次数和尽可能少的纪录移动次数；

　　　　2 辅助空间：存放待排序占用空间加上执行算法所需要其他存储空间；

　　　　3 复杂性： 算法本身复杂度，不止时间；

　　9.3 冒泡：

　　　　时间：O（nˇ2）；

　　9.4 简单排序：

　　　　通过n－i次关键字比较，从n－i＋1个记录中选出关键字最小的值，并和第i个交换；

　　　　时间：O（nˇ2）；

　　　　略优于冒泡（每次只交换一个值）；

　　9.5 直接插入：

　　　　将一个记录插入到已排序的序表中；

　　　　时间：O（nˇ2）；

　　　　略优于冒泡（比较次数少）；

　　9.6 希尔排序：

　　　　基本有序：小的关键字基本在前面，大的基本在后面，不大不小的基本在中间；

　　　　时间：O（nˇ(2/3)）；

　　9.7 堆排序：

　　　　堆：完全二叉树；

　　　　大顶堆：每个结点堆值都大于或等于其左右孩子结点的值；

　　　　小顶堆：每个结点堆值都小于或等于其左右孩子结点的值；

　　　　堆排序（大顶堆）：将待排序序列构造一个大顶堆；最大值此时在根结点，移走根结点，剩余n－1个结点从新构造一个堆，得到次小值，如此反复得到一个有序序列；



</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> data structure </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>归并排序</title>
      <url>/algorithms/2018/02/04/Sort3/</url>
      <content type="text">

归并排序

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Sort </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>直接插入排序，二分查找插入排序，希尔排序</title>
      <url>/algorithms/2018/02/04/Sort1/</url>
      <content type="text">直接插入排序，二分查找插入排序，希尔排序

直接插入排序（Insertion Sort）可以说是排序里最简单的了。为简化问题，我们下面只讨论升序排序。

二分查找插入排序 因为在一个有序序列中查找一个插入位置，所以可使用二分查找，减少元素比较次数提高效率。

希尔排序，也称递减增量排序算法，以其设计者希尔（Donald Shell）的名字命名，该算法由1959年公布。
</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Sort </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>SPFA算法</title>
      <url>/algorithms/2018/02/04/SPFA/</url>
      <content type="text">SPFA（Shortest Path Faster Algorithm）算法，是西南交通大学段凡丁于1994年发表的，其在Bellman-ford算法的基础上加上一个队列优化，减少了冗余的松弛操作，是一种高效的最短路算法。

SPFA算法

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Graph </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>堆排序</title>
      <url>/algorithms/2018/02/03/Sort2/</url>
      <content type="text">堆排序

堆排序是利用堆的性质进行的一种选择排序。下面先讨论一下堆。

堆实际上是一棵完全二叉树，其满足性质：任何一结点大于等于或者小于等于其左右子树结点。

堆分为大顶堆和小顶堆，满足“任何一结点大于等于其左右子树结点”的称为大顶堆，满足“任何一结点小于等于其左右子树结点”的称为小顶堆。由上述性质可知：大顶堆的堆顶肯定是最大的，小顶堆的堆顶是最小的。

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Sort </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Bellman-Ford算法</title>
      <url>/algorithms/2018/02/01/Bellman-Ford/</url>
      <content type="text">Dijkstra算法是处理单源最短路径的有效算法，但它对存在负权回路的图就会失效。这时候，就需要使用其他的算法来应对这个问题，Bellman-Ford（中文名：贝尔曼-福特）算法就是其中一个。

Bellman-Ford算法
</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Graph </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>﻿﻿Sunday算法</title>
      <url>/algorithms/2018/01/27/Sunday/</url>
      <content type="text">Sunday算法是Daniel M.Sunday于1990年提出的字符串模式匹配。其效率在匹配随机的字符串时比其他匹配算法还要更快。Sunday算法的实现可比KMP，BM的实现容易太多。

﻿﻿Sunday算法

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> String </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>﻿Sparse Table算法</title>
      <url>/algorithms/2018/01/27/Sparse-Table/</url>
      <content type="text">找一个区间最值，最简单的直接比较，复杂度是$O(n)$，所以如果查找次数很少，用ST算法没有意义。ST算法的应用场景就是要对一个数串查询多次的情况。

Sparse Table算法

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> String </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>﻿﻿﻿﻿Prim算法</title>
      <url>/algorithms/2018/01/27/Prim/</url>
      <content type="text">假设要在n个城市之间通信联络网，则连通n个城市只需要n-1条线路。这时，自然会考虑这样一个问题，如何在最节省经费的前提下建立这个通信网。

﻿﻿﻿﻿Prim算法

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Graph </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>﻿﻿﻿Manacher算法</title>
      <url>/algorithms/2018/01/27/Manacher/</url>
      <content type="text">1975年，一个叫Manacher的人发明了一个算法，Manacher算法（中文名：马拉车算法），该算法可以把时间复杂度提升到$O(n)$。

Manacher算法

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> String </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>﻿﻿KMP算法：如何理解KMP</title>
      <url>/algorithms/2018/01/27/KMP/</url>
      <content type="text">给定一个主串（以 S 代替）和模式串（以 P 代替），要求找出 P 在 S 中出现的位置，此即串的模式匹配问题。

Knuth-Morris-Pratt 算法（简称 KMP）是解决这一问题的常用算法之一，这个算法是由高德纳（Donald Ervin Knuth）和沃恩·普拉特在1974年构思，同年詹姆斯·H·莫里斯也独立地设计出该算法，最终三人于1977年联合发表。

在继续下面的内容之前，有必要在这里介绍下两个概念：真前缀 和 真后缀。

﻿﻿KMP算法：如何理解KMP

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> String </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>﻿﻿Boyer-Moore算法</title>
      <url>/algorithms/2018/01/27/Boyer-Moore/</url>
      <content type="text">各种文本编辑器的”查找”功能（Ctrl+F），大多采用Boyer-Moore算法。Boyer-Moore算法不仅效率高，而且构思巧妙。1977年，德克萨斯大学的Robert S. Boyer教授和J Strother Moore教授发明了这种算法。

Boyer-Moore算法

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> String </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>﻿Dijkstra算法与Prim算法的区别</title>
      <url>/algorithms/2018/01/22/DijkstraPrim/</url>
      <content type="text">Dijkstra算法与Prim算法非常相似，甚至很多初学者觉得它们就是一样的。它们最直观的区别就是目的不同：前者求解最短路径，后者求解最小生成树。



对比上图，


  
    最短路径

    a-&amp;gt;b  @length = 2
a-&amp;gt;c  @length = 3

    
  
  
    最小生成树

    a-&amp;gt;b-&amp;gt;c  @sum = 4

    
  


结论：两者不一样！

好，最后让我们回归代码。

Dijkstra算法与Prim算法都有一个数组，不妨统一称为R[]，我们每次都是取R[]的最小值，接着更新R[]，再取其最小值，，，往复下去。而这两者的区别就发生在更新操作之中。


  
    最短路径

    for the weight of edge(u-&amp;gt;v)
    if R[v] &amp;gt; R[u] + weight
        R[v] = R[u] + weight

    
  
  
    最小生成树

    for the weight of edge(u-&amp;gt;v)
    if R[v] &amp;gt; weight
        R[v] = weight

    
  


其区别，从代码来看，显而易见。

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Graph </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>﻿BFS和DFS</title>
      <url>/algorithms/2018/01/22/BFS-DFS/</url>
      <content type="text">这两者“遍历”的序列到底有何差别？

那本篇文章就单纯来讲讲它们的区别和各自的应用，不会涉及任何代码。

广度优先搜索算法（Breadth-First-Search，缩写为BFS），是一种利用队列实现的搜索算法。简单来说，其搜索过程和“湖面丢进一块石头激起层层涟漪”类似。

深度优先搜索算法（Depth-First-Search，缩写为DFS），是一种利用递归实现的搜索算法。简单来说，其搜索过程和“不撞南墙不回头”类似。

BFS的重点在于队列，而DFS的重点在于递归。这是它们的本质区别。

举个典型例子，如下图，灰色代表墙壁，绿色代表起点，红色代表终点，规定每次只能走一步，且只能往下或右走。求一条绿色到红色的最短路径。



对于上面的问题，BFS和DFS都可以求出结果，它们的区别就是在复杂度上存在差异。我可以先告诉你，该题BFS是较佳算法。

BFS



如上图所示，从起点出发，对于每次出队列的点，都要遍历其四周的点。所以说BFS的搜索过程和“湖面丢进一块石头激起层层涟漪”很相似，此即“广度优先搜索算法”中“广度”的由来。

DFS



如上图所示，从起点出发，先把一个方向的点都遍历完才会改变方向……所以说，DFS的搜索过程和“不撞南墙不回头”很相似，此即“深度优先搜索算法”中“深度”的由来。

总结

现在，你不妨对照着图，再去看看你打印出的遍历序列，是不是一目了然呢？

最后我再说下它们的应用方向。

BFS常用于找单一的最短路线，它的特点是”搜到就是最优解”，而DFS用于找所有解的问题，它的空间效率高，而且找到的不一定是最优解，必须记录并完成整个搜索，故一般情况下，深搜需要非常高效的剪枝（剪枝的概念请百度）。
</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Graph </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>﻿BFPRT算法（TOP-K问题）</title>
      <url>/algorithms/2018/01/22/BFPRT/</url>
      <content type="text">在一堆数中求其前k大或前k小的问题，简称TOP-K问题。而目前解决TOP-K问题最有效的算法即是”BFPRT算法”，又称为”中位数的中位数算法”，该算法由Blum、Floyd、Pratt、Rivest、Tarjan提出，最坏时间复杂度为$O(n)$。

﻿BFPRT算法（TOP-K问题）

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Mass data processing </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Aho-Corasick 算法</title>
      <url>/algorithms/2018/01/22/Aho-Corasick/</url>
      <content type="text">Aho–Corasick算法（也称AC算法，AC自动机）是由Alfred V. Aho和Margaret J.Corasick 发明的字符串搜索算法，该算法在1975年产生于贝尔实验室，是著名的多模匹配算法之一。

Aho-Corasick 算法
</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Tree </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Machine Learning</title>
      <url>/ml/2017/10/30/Machine-Learning/</url>
      <content type="text">它是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域，它主要使用归纳、综合而不是演绎。

数学是基础
微积分
概率论和统计学
线性代数（矩阵，向量）
数值数学（数值分析，线性规划，凸优化理论，常见数值优化算法）
实分析和泛函的基础

《统计学习方法》 李航博士

机器学习

机器学习 机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。

从大量数据中找到规律和知识，然后用规律和知识做预测和决策。

监督学习

从给定的训练数据集中学习一个函数，当新数据到来时，可以根据这个函数预测结果。

Square判断一笔交易是否是欺诈，信用卡咋骗
Airbnb 预测用户网络平台上的违规操作
Airbnb 搜索引擎，搜索结果最大程度可能是用户感兴趣的租房
Airbnb 预测一个房租的最佳定价范围

线性回归
决策树

Aerosolve
Scikit-Learn python

无监督学习

从一个输入集里选择识别隐藏的有用的信息，比如从生物信息的DNA里找到负责同一个生物功能的DNA群，图像图形处理里的人脸识别。研究方法是聚类分析。


  数据处理与可视化：PCA，LDA，MDS
  聚类算法
  稀疏编码


增强学习

通过观察来学习应该如何的动作。

机器学习偏向数学问题推导，数据挖掘就是抽特征
不要沉迷于数学公式推导，理解如何运用数据
动手实现一些简单的算法，如感知机，k近邻，线性回归
找一个实际案例，从他的算法选择，特征参数选取调整，以及数据管道的建立等系统的学习一下

基本不会去实现这些基础算法，都有现成的开源工具

概率图模型（Probabilistic graphical model）
两个核心的机器学习模型：Latent Dirichlet Allocation（LDA） Probabilistic Matrix Factorization（PMF）
统计计算（Statistical computing）	
深度学习（Deep learning）
优化（optimization）
PAC学习理论（PAC Learning）
非参数贝叶斯统计（Non-parametric Bayesian statistics）

参考链接：http://www.zhihu.com/question/21714701

分类器


  Naive Bayes
  Linear Discriminant Analysis
  Logistic Regression
  Linear SVM
  Kernel SVM
  Adaboost
  Decision
  Neural network


数据挖掘

在知乎的描述中。数据挖掘是指从大量的数据中自动搜索隐藏于其中的有着特殊关系性的信息和知识的过程。

入门参考

Machine learning Andrew Ng 在 coursera公开课。最好能完成所有作业。课程讲义http://cs229.stanford.edu/materials.html

网易的andrew ng公开课， 这个也不错，年代久远一些。

julyedu 课程大纲

《机器学习基石》 https://www.coursera.org/course/ntumlone

《机器学习技法》 公开课

《机器学习实战》

《机器学习：实用案例解析》 本书比较全面系统地介绍了机器学习的方法和技术。全书案例既有分类问题，也有回归问题；既包含监督学习，也涵盖无监督学习。本书讨论的案例从分类讲到回归，然后讨论了聚类、降维、最优化问题等。这些案例包括分类：垃圾邮件识别，排序：智能收件箱，回归模型：预测网页访问量，正则化：文本回归，最优化：密码破解，无监督学习：构建股票市场指数，空间相似度：用投票记录对美国参议员聚类，推荐系统：给用户推荐R语言包，社交网络分析：在Twitter上感兴趣的人，模型比较：给你的问题找到最佳算法。各章对原理的叙述力求概念清晰、表达准确，突出理论联系实际，富有启发性，易于理解。在探索这些案例的过程中用到的基本工具就是R统计编程语言。

《Machine Learning》 Tom Mitchell 
Simon Haykin的《神经网络与机器学习》


第1课 微积分与概率论
Taylor展式、梯度下降和牛顿法初步、Jensen不等式、常见分布与共轭分布

第2课 数理统计与参数估计
切比雪夫不等式、大数定理、中心极限定理、矩估计、极大似然估计

第3课 矩阵和线性代数
特征向量、对称矩阵对角化、线性方程

第4课 凸优化
凸集、凸函数、凸优化、KKT条件

第5课 回归
最小二乘法、高斯分布、梯度下降、过拟合、Logistic回归
实践示例：线性回归、Logistic回归实现和分析

第6课 梯度下降算法剖析
自适应学习率、拟牛顿、LBFGS
实践示例：自适应学习率代码实现和参数调试分析

第7课 最大熵模型
熵、相对熵、信息增益、最大熵模型、IIS

第8课 聚类
K-means/K-Medoid/密度聚类/谱聚类
实践示例：K-means、谱聚类代码实现和参数调试分析

第9课 推荐系统
协同过滤、隐语义模型pLSA/SVD、随机游走Random Walk
实践示例：协同过滤代码实现和参数调试分析

第10课 决策树和随机森林
ID3、C4.5、CART、Bagging、GBDT
实践案例：使用随机森林进行数据分类

第11课 Adaboost
Adaboost、前向分步算法

第12课 SVM
线性可分支持向量机、线性支持向量机、非线性支持向量机、SMO
实践案例: 使用SVM进行数据分类

第13课 贝叶斯网络
朴素贝叶斯、有向分离、马尔科夫模型/HMM/pLSA

第14课 EM算法
GMM、pLSA、HMM
实践案例：分解男女身高、图像分割

第15课 主题模型
pLSA、共轭先验分布、LDA
实践案例：使用LDA进行文档聚类

第16课 采样与变分
MCMC/KL(p||q)与KL(q||p)

第17课 隐马尔科夫模型HMM
概率计算问题、参数学习问题、状态预测问题
实践案例：使用HMM进行中文分词

第18课 条件随机场CRF
概率无向图模型、MRF、线性链CRF

第19课 人工神经网络
BP算法、CNN、RNN

第20次课 深度学习
实践案例：使用Torch进行图像分类及卷积网络可视化的深度学习实践

预习

《高等数学·上下册》；
《概率论与数理统计·浙大版》、《数理统计学简史·陈希孺》；
《矩阵分析与应用·张贤达》；
《凸优化(Convex Optimization) · Stephen Boyd &amp;amp; Lieven Vandenberghe著》；
《统计学习方法·李航》；
《Pattern Recognition And Machine Learning · Christopher M. Bishop著》，简称PRML；
</content>
      <categories>
        
          <category> ML </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Algorithms</title>
      <url>/algorithms/2017/10/26/Algorithms/</url>
      <content type="text">链表


  链表
  双向链表


哈希表/散列表 (Hash Table)


  散列函数
  碰撞解决


字符串算法


  排序
  查找
    
      BF算法
      KMP算法
      BM算法
    
  
  正则表达式
  数据压缩


二叉树


  二叉树
  二叉查找树
  伸展树(splay tree 分裂树)
  平衡二叉树AVL
  红黑树
  B树,B+,B*
  R树
  Trie树(前缀树)
  后缀树
  最优二叉树(赫夫曼树)
  二叉堆 （大根堆，小根堆）
  二项树
  二项堆
  斐波那契堆(Fibonacci Heap)


图的算法


  图的存储结构和基本操作（建立，遍历，删除节点，添加节点）
  最小生成树
  拓扑排序
  关键路径
  最短路径: Floyd,Dijkstra,bellman-ford,spfa


排序算法

交换排序算法


  冒泡排序
  插入排序
  选择排序
  希尔排序
  快排
  归并排序
  堆排序


线性排序算法


  桶排序


查找算法


  顺序表查找：顺序查找
  有序表查找：二分查找
  分块查找： 块内无序，块之间有序；可以先二分查找定位到块，然后再到块中顺序查找
  动态查找:  二叉排序树，AVL树，B- ，B+    （这里之所以叫 动态查找表，是因为表结构是查找的过程中动态生成的）
  哈希表：  O(1)


15个经典基础算法


  Hash
  快速排序
  快递选择SELECT
  BFS/DFS （广度/深度优先遍历）
  红黑树 （一种自平衡的二叉查找树）
  KMP    字符串匹配算法
  DP (动态规划 dynamic programming)
  A*寻路算法： 求解最短路径
  Dijkstra：最短路径算法 （八卦下：Dijkstra是荷兰的计算机科学家,提出”信号量和PV原语“,”解决哲学家就餐问题”,”死锁“也是它提出来的）
  遗传算法
  启发式搜索
  图像特征提取之SIFT算法
  傅立叶变换
  SPFA(shortest path faster algorithm)  单元最短路径算法


海量数据处理


  Hash映射/分而治之
  Bitmap
  Bloom filter(布隆过滤器)
  Trie树
  数据库索引
  倒排索引(Inverted Index)
  双层桶划分
  外排序
  simhash算法
  分布处理之Mapreduce


算法设计思想


  迭代法
  穷举搜索法
  递推法
  动态规划
  贪心算法
  回溯
  分治算法


</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>DB Algorithms</title>
      <url>/algorithms/2017/10/24/DB-Algorithms/</url>
      <content type="text">基于数据库技术的各类算法

数据库系统中的算法


  电梯算法
  B树索引
  R树索引
  位图索引
  一趟算法
  二趟算法
    
      基于排序
      基于散列
    
  
  连接树
    
      动态规划
      贪婪算法
    
  
  分布式并行数据库中的任务分配算法
    
      并行算法
    
  
  数据挖掘
 	* 发现频繁项集的算法
    
      发现近似商品的算法
      PageRank
    
  


参考

《数据库系统实现》
《redis设计与实现》

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> DB </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Graph</title>
      <url>/2017/10/23/Graph/</url>
      <content type="text">

title: Graph
categories:

  Algorithms
tags:
  Graph




图算法指利用特制的线条算图求得答案的一种简便算法。无向图、有向图和网络能运用很多常用的图算法，这些算法包括：各种遍历算法（这些遍历类似于树的遍历），寻找最短路径的算法，寻找网络中最低代价路径的算法，回答一些简单相关问题（例如，图是否是连通的，图中两个顶点间的最短路径是什么，等等）的算法。图算法可应用到多种场合，例如：优化管道、路由表、快递服务、通信网站等。

图

图的存储结构


  对象和指针
  矩阵
  邻接表


图的操作

遍历


  广度优先
  深度优先


Dijkstra
A*

用于游戏编程和分布式计算

</content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Hash</title>
      <url>/algorithms/2017/10/22/Hash/</url>
      <content type="text">散列表使用某种算法操作(散列函数)将键转化为数组的索引来访问数组中的数据，这样可以通过Key-value的方式来访问数据，达到常数级别的存取效率。现在的nosql数据库都是采用key-value的方式来访问存储数据。

散列表

本节围绕以下内容展开：


  散列表
  散列函数设计
  冲突处理
  hashmap数据结构


散列表是算法在时间和空间上做出权衡的经典例子。通过一个散列函数，将键值key映射到记录的访问地址，达到快速查找的目的。如果没有内存限制，我们可以直接将键作为数组的索引，所有的操作操作只需要一次访问内存就可以完成。但这种情况不太现实。

散列函数

散列函数就是将键转化为数组索引的过程。且这个函数应该易于计算且能够均与分布所有的键。

散列函数最常用的方法是除留余数法。这时候被除数应该选用素数，这样才能保证键值的均匀散步。

散列函数和键的类型有关，每种数据类型都需要相应的散列函数；比如键的类型是整数，那我们可以直接使用除留余数法；这里特别说明下，大多数情况下，键的类型都是字符串，这个时候我们任然可以使用除留余数法，将字符串当做一个特别大的整数。

int hash = 0;
for (int i=0;i&amp;lt;s.length();i++){
	hash = (R*hash +s.charAt(i)%M);
}



还有，比如下面的：

Hash hashCode(char *key){
	int offset = 5;
	Hash hashCode = 0;
	while(*key){
		hashCode = (hashCode &amp;lt;&amp;lt; offset) + *key++;
	}
	return hashCode;		
}



使用时 hashCode(key) &amp;amp; (size-1)  就可以得到一个 size-1 范围内的hash值

当然，还有其他的散列函数，如平方取中法, 随机数法等。

碰撞解决

不同的关键字得到同一个散列地址 f(key1)=f(key2) ，即为碰撞 。这是我们需要尽量避免的情况。常见的处理方法有：


  拉链法
  线性探测法


拉链法

将大小为M的数组中的每个元素指向一条链表，链表中的每个节点都存储了散列值为该元素索引的键值对。每条链表的平均长度是N/M，N是键值对的总个数。如下图：



添加操作：


  通过hash函数得到hashCode
  通过hashcode得到index
  如果index处没有链表，建立好新结点，作为新链表的首结点
  如果index处已经有链表，先要遍历看key是否已经存在，如果存在直接返回，如果不存在，加入链表头部


删除操作：


  通过hash函数得到hashCode
  通过hashcode得到index
  遍历链表，删除结点


线性探测法

使用大小为M的数组保存N个键值对，当碰撞发生时，直接检查散列表中的下一个位置。

数据结构和算法

这里给出拉链法构造的hashmap的算法，表示如下：

typedef char * Key;
typedef int value;
typedef unsigned int Hash;

/*每个节点表示*/
typedef struct Entry{
	Hash hash;
	Key key;
	Value value;
	Entry *next;
}Entry;

typedef struct HashMap{
	Entry **heads;
	unsigned int size; /* 数组大小*/
	unsigned int usage;/* 键值对的个数*/
}HashMap;

Hash hashCode(Key);
HashMap *create(unsigned int size);
HashMap *put(HashMap *,Key ,Value);
int get(HashMap *,Key);

HashMap *_putInHead(HashMap *,int index,Key,Value);
HashMap *_putInList(HashMap *,int index,Key,Value);

Hash hashCode(char *key){
	int offset = 5;
	Hash hashCode = 0;
	while(*key){
		hashCode = (hashCode &amp;lt;&amp;lt; offset) + *key++;
	}
	return hashCode;		
}

HashMap *create(unsigned int size){
	HashMap *hashMap = malloc(sizeof(HashMap));
	hashMap-&amp;gt;size = size;
	hashMap-&amp;gt;usage = 0;
	hashMap-&amp;gt;heads = calloc(size,sizeof(Entry *));

	return hashMap;
}

HashMap *put(HashMap *hashMap,Key key,Value value){
	if (key == NULL){
		return hashMap;
	}
	Hash hash = hashCode(key);
	int index = hash &amp;amp; (size-1);/*  */
	if (hashMap-&amp;gt;heads[index] == NULL){
		_putInHead(hashMap,index,key,value);
	}else{
		_putInList(hashMap,index,key,value);
	}
}

Value get(HashMap hashMap*,Key key){
	if (key == NULL){
		return hashMap;
	}
	Hash hash = hashCode(key);
	int index = hash &amp;amp; (size-1);/*  */

	Entry *entry = hashMap-&amp;gt;heads[index];
	while(entry != NULL){
		if (entry-&amp;gt;hash == hash){
			return entry-&amp;gt;value;
		}
		entry = entry-&amp;gt;next;
	}
	return NULL;
}

HashMap *_putInHead(HashMap *hashMap,int index,Key key,Value value){
	Entry *newHead = malloc(sizeof(Entry));
	newHead-&amp;gt;hash = hash;
	newHead-&amp;gt;key = key;
	newHead-&amp;gt;value = value;

	hashMap-&amp;gt;heads[index] = newHead;
	(hashMap-&amp;gt;usage)++;
	return hashMap;
}

HashMap *_putInList(HashMap *hashMap,int index,Key key,Value value){
	Entry *lastEntry = hashMap-&amp;gt;heads[index];
	while(lastEntry != NULL){
		if (lastEntry-&amp;gt;hash == hash){
			return hashMap;
		}else{
			lastEntry = lastEntry-&amp;gt;next;
		}
	}

	lastEntry = malloc(sizeof(Entry));
	lastEntry-&amp;gt;hash = hash;
	lastEntry-&amp;gt;key = key;
	lastEntry-&amp;gt;value = value;
	lastEntry-&amp;gt;next = hashMap-&amp;gt;heads[index];

	hashMap-&amp;gt;heads[index] = lastEntry;
	(hashMap-&amp;gt;usage)++;
	return hashMap;
}




Hashmap应用


  cocos2d 游戏引擎  CCScheduler
  linux 内核bcache。 缓存加速技术，使用SSD固态硬盘作为高速缓存，提高慢速存储设备HDD机械硬盘的性能
  hash表在海量数据处理中有广泛应用。如海量日志中，提取出某日访问百度次数最多的IP


参考

《Algorithms》

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Hash </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Search</title>
      <url>/algorithms/2017/10/21/Search/</url>
      <content type="text">查找是在大量的信息中寻找一个特定的信息元素，在计算机应用中，查找是常用的基本运算，例如编译程序中符号表的查找。

查找算法


  顺序查找
  二分查找
  分块查找
  动态查找
  哈希表


顺序查找

顺序表查找。复杂度O(n)

二分查找

有序表中查找我们可以使用二分查找。

/*
eg: [1,3,5,6,7,9] k=6
@return 返回元素的索引下表，找不到就返回-1
*/
int binary_search(int *a,int length,int k){
	int low = 0;
	int high = length-1;
	int mid;

	while(low&amp;lt;high){
		mid = (low+high)/2;
		if (a[mid] &amp;lt; k) low = mid+1;
		if (a[mid == k]) return mid;
		if (a[mid] &amp;gt; k) high = mid-1; 
	}

	return -1;
}



分块查找

块内无序，块之间有序；可以先二分查找定位到块，然后再到块中顺序查找。

动态查找

这里之所以叫 动态查找表，是因为表结构是查找的过程中动态生成的。查找结构通常是二叉排序树，AVL树，B- ，B+等。这部分的内容可以去看『二叉树』章节

哈希表

哈希表以复杂度O(1)的成绩位列所有查找算法之首，大量查找的数据结构中都可以看到哈希表的应用。

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Search </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>String</title>
      <url>/algorithms/2017/10/19/String/</url>
      <content type="text">字符串在计算机中的应用非常广泛，这里讨论有关字符串的最重要的算法：
字符串


  排序
  查找
    
      单词查找树
      子串查找
    
  
  正则表达式:正则表达式是模式匹配的基础,是一个一般化了的子字符串的查找问题,也是搜索工具grep的核心。
    
      模式匹配
      grep
    
  
  数据压缩
    
      赫夫曼树
      游程编码
    
  


参考

《Algorithms》

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> String </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Algorithms Analysis</title>
      <url>/algorithms/2017/10/18/Algorithms-Analysis/</url>
      <content type="text">详细介绍每一种算法设计的思路，并为每种方法给出一个经典案例的详细解读，总结对应设计思路，最后给出其它案例，以供参考。

算法分析思路


  迭代法
  穷举搜索法
  动态规划
  贪心算法
  回溯法
  分治算法
  递归




迭代法

是一种不断用旧值递推新值的过程，分精确迭代和近视迭代。是用来求方程和方程组近似根的方法。

迭代变量
迭代关系， 迭代关系选择不合理，会导致迭代失败
迭代过程控制，也就是迭代什么时候结束，不能无休止进行下去

穷举搜索法

或者叫蛮力法。对可能的解的众多候选按照某种顺序逐一枚举和检验。典型的问题如选择排序和冒泡排序。

背包问题

给定n个重量为 w1,w2,…,wn,定价为 v1,v2,…,vn 的物品，和一个沉重为W的背包，求这些物品中一个最有价值的子集，且能装入包中。

其它案例

选择排序
冒泡排序

动态规划DP

复杂问题不能分解成几个子问题，而分解成一系列子问题；

DP通常基于一个递推公式及一个(或多个)初始状态，当前子问题解由上一次子问题解推出。

状态
状态转移方程
递推关系

动态规划算法的关键在于解决冗余，以空间换时间的技术，需要存储过程中的各种状态。可以看着是分治算法+解决冗余

使用动态规划算法的问题的特征是子问题的重叠性，否则动态规划算法不具备优势

###基本步骤


  划分问题
  选择状态
  确定决策并写出状态转移方程
  写出规划方程


最长递增子序列

最长递增子序列（LIS Longest Increasing Subsequence）

其它案例

最短路径

贪心算法

不追求最优解，只找到满意解。

赫夫曼编码

其它案例

找回零钱问题
装箱问题

回溯法

也叫 试探法。 是一种选优搜索法，按照选优条件搜索，当搜索到某一步，发现原先选择并不优或达不到目标，就退回重新选择。

一般步骤


  针对问题，定义解空间（ 这时候解空间是一个集合，且包含我们要找的最优解）
  组织解空间，确定易于搜索的解空间结构，通常组织成树结构 或 图结构
  深度优先搜索解空间，搜索过程中用剪枝函数避免无效搜索


回溯法求解问题时，一般是一边建树，一边遍历该树；且采用非递归方法。

八皇后问题

8x8的国际象棋棋盘上放置8个皇后，使得任何一个皇后都无法直接吃掉其他的皇后。任意2个皇后都不能处于同一个 横线，纵线，斜线上。

分析

  任意2个皇后不能同一行，也就是每个皇后占据一行，通用的，每个皇后也要占据一列
  一个斜线上也只有一个皇后


其它案例

迷宫问题

分治算法

将一个难以直接解决的大问题，分割成一些规模较小的相同问题，各个击破，分而治之。

分治算法常用递归实现

1） 问题缩小的小规模可以很容易解决
2) 问题可以分解为规模较小相同问题
3） 子问题的解可以合并为该问题的解
4） 各个子问题相互独立，(如果这条不满足,转为动态规划求解）

分治法的步骤：

  分解
  解决
  合并


大整数乘法

如 26542123532213598*345987342245553677884

其它案例

快速排序 
归并排序  
最大子数组和

递归

递归是一种设计和描述算法的有力工具。 递归算法执行过程分 递推 和 回归  两个阶段

在 递推 阶段，将大的问题分解成小的问题
在  回归 阶段，获得最简单问题的解后，逐级返回，依次得到稍微复杂情况的解，知道获得最终的结果

1） 确定递归公式
2） 确定边界条件

斐波那契数列

fib(n)=fib(n-1)+fib(n-2)

递归实现




非递归实现




其它案例

阶乘计算
梵塔问题 （三根针1，2，3表示，1号从小到大n个盘子，先要都移到3号上，不能出现大盘压小盘，找出移动次数最少的方案）
快速排序

递归运行效率较低，因为有函数调用的开销，递归多次也可能造成栈溢出。

总结

贪心法、分治法、动态规划都是将问题归纳为根小的、相似的子问题，通过求解子问题产生全局最优解。

贪心法

分治法

动态规划

参考

《算法设计与分析基础》 Anany Levitin 
http://www.chinaunix.net/old_jh/23/437639.html

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Analysis </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>simhash算法</title>
      <url>/2017/10/01/simhash/</url>
      <content type="text">simhash是google用来处理海量文本去重的算法。

simhash算法

1、分词，把需要判断文本分词形成这个文章的特征单词。最后形成去掉噪音词的单词序列并为每个词加上权重，我们假设权重分为5个级别（1~5）。比如：“ 美国“51区”雇员称内部有9架飞碟，曾看见灰色外星人 ” ==&amp;gt; 分词后为 “ 美国（4） 51区（5） 雇员（3） 称（1） 内部（2） 有（1） 9架（3） 飞碟（5） 曾（1） 看见（3） 灰色（4） 外星人（5）”，括号里是代表单词在整个句子里重要程度，数字越大越重要。

2、hash，通过hash算法把每个词变成hash值，比如“美国”通过hash算法计算为 100101,“51区”通过hash算法计算为 101011。这样我们的字符串就变成了一串串数字，还记得文章开头说过的吗，要把文章变为数字计算才能提高相似度计算性能，现在是降维过程进行时。

3、加权，通过 2步骤的hash生成结果，需要按照单词的权重形成加权数字串，比如“美国”的hash值为“100101”，通过加权计算为“4 -4 -4 4 -4 4”；“51区”的hash值为“101011”，通过加权计算为 “ 5 -5 5 -5 5 5”。

4、合并，把上面各个单词算出来的序列值累加，变成只有一个序列串。比如 “美国”的 “4 -4 -4 4 -4 4”，“51区”的 “ 5 -5 5 -5 5 5”， 把每一位进行累加， “4+5 -4+-5 -4+5 4+-5 -4+5 4+5” ==》 “9 -9 1 -1 1 9”。这里作为示例只算了两个单词的，真实计算需要把所有单词的序列串累加。

5、降维，把4步算出来的 “9 -9 1 -1 1 9” 变成 0 1 串，形成我们最终的simhash签名。 如果每一位大于0 记为 1，小于0 记为 0。最后算出结果为：“1 0 1 0 1 1”

simhash计算过程图


大家可能会有疑问，经过这么多步骤搞这么麻烦，不就是为了得到个 0 1 字符串吗？我直接把这个文本作为字符串输入，用hash函数生成 0 1 值更简单。其实不是这样的，传统hash函数解决的是生成唯一值，比如 md5、hashmap等。md5是用于生成唯一签名串，只要稍微多加一个字符md5的两个数字看起来相差甚远；hashmap也是用于键值对查找，便于快速插入和查找的数据结构。不过我们主要解决的是文本相似度计算，要比较的是两个文章是否相识，当然我们降维生成了hashcode也是用于这个目的。看到这里估计大家就明白了，我们使用的simhash就算把文章中的字符串变成 01 串也还是可以用于计算相似度的，而传统的hashcode却不行。我们可以来做个测试，两个相差只有一个字符的文本串，“你妈妈喊你回家吃饭哦，回家罗回家罗” 和 “你妈妈叫你回家吃饭啦，回家罗回家罗”。

通过simhash计算结果为：

1000010010101101111111100000101011010001001111100001001011001011

1000010010101101011111100000101011010001001111100001101010001011

通过 hashcode计算为：

1111111111111111111111111111111110001000001100110100111011011110

1010010001111111110010110011101

大家可以看得出来，相似的文本只有部分 01 串变化了，而普通的hashcode却不能做到，这个就是局部敏感哈希的魅力。
</content>
      <categories>
        
      </categories>
      <tags>
        
          <tag> Mass data processing </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>倒排索引(Inverted Index)</title>
      <url>/big%20data/2017/10/01/inverted-Index/</url>
      <content type="text">也叫反向索引。是文档检索系统中最常用的数据结构。
倒排索引(Inverted Index)

常规的索引是文档到关键词的映射，如果对应的文档是

Elasticsearch就是使用倒排索引(inverted index)的结构来做快速的全文搜索。ElasticSearch 不仅用于全文搜索, 还有非常强大的统计功能 (facets)。

携程，58，美团的分享中都提到ES构建实时日志系统，帮助定位系统问题。

Elasticsearch权威指南

</content>
      <categories>
        
          <category> Big Data </category>
        
      </categories>
      <tags>
        
          <tag> Mass data processing </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>分布处理之Mapreduce</title>
      <url>/big%20data/2017/10/01/Mapreduce/</url>
      <content type="text">分布处理之Mapreduce

MapReduce是Google提出的一个软件架构，用于大规模数据集（大于1TB）的并行运算。概念“Map（映射）”和“Reduce（归纳）”，及他们的主要思想，都是从函数式编程语言借来的，还有从矢量编程语言借来的特性。MapReduce的伟大之处就在于让不熟悉并行编程的程序员也能充分发挥分布式系统的威力。

Mapreduce工作原理

举一个例子：10年内所有论文(当然有很多很多篇)里面出现最多的几个单词。

我们把论文集分层N份，一台机器跑一个作业。这个方法跑得快，但是有部署成本，需要把程序copy到别的机器，要把论文分N份，且还需要最后把N个运行结果整合起来。这其实就是Mapreduce本质。

map函数和reduce函数是交给用户实现的，这两个函数定义了任务本身。


  map函数：接受一个键值对（key-value pair），产生一组中间键值对。MapReduce框架会将map函数产生的中间键值对里键相同的值传递给一个reduce函数。Map操作是可以高度并行的。
  reduce函数：接受一个键，以及相关的一组值，将这组值进行合并产生一组规模更小的值（通常只有一个或零个值）。


Hadoop

谷歌技术有”三宝”，GFS、MapReduce和大表（BigTable）。

Hadoop实际上就是谷歌三宝的开源实现，Hadoop MapReduce对应Google MapReduce，HBase对应BigTable，HDFS对应GFS。HDFS（或GFS）为上层提供高效的非结构化存储服务，HBase（或BigTable）是提供结构化数据服务的分布式数据库，Hadoop MapReduce（或Google MapReduce）是一种并行计算的编程模型，用于作业调度。

Hadoop 使用java实现。

</content>
      <categories>
        
          <category> Big Data </category>
        
      </categories>
      <tags>
        
          <tag> Mass data processing </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Hash映射,分而治之</title>
      <url>/big%20data/2017/10/01/Hash-mapping/</url>
      <content type="text">这里的Hash映射是指通过一种映射散列的方式，将海量数据均匀分布在对应的内存或更小的文件中

Hash映射,分而治之

使用hash映射有个最重要的特点是: hash值相同的两个串不一定一样，但是两个一样的字符串hash值一定相等。哈希函数如下：

int hash = 0;
for (int i=0;i&amp;lt;s.length();i++){
	hash = (R*hash +s.charAt(i)%M);
}



大文件映射成多个小文件。具体操作是，比如要拆分到100(M)个文件：


  对大文件中的每条记录求hash值，然后对M取余数，即 hash(R)%M，结果为K
  将记录R按结果K分配到第K个文件，从而完成数据拆分


这样，两条相同的记录肯定会被分配到同一个文件。

</content>
      <categories>
        
          <category> Big Data </category>
        
      </categories>
      <tags>
        
          <tag> Mass data processing </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>外排序</title>
      <url>/big%20data/2017/10/01/External-sorting/</url>
      <content type="text">对磁盘文件的排序。将待处理的数据不能一次装入内存，先读入部分数据排序后输出到临时文件，采用「排序-归并」的策略。在归并阶段将这些临时文件组合为一个大的有序文件，也即排序结果。

外排序

多路归并,最小堆

比如，要对900 MB的数据进行排序，但机器上只有100 MB的可用内存时，外归并排序按如下方法操作：


  读入100 MB的数据至内存中，用某种常规方式（如快速排序、堆排序、归并排序等方法）在内存中完成排序。
  将排序完成的数据写入磁盘。
  重复步骤1和2直到所有的数据都存入了不同的100 MB的块（临时文件）中。在这个例子中，有900 MB数据，单个临时文件大小为100 MB，所以会产生9个临时文件。
  读入每个临时文件（顺串）的前10 MB（ = 100 MB / (9块 + 1)）的数据放入内存中的输入缓冲区，最后的10 MB作为输出缓冲区。（实践中，将输入缓冲适当调小，而适当增大输出缓冲区能获得更好的效果。）
  执行九路归并算法，将结果输出到输出缓冲区。一旦输出缓冲区满，将缓冲区中的数据写出至目标文件，清空缓冲区。一旦9个输入缓冲区中的一个变空，就从这个缓冲区关联的文件，读入下一个10M数据，除非这个文件已读完。这是“外归并排序”能在主存外完成排序的关键步骤 – 因为“归并算法”(merge algorithm)对每一个大块只是顺序地做一轮访问(进行归并)，每个大块不用完全载入主存。


为了增加每一个有序的临时文件的长度，可以采用置换选择排序（Replacement selection sorting）。它可以产生大于内存大小的顺串。具体方法是在内存中使用一个最小堆进行排序，设该最小堆的大小为M。算法描述如下：


  初始时将输入文件读入内存，建立最小堆。
  将堆顶元素输出至输出缓冲区。然后读入下一个记录：
    
      若该元素的关键码值不小于刚输出的关键码值，将其作为堆顶元素并调整堆，使之满足堆的性质；
      否则将新元素放入堆底位置，将堆的大小减1。
    
  
  重复第2步，直至堆大小变为0。
  此时一个顺串已经产生。将堆中的所有元素建堆，开始生成下一个顺串。[3]


此方法能生成平均长度为2M的顺串，可以进一步减少访问外部存储器的次数，节约时间，提高算法效率。

</content>
      <categories>
        
          <category> Big Data </category>
        
      </categories>
      <tags>
        
          <tag> Mass data processing </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>双层桶划分</title>
      <url>/big%20data/2017/10/01/Double-bucket-partition/</url>
      <content type="text">双层桶不是一种数据结构，只是一种算法思维。分而治之思想。
双层桶划分

当我们有一大推数据需要处理时，局限于各种资源限制(主要说内存)不能一次处理完成，这是需要将一大堆数据分成多个小段数据。通过处理各个小段数据完成最终任务。

双层这里是虚指，并不是一定把数据分成2份，也可能多份。比如下面几个问题：


  2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。
  5亿个int找它们的中位数


第一个问题，2.5亿(2^32=4,294,967,296)个数,我们将这2^32个数分到2^8=256个区域(文件中)。每个文件中的平均数字个数差不多 2^24个(1千7百万个)。
0~2^24 第一个文件，2^24~2^25第二个文件

假设32位机，装下这些数字需要的内存是 2^24*4=2^26=64MB,也可以不用将文件一次性读入内存而是采用流式读取。

然后对每个文件使用bitmap处理，每2bit(2-bitmap)表示一个整数，00表示整数未出现，01表示出现一次，10表示出现两次及其以上。这样，每个文件2^24个数字，最大数2^32/(8/2)=2^30=1GB内存

这个问题倒是更新是bitmap的应用，没有很好体现双层桶分治的优势。

第二个问题，首先我们将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。

适用问题领域是：top-k，中位数，不重复或重复的数字

</content>
      <categories>
        
          <category> Big Data </category>
        
      </categories>
      <tags>
        
          <tag> Mass data processing </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>数据库索引</title>
      <url>/big%20data/2017/10/01/Database-index/</url>
      <content type="text">数据库索引

索引使用的数据结构多是B树或B+树。B树和B+树广泛应用于文件存储系统和数据库系统中，mysql使用的是B+树，oracle使用的是B树，Mysql也支持多种索引类型，如b-tree 索引，哈希索引，全文索引等。

一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。

磁盘数据查找过程



盘面：每一个盘片都有2个上下盘面，每个盘面都可以存储数据

柱面：所有盘面上的同一磁道构成一个圆柱，叫做柱面。磁盘读写按柱面进行;
只在同一柱面所有的磁头全部读/写完毕后磁头才转移到下一柱面，因为选取磁头只需通过电子切换即可，而选取柱面则必须通过机械切换。电子切换相当快，比在机械上磁头向邻近磁道移动快得多，所以，数据的读/写按柱面进行，而不按盘面进行。也就是说，一个磁道写满数据后，就在同一柱面的下一个盘面来写，一个柱面写满后，才移到下一个扇区开始写数据。读数据也按照这种方式进行，这样就提高了硬盘的读/写效率。

磁道：磁盘在格式化时被划分出许多同心圆，这些同心圆轨迹叫做磁道 track。磁道从外向内从0开始编号。

扇区：信息以脉冲串的形式记录在这些轨迹中，这些同心圆不是连续记录数据，而是被划分成一段段圆弧，每段圆弧叫做一个扇区，扇区从“1”开始编号 。扇区也叫块号。

磁盘在物理上划分为柱面, 磁道，扇区。想要读取扇区的数据，需要将磁头放到这个扇区上方:


  先找到柱面，也就是寻道。磁头是不能动的，但可以沿着磁盘半径方向运动，耗时记为寻道事件 t(seek)
  将目标扇区旋转到磁头下，这个过程耗时是旋转时间t(r)


一个磁盘扇区数据读取的时间t = t(seek)+t(r)+t(数据传输) , 在数据库查找数据时，查找时间与访问的磁盘盘块成正比，内存处理时间可以忽略不计。

B树

2-3树：一个节点最多有2个key，红黑树就是2-3树的一种实现。

B树又叫多路平衡查找树。B树可以看做是对2-3树的扩展，允许每个节点有M-1个key，并以升序排列，这里的M就是B树的阶。

B树的度d(d&amp;gt;=2) ，有一些特征：


  根节点至少有2个子节点
  所有的叶节点具有相同的深度 h，也就是树高
  每个叶子节点至少包含一个key和2个指针，最多2d-1个key和2d个指针，叶节点的指针都是null。每个节点的关键字个数在【d-1,2d-1】之间
  每个非叶子节点，key和指针互相间隔，节点两端是指针，因此节点中指针个数=key的个数+1
  每个指针要么是null，要么指向另一个节点


如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v(key1)，其中v(key1)为node的第一个key的值。
如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于v(keym)，其中v(keym)为node的最后一个key的值。
如果某个指针在节点node的左右相邻key分别是keyi和keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)且大于v(keyi)。

使用数据结构表示如下：

typedef struct Item{
     int key;
     Data data;
}

#define m 3 //B树的阶

typedef struct BTNode{
    int degree; //B树的度
    int keynums; //每个节点key的个数
     Item  items[m];
     struct BTNode *p[m];
}BTNode,* BTree;

typedef struct{
     BTNode *pt; //指向找到的节点
     int i; // 节点中关键字的序号 (0,m-1)
     int tag; //1:查找成功，0：查找失败
}Result;

Status btree_insert(root,target);
Status btree_delete(root,target);
Result btree_find(root,target);




建立索引

当为一张空表创建索引时，数据库系统将为你分配一个索引页，该索引页在你插入数据前一直是空的。此页此时既是根结点，也是叶结点。每当你往表中插入一行数据，数据库系统即向此根结点中插入一行索引记录。

插入和删除新的数据记录都会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质

查找操作

从root节点出发，对每个节点，找到等于target的key，则查找成功；或者找到大于target的最小k[i], 到 k[i] 左指针指向的子节点继续查找，直到页节点，如果找不到，说明关键字target不在B树中。

分析下时间复杂度：

对于一个度为d的B-Tree,每个节点的索引key个数是d-1, 索引key个数为N，树高h上限是：

2d^h-1=N ==&amp;gt; h=logd^((N+1) /2) ？？？

因此，检索一个key，查找节点的个数的复杂度是O(logd^N)

比如d=2，N=1,000,000 (1百万)，h差不多20个
d=3,N=1,000,000 (1百万) ,h差不多13个(3^11=1,594,323)
d=4,N=1,000,000 (1百万) ,h差不多10个
d=5,N=1,000,000 (1百万) ,h差不多9个 (5^9 = 1,953,125)
d=6,N=1,000,000 (1百万) ,h差不多8个(6^8 = 1,679,616)
d=7,N=1,000,000 (1百万) ,h差不多8个
d=8,N=1,000,000 (1百万) ,h差不多7个
d=9,N=1,000,000 (1百万) ,h差不多7个
d=10,N=1,000,000 (1百万) ,h差不多6个
d=100时，h差不多3个



数据库系统在设计时，通常将一个节点的大小设为一个页大小(通常4k)，这样保证一个节点在物理上也存储在一个页里，加上计算机存储分配都是按页对其，这样保证一个节点只需要一次I/O.

实际应用中，d都是比较大，通常超过100，因此1百万的数据通常最多访问3个节点，也就是3次I/O, 因此使用B树作为索引结构查询效率非常高。

插入数据

插入数据时，需要更新索引，索引中也要添加一条记录。索引中添加一条记录的过程是：

沿着搜索的路径从root一直到叶节点

每个节点的关键字个数在【d-1,2d-1】之间，当节点的关键字个数是2t-1时，再加入target就违反了B树定义，需要对该节点进行分裂：已中间节点为界，分成2个包含d-1个关键字的子节点（另外还有一个分界关键字，2*(d-1)+1=2d-1），同时把该分界关键字提升到该叶子的父节点中，如果这导致父节点关键字个数超过2d-1,就继续向上分裂，直到根节点。

如下演示动画，往度d=2的B树中插入： 6 10 4 14 5 11 15 3 2 12 1 7 8 8 6 3 6 21 5 15 15 6 32 23 45 65 7 8 6 5 4



B树和B+树的区别

B树和B+树的区别在于：


  B+树的非叶子节点只包含导航信息，不包含实际记录的信息，这可以保证一个固定大小节点可以放入更多个关键字，也就是更大的度d，从而树高h可以更小，从而相比B树有更优秀的查询效率
  所有的叶子节点和相邻的节点使用链表方式相连，便于区间查找和遍历


</content>
      <categories>
        
          <category> Big Data </category>
        
      </categories>
      <tags>
        
          <tag> Mass data processing </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Bloom filter(布隆过滤器)</title>
      <url>/big%20data/2017/10/01/Bloom-filter/</url>
      <content type="text">Bloom Filter是由Bloom在1970年提出的一种多哈希函数映射的快速查找算法。通常应用在一些需要快速判断某个元素是否属于集合，但是并不严格要求100%正确的场合。

Bloom filter(布隆过滤器)

Bloom filter 特点

为了说明Bloom Filter存在的重要意义，举一个实例：假设要你写一个网络蜘蛛（web crawler）。由于网络间的链接错综复杂，蜘蛛在网络间爬行很可能会形成“环”。为了避免形成“环”，就需要知道蜘蛛已经访问过那些URL。给一个URL，怎样知道蜘蛛是否已经访问过呢？稍微想想，就会有如下几种方案：


  将访问过的URL保存到数据库。
  用HashSet将访问过的URL保存起来。那只需接近O(1)的代价就可以查到一个URL是否被访问过了。
  URL经过MD5或SHA-1等单向哈希后再保存到HashSet或数据库。
  BitMap方法。建立一个BitSet，将每个URL经过一个哈希函数映射到某一位。


方法1~3都是将访问过的URL完整保存，方法4则只标记URL的一个映射位。以上方法在数据量较小的情况下都能完美解决问题，但是当数据量变得非常庞大时问题就来了。

方法1的缺点：数据量变得非常庞大后关系型数据库查询的效率会变得很低。而且每来一个URL就启动一次数据库查询是不是太小题大做了？
方法2的缺点：太消耗内存。随着URL的增多，占用的内存会越来越多。就算只有1亿个URL，每个URL只算50个字符，就需要5GB内存。
方法3：由于字符串经过MD5处理后的信息摘要长度只有128Bit，SHA-1处理后也只有160Bit，因此方法3比方法2节省了好几倍的内存。
方法4消耗内存是相对较少的，但缺点是单一哈希函数发生冲突的概率太高。还记得数据结构课上学过的Hash表冲突的各种解决方法么？若要降低冲突发生的概率到1%，就要将BitSet的长度设置为URL个数的100倍。

实质上上面的算法都忽略了一个重要的隐含条件：允许小概率的出错，不一定要100%准确！也就是说少量url实际上没有没网络蜘蛛访问，而将它们错判为已访问的代价是很小的——大不了少抓几个网页呗。

Bloom filter 算法

Bloom filter可以看做是对bitmap的扩展。只是使用多个hash映射函数，从而减低hash发生冲突的概率。算法如下:


  创建 m 位的bitset，初始化为0， 选中k个不同的哈希函数
  第 i 个hash 函数对字符串str 哈希的结果记为 h(i,str) ,范围是（0，m-1）
  
    将字符串记录到bitset的过程：对于一个字符串str,分别记录h(1,str),h(2,str)…,h(k,str)。 然后将bitset的h(1,str),h(2,str)…,h(k,str)位置1。也就是将一个str映射到bitset的 k 个二进制位。
  
  
    检查字符串是否存在:对于字符串str，分别计算h(1，str)、h(2，str),…,h(k，str)。然后检查BitSet的第h(1，str)、h(2，str),…,h(k，str) 位是否为1，若其中任何一位不为1则可以判定str一定没有被记录过。若全部位都是1，则“认为”字符串str存在。但是若一个字符串对应的Bit全为1，实际上是不能100%的肯定该字符串被Bloom Filter记录过的。（因为有可能该字符串的所有位都刚好是被其他字符串所对应）这种将该字符串划分错的情况，称为false positive 。
  
  删除字符串:字符串加入了就被不能删除了，因为删除会影响到其他字符串。实在需要删除字符串的可以使用Counting bloomfilter(CBF)。


Bloom Filter 使用了k个哈希函数，每个字符串跟k个bit对应。从而降低了冲突的概率。

最优的哈希函数个数，位数组m大小

哈希函数的选择对性能的影响应该是很大的，一个好的哈希函数要能近似等概率的将字符串映射到各个Bit。选择k个不同的哈希函数比较麻烦，一种简单的方法是选择一个哈希函数，然后送入k个不同的参数。

在原始个数位n时，那这里的k应该取多少呢？位数组m大小应该取多少呢？这里有个计算公式:k=(ln2)*(m/n), 当满足这个条件时，错误率最小。

假设错误率为0.01， 此时m 大概是 n 的13倍，k大概是8个。 这里的n是元素记录的个数，m是bit位个数。如果每个元素的长度原大于13，使用Bloom Filter就可以节省内存。

错误率估计

实现示例

#define SIZE 15*1024*1024
char a[SIZE]; /* 15MB*8 = 120M bit空间 */
memset(a,0,SIZE);

int seeds[] = { 5, 7, 11, 13, 31, 37, 61};

int hashcode(int cap,int seed, string key){
	int hash = 0;
	for (int i=0;i&amp;lt;key.length();i++){
		hash = (seed*hash +key.charAt(i));
	}
	return hash &amp;amp; (cap-1);
}



对每个字符串str求哈希就可以使用 hashcode(SIZE*8,seeds[i],str) ,i 的取值范围就是 （0，k）。

Bloom filter应用


  拼写检查一类的字典应用
  数据库系统
  网络领域（爬虫，web cache sharing）


参考
http://www.cnblogs.com/heaad/archive/2011/01/02/1924195.html
http://blog.csdn.net/jiaomeng/article/details/1495500  
http://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html  哈希函数个数k、位数组大小m 测试论证

</content>
      <categories>
        
          <category> Big Data </category>
        
      </categories>
      <tags>
        
          <tag> Mass data processing </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Bitmap</title>
      <url>/2017/10/01/Bitmap/</url>
      <content type="text">

layout: post
title: Bitmap算法
category: Big Data
tags:

  
    Mass data processing
  


也就是用1个(或几个)bit位来标记某个元素对应的value(如果是1bitmap，就只能是元素是否存在;如果是x-bitmap,还可以是元素出现的次数等信息)。使用bit位来存储信息，在需要的存储空间方面可以大大节省。

Bitmap

应用场景有：


  排序（如果是1-bitmap,就只能对无重复的数排序）
  判断某个元素是否存在


比如，某文件中有若干8位数字的电话号码，要求统计一共有多少个不同的电话号码？

分析：8位最多99 999 999, 如果1Byte表示1个号码是否存在，需要95MB空间，但是如果1bit表示1个号码是否存在，则只需要 95/8=12MB 的空间。这时，数字k(0~99 999 999)与bit位的对应关系是：

#define SIZE 15*1024*1024
char a[SIZE];
memset(a,0,SIZE);

// a[k/8]这个字节中的 `k%8` 位命中,置为1
// 这里要注意 big-endian 和  little-endian的问题 ，假设这里是big-endian
a[k/8] = a[k/8] | (0x01 &amp;lt;&amp;lt; (k%8))



</content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>海量数据处理(BD)</title>
      <url>/big%20data/2017/10/01/BD/</url>
      <content type="text">海量数据处理

所谓海量数据，就是数据量太大，要么在短时间内无法计算出结果，要么数据太大，无法一次性装入内存。

针对时间，我们可以使用巧妙的算法搭配合适的数据结构，如bitmap/堆/trie树等
针对空间，就一个办法，大而化小，分而治之。常采用hash映射


  Hash映射/分而治之
  Bitmap
  Bloom filter(布隆过滤器)
  双层桶划分
  Trie树
  数据库索引
  倒排索引(Inverted Index)
  外排序
  simhash算法
  分布处理之Mapreduce


估算

在处理海量问题之前，我们往往要先估算下数据量，能否一次性载入内存？如果不能，应该用什么方式拆分成小块以后映射进内存？每次拆分的大小多少合适？以及在不同方案下，大概需要的内存空间和计算时间。

比如,我们来了解下以下常见问题时间 和 空间 估算 :

8位的电话号码，最多有99 999 999个
IP地址
1G内存，2^32 ,差不多40亿，40亿Byte*8 = 320亿 bit




海量处理问题常用的分析解决问题的思路是：


  分而治之/Hash映射 + hash统计/trie树/红黑树/二叉搜索树 + 堆排序/快速排序/归并排序
  双层桶划分
  Bloom filter 、Bitmap
  Trie树/数据库/倒排索引
  外排序
  分布处理之 Hadoop/Mapreduce


</content>
      <categories>
        
          <category> Big Data </category>
        
      </categories>
      <tags>
        
          <tag> Mass data processing </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title>Sort</title>
      <url>/algorithms/2013/12/25/Sort/</url>
      <content type="text">所谓排序，就是使一串记录，按照其中的某个或某些关键字的大小，递增或递减的排列起来的操作。排序算法，就是如何使得记录按照要求排列的方法。

排序算法

排序的稳定性 是指对于相等的元素，排序之后，任然保存2个元素的位置没有变，就是稳定的排序，反之就是不稳定排序。

交换排序算法


  冒泡排序
  插入排序
  选择排序
  希尔排序
  快排
  归并排序
  堆排序


线性排序算法


  桶排序


交换排序算法

排序算法的复杂度由 比较的次数 和 交换的次数 一起决定。

直接选择排序


  从未排序的序列中选择最小的元素，与放在第一个位置的元素交换
  依次类推，直到全部排序


在a【i,n】中最小的元素和 a[i]交换位置。空间复杂度O(1)，时间复杂度 O(n^2)

冒泡排序


  相邻的2各元素比较，大的向后移，经过一轮比较，做大的元素排在最后
  第二轮，第二大的元素排倒数第二个位置
  直到全部排好


这样，即使是排好序的拿冒泡排序排序，比较的时间复杂度O(n^2)

插入排序


  第一个元素算作已经排好
  取下一个元素，从已经排好的序列元素中，从后向前扫描
  如果排好序的元素大于 新元素，排好序的元素移到下一个位置
  重复3，直到直到最后的插入位置
  重复2


类似插入扑克牌的效果

最坏的情况： 待排序的是一个逆序排放的数组，这样导致每一轮都要移动元素；此时复杂度是是0(n^2) 
最好的情况： 待排序的是一已经顺序排放的数字，此时只需要做一轮比较就够了 0（n）。因此可以看到，对大部分数据已经有序这样的数组排序，使用插入排序非常有优势

空间复杂度O（1）

希尔排序

递减增量排序算法，对插入排序的改进，实质是分组插入排序，又叫缩小增量排序


  先将待排数列分割成若干子序列（增量为m)
  对每个子序列使用插入排序
  减小增量，再排序
  对全体元素做一次插入排序


希尔排序提升排序的奥秘就在于数据元素越有序，使用插入排序效率越高

快速排序

递归一次，pivot 左边都比它小，右边都比它大。这是递归，分治的思想。

对 A[p…r] :

  分解：A[p..q-1]  A[q+1..r],使得 A[p…q-1]&amp;lt;A[q]&amp;lt;A[q+1..r]
  解决：递归调用 快排，，对子数组A[p..q-1],A[q+1..r]排序
  合并（子问题相互独立的，因此用分治算法就可以了）


具体步骤：


  从数列中选择一个元素，作为基准 pivot。通常取分区的第一个或最后一个
  重排数列，比 pivot 小得排左边，比pivot大的排右边，相等的随便。 一句话就是挖坑填数
  递归的，使用相同的方式，重排左右两边的子序列


扫描过程分2种：

  挖坑排序，2头向中间扫描，先从后向前找，再从前向后找。
  单向扫描


    void quicksort(int *a, int left, int right){
        if (left&amp;lt;right)//加上这个，不然有死循环，造成堆栈溢出，这也是递归结束条件
        {
            int i = partion(a,left,right);//使得局部有序，i作为分隔
            quicksort(a,left,i-1); 
            quicksort(a,i+1,right);
        }
    }

    // 挖坑填数，2边向中间扫描
    int partion(int *a, int start,int end){
        int i=start,j=end;
        int tmp = a[i]; // 这里要做越界检查
        while(i&amp;lt;j){
            // 从后向前扫描，找到第一个小于tmp的值，来填a[i]
             while(i&amp;lt;j &amp;amp;&amp;amp; a[j]&amp;gt;=tmp){
                 j--;
            }   
             if (i&amp;lt;j)//找到了,这时候a[j]为坑 
            {   
                a[i++] = a[j];  
            }
            // 从左向右扫描，找一个大于 tmp的 数， 去填坑a[j]
            while(i&amp;lt;j &amp;amp;&amp;amp; a[i]&amp;lt;tmp){
                i++;
            }
            if (i&amp;lt;j)
            {
                a[j++]=a[i];
            }
        }
        //扫描完成后，i==j
        a[i]=tmp;
        return i;
    }




平均复杂度 O(n*logn)
最坏O(n^2)
空间复杂度

快速排序是对冒泡排序的改进，划分交换排序。

归并排序merge

分治算法，必然用到递归

2个有序数组的合并操作是O(n)的复杂度
因此我们可以将无序的数组，分成2个子数组分别排序，然后再merge,依次类推

归并排序的步骤:


  分解。将一个数组分成n/2个子数组,每个序列2个元素，(2路归并)
  解决。 将各个子数组都排好序，然后 merge 2个有序数组
  
    合并

    if (length&amp;gt;1)
 {  
     merge_sort(a,length/2);
     merge_sort(a+length/2,length-length/2);
     merge_array(a,length/2,a+length/2,length-length/2);
 }
  


堆排序

利用堆这种数据结构设计的一种排序算法

先来了解下 堆 结构

堆分小根堆和大根堆

堆： 任一节点小于（或大于）其所有的孩子节点，如果是大于所有孩子节点，这就是一颗大根堆，也就是根节点是堆上的最大值；如果节点小于所有的子节点，这就是一颗小跟堆，也即是根节点是堆上所有节点的最小值。

堆也被称为优先队列
堆总是一颗完全树

堆用数组来存储，i节点的父节点就是(i-1)/2,左右子节点小标是 2i+1，2i+2。

堆的操作有：

建堆
插入：都是插入到数组最后，然后再调整满足堆次序
删除：删除总是发生在 A[0]处，也就是只删除根节点

这样难怪堆被称为 优先队列。插入和删除分别在 数组尾部和头部，只是需要再次调整以满足堆次序。

堆的应用场景有：
优先队列  如iOS中的NSOperationQueue 就是维护一个优先队列
堆排序

我们来看看如何使用堆 来做排序?

1.将待排序数列看做一颗完全二叉树的存储结构 
2.堆化数组，结束后，根a[0]变成了最小的值（小根堆）
3.取a[0]值，然后对堆做删除操作，此时，堆会重新 堆化数组，a[0]又是下一个最小的值。
删除操作通常是先把数组最后的元素提到a[0]位置，然后从根节点开始进行一次从上向下的调整；调整时，先从左右孩子中找最小的交换。如果父节点比每个节点都小就不用调整。（因此，在堆排序是可以直接让 a[0]和数组最后一个元素互换，但要先保存好a[0],或者a[n-1],这样导致了使用堆排序时，递增排序使用大根堆，递减排序使用小根堆。）

  循环3，就可以按从小到大的顺序取出所有数组元素。


堆排序主要时间花在建堆期间和堆化数组，找数列中最大树只需要O(1)时间复杂度

void heap_sort(int *a, int length){
    // 建立堆 大根堆，递增排序
    heap_build(a,length);
    for (int i = length-1; i &amp;gt;0; --i)
    {
     //交换
     heap_swop(&amp;amp;a[0],&amp;amp;a[i]);
        //调整
     heap_adjust(a,i);
    }
}



推排序还可以用来求 top-K 大(小)的问题。

线性排序算法

上面的算法都是基于比较的排序，时间复杂度最好也是 NlogN.而非基于比较的排序，可以突破NlogN的时间下限。当然，非比较的排序，也是需要有一些限定条件的。

桶排序  bucket sort

比如给全校学生做个分数排序，最大分100分。我们使用一个100个空间的辅助数据，以key为分数，value为命中的次数。通过O(n)复杂度就可以完成排序任务。这种排序方式就是桶排序。

也就是分配一个hash[100]的空间，初始化为0,遍历一遍，出现的数字就hash[k]++,这样再次遍历一次，就可以得到n个数的顺序了。

###小结

常见的排序算法都是比较排序，比较排序的时间复杂度通常为 O(n^2) 或 O(nlogn)
但是如果带排序的数字有一些特俗性时，我们可以根据这来设计更加优化的排序算法。

</content>
      <categories>
        
          <category> Algorithms </category>
        
      </categories>
      <tags>
        
          <tag> Sort </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
