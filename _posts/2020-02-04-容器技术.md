---
title: 容器技术
categories:
- 容器
tags:
- Kubernetes
---


## Docker

- Docker 实际上只是一个使用 Cgroups 和 Namespace 实现的“沙盒”而已
  - 所谓 Docker 镜像，其实就是一个压缩包。
  - 大多数 Docker 镜像是直接由一个完整操作系统的所有文件和目录构成的，所以这个压缩包里的内容跟你本地开发和测试环境用的操作系统是完全一样的。
  - 这就是 Docker 镜像最厉害的地方：只要有这个压缩包在手，你就可以使用某种技术创建一个“沙盒”，在“沙盒”中解压这个压缩包，然后就可以运行你的程序了。
  - 容器时代，“编排”显然就是对 Docker 容器的一系列定义、配置和创建动作的管理







## 进程

- 对于进程来说，它的静态表现就是程序，平常都安安静静地待在磁盘上；而一旦运行起来，它就变成了计算机里的数据和状态的总和，这就是它的动态表现。
- 而容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。
  - Cgroups 技术是用来制造约束的主要手段，而Namespace 技术则是用来修改进程视图的主要方法。
  - 本来，每当我们在宿主机上运行了一个 /bin/sh 程序，操作系统都会给它分配一个进程编号，比如 PID=100。这个编号是进程的唯一标识，就像员工的工牌一样。
  - 而现在，我们要通过 Docker 把这个 /bin/sh 程序运行在一个容器当中。这时候，Docker 就会在这个第 100 号员工入职时给他施一个“障眼法”，让他永远看不到前面的其他 99 个员工，更看不到比尔 · 盖茨。这样，他就会错误地以为自己就是公司里的第 1 号员工。
  - 这种机制，其实就是对被隔离应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号，比如 PID=1。可实际上，他们在宿主机的操作系统里，还是原来的第 100 号进程。
  - 除了我们刚刚用到的 PID Namespace，Linux 操作系统还提供了 Mount、UTS、IPC、Network 和 User 这些 Namespace，用来对各种不同的进程上下文进行“障眼法”操作。
- 所以，Docker 容器这个听起来玄而又玄的概念，实际上是在创建容器进程时，指定了这个进程所需要启用的一组 Namespace 参数。这样，容器就只能“看”到当前 Namespace 所限定的资源、文件、设备、状态，或者配置。而对于宿主机以及其他不相关的程序，它就完全看不到了。
- 虚拟机和容器的对比图
  - Hypervisor
    - 通过硬件虚拟化功能，模拟出了运行一个操作系统需要的各种硬件，比如 CPU、内存、I/O 设备等等
    - 然后，它在这些虚拟的硬件上安装了一个新的操作系统，即 Guest OS。
  - Docker Engine
    - 把虚拟机的概念套在了容器上，这样的说法，并不严谨。
    - 在理解了 Namespace 的工作方式之后，你就会明白，跟真实存在的虚拟机不同，在使用Docker 的时候，并没有一个真正的“Docker 容器”运行在宿主机里面。Docker 项目帮助用户启动的，还是原来的应用进程，只不过在创建这些进程时，Docker 为它们加上了各种各样的Namespace 参数。
    - 这时，这些进程就会觉得自己是各自 PID Namespace 里的第 1 号进程，只能看到各自 Mount Namespace 里挂载的目录和文件，只能访问到各自 Network Namespace 里的网络设备，就仿佛运行在一个个“容器”里面，与世隔绝。





## 隔离与限制

- 真正对隔离环境负责的是宿主机操作系统本身：
  - 用户运行在容器里的应用进程，跟宿主机上的其他进程一样，都由宿主机操作系统统一管理，只不过这些被隔离的进程拥有额外设置过的 Namespace 参数。而 Docker 项目在这里扮演的角色，更多的是旁路式的辅助和管理工作。
  - “敏捷”和“高性能”是容器相较于虚拟机最大的优势，也是它能够在 PaaS 这种更细粒度的资源管理平台上大行其道的重要原因。
- 基于 Linux Namespace 的隔离机制相比于虚拟化技术也有很多不足之处，其中最主要的问题就是：隔离得不彻底
  - 既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。
  - 在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。
- 容器的“限制”问题
  - 还是以 PID Namespace 为例，虽然第 100 号进程表面上被隔离了起来，但是它所能够使用到的资源（比如 CPU、内存），却是可以随时被宿主机上的其他进程（或者其他容器）占用的，这些情况，显然都不是一个“沙盒”应该表现出来的合理行为。
  - 而Linux Cgroups 就是 Linux 内核中用来为进程设置资源限制的一个重要功能。
    - 它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。
    - 在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。
    - 在 /sys/fs/cgroup 下面有很多诸如 cpuset、cpu、 memory 这样的子目录，也叫子系统。这些都是我这台机器当前可以被 Cgroups 进行限制的资源种类。而在子系统对应的资源种类下，你就可以看到该类资源具体可以被限制的方法
    - Linux Cgroups 的设计还是比较易用的，简单粗暴地理解，它就是一个子系统目录加上一组资源限制文件的组合。
      - 而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录）
      - 然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。
- 容器本身的设计，就是希望容器和应用能够同生命周期，这个概念对后续的容器编排非常重要。否则，一旦出现类似于“容器是正常运行的，但是里面的应用早已经挂了”的情况，编排系统处理起来就非常麻烦了
- 另外，跟 Namespace 的情况类似，Cgroups 对资源的限制能力也有很多不完善的地方，被提及最多的自然是 /proc 文件系统的问题。
  - Linux 下的 /proc 目录存储的是记录当前内核运行状态的一系列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息
  - 你如果在容器里执行 top 指令，就会发现，它显示的信息居然是宿主机的 CPU 和内存数据，而不是当前容器的数据。
  - 造成这个问题的原因就是，/proc 文件系统并不知道用户通过 Cgroups 给这个容器做了什么样的资源限制，即：/proc 文件系统不了解 Cgroups 限制的存在。









## 容器镜像

- 容器里的进程看到的文件系统又是什么样子的呢
  - Mount Namespace 修改的，是容器进程对文件系统“挂载点”的认知。但是，这也就意味着，只有在“挂载”这个操作发生之后，进程的视图才会被改变。而在此之前，新创建的容器会直接继承宿主机的各个挂载点。
  - Mount Namespace ：它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。
  - 作为一个普通用户，我们希望的是一个更友好的情况：每当创建一个新容器时，我希望容器进程看到的文件系统就是一个独立的隔离环境，而不是继承自宿主机的文件系统。怎么才能做到这一点呢？
    - 在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成这个工作。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。
    - Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux操作系统里的第一个 Namespace。
- 这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。
  - rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。
  - 这也是容器相比于虚拟机的主要缺陷之一：毕竟后者不仅有模拟出来的硬件机器充当沙盒，而且每个沙盒里还运行着一个完整的 Guest OS 给应用随便折腾。
  - 不过，正是由于 rootfs 的存在，容器才有了一个被反复宣传至今的重要特性：一致性。
    - 由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。
    - 这就赋予了容器所谓的一致性：无论在本地、云端，还是在一台任何地方的机器上，用户只需要解压打包好的容器镜像，那么这个应用运行所需要的完整的执行环境就被重现出来了。
- 难道我每开发一个应用，或者升级一下现有的应用，都要重复制作一次 rootfs 吗？
  - Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。
  - 这个想法不是凭空臆造出来的，而是用到了一种叫作联合文件系统（Union File System）的能力。最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下
- Docker 镜像使用的rootfs，往往由多个“层”组成：
  - 第一部分，只读层。
    - ro+wh，即 readonly+whiteout
    - 可以看到，这些层，都以增量的方式分别包含了 Ubuntu/centos 操作系统的一部分。
  - 第二部分，Init 层。
    - 它是一个以“-init”结尾的层，夹在只读层和读写层之间。Init 层是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息。
    - 需要这样一层的原因是，这些文件本来属于只读的 Ubuntu 镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。
    - 可是，这些修改往往只对当前的容器有效，我们并不希望执行 docker commit 时，把这些信息连同可读写层一起提交掉。
    - 所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行docker commit 只会提交可读写层，所以是不包含这些内容的。
  - 第三部分，可读写层。
    - 专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里。
    - 如果我现在要做的，是删除只读层里的一个文件呢？
      - 为了实现这样的删除操作，AuFS 会在可读写层创建一个 whiteout 文件，把只读层里的文件“遮挡”起来。
  - 最终，这些层都被联合挂载到 /var/lib/docker/aufs/mnt 目录下，表现为一个完整的Ubuntu 操作系统供容器使用。







## 重新认识Docker容器

- Dockerfile使用一些标准的原语，描述我们所要构建的 Docker 镜像。并且这些原语，都是按顺序处理的。

- 容器技术使用了 rootfs 机制和 Mount Namespace，构建出了一个同宿主机完全隔离开的文件系统环境。

  - Volume 机制，允许你将宿主机上指定的目录或者文件，挂载到容器里面进行读取和修改操作。

  - > $ docker run -v /test ... 
    > $ docker run -v /home:/test ...
    > 在第一种情况下，由于你并没有显示声明宿主机目录，那么 Docker 就会默认在宿主机上创建一个临时目录 /var/lib/docker/volumes/[VOLUME_ID]/_data，然后把它挂载到容器的test 目录上。而在第二种情况下，Docker 就直接把宿主机的 /home 目录挂载到容器的 /test目录上。

- Docker 又是如何做到把一个宿主机上的目录或者文件，挂载到容器里面去呢

  - 当容器进程被创建之后，尽管开启了 Mount Namespace，但是在它执行 chroot（或者 pivot_root）之前，容器进程一直可以看到宿主机上的整个文件系统。
  - 宿主机上的文件系统，也自然包括了我们要使用的容器镜像
  - 这个镜像的各个层,在容器进程启动后，它们会被联合挂载在var/lib/docker/aufs/mnt/ 目录中,这样容器所需的 rootfs 就准备好了。
  - 所以，我们只需要在 rootfs 准备好之后，在执行 chroot 之前，把 Volume 指定的宿主机目录（比如 /home 目录），挂载到指定的容器目录（比如 /test 目录）在宿主机上对应的目录（即var/lib/docker/aufs/mnt/[可读写层 ID]/test）上，这个 Volume 的挂载工作就完成了。
  - 由于执行这个挂载操作时，“容器进程”已经创建了，也就意味着此时 MountNamespace 已经开启了。所以，这个挂载事件只在这个容器里可见。你在宿主机上，是看不见容器内部的这个挂载点的。这就保证了容器的隔离性不会被 Volume 打破
    - 这里提到的 " 容器进程 "，是 Docker 创建的一个容器初始化进程(dockerinit)，而不是应用进程 (ENTRYPOINT + CMD)。
    - dockerinit 会负责完成根目录的准备、挂载设备和目录、配置 hostname 等一系列需要在容器内进行的初始化操作
    - 最后，它通过 execv() 系统调用，让应用进程取代自己，成为容器里的 PID=1 的进程。

- 而这里要使用到的挂载技术，就是 Linux 的绑定挂载（Bind Mount）机制
  - 你在该挂载点上进行的任何操作，只是发生在被挂载的目录或者文件上，而原挂载点的内容则会被隐藏起来且不受影响。
  - 绑定挂载实际上是一个 inode 替换的过程。在Linux 操作系统中，inode 可以理解为存放文件内容的“对象”，而 dentry，也叫目录项，就是访问这个 inode 所使用的“指针”。
  - mount --bind /home /test，会将 /home 挂载到 /test 上。其实相当于将test 的 dentry，重定向到了 /home 的 inode。
    - 当我们修改 /test 目录时，实际修改的是home 目录的 inode。这也就是为何，一旦执行 umount 命令，/test 目录原先的内容就会恢复：因为修改真正发生在的，是 /home 目录里。
    - 可以成功地将一个宿主机上的目录或文件，不动声色地挂载到容器中。
    - 容器的镜像操作，比如 docker commit，都是发生在宿主机空间的。而由于 Mount Namespace 的隔离作用，宿主机并不知道这个绑定挂载的存在。所以，在宿主机看来，容器中可读写层的 /test 目录（/var/lib/docker/aufs/mnt/[可读写层ID]/test），始终是空的。
    - 由于 Docker 一开始还是要创建 /test 这个目录作为挂载点，所以执行了 docker commit 之后，你会发现新产生的镜像里，会多出来一个空的 /test 目录。







## Kubernetes的本质

- 一个正在运行的 Linux 容器，其实可以被“一分为二”地看待：
  - 一组联合挂载在 /var/lib/docker/aufs/mnt 上的 rootfs，这一部分我们称为“容器镜像”（Container Image），是容器的静态视图；
  - 一个由 Namespace+Cgroups 构成的隔离环境，这一部分我们称为“容器运行时”（Container Runtime），是容器的动态视图。
- 在整个“开发 - 测试 - 发布”的流程中，真正承载着容器信息进行传递的，是容器镜像，而不是容器运行时。
- Kubernetes 项目要解决的问题是什么？
  - 对于大多数用户来说，他们希望 Kubernetes 项目带来的体验是确定的：现在我有了应用的容器镜像，请帮我在一个给定的集群上把这个应用运行起来。
  - 更进一步地说，我还希望 Kubernetes 能给我提供路由网关、水平扩展、监控、备份、灾难恢复等一系列运维能力。
- Kubernetes 项目的架构
  -  Master 和 Node两种节点组成，而这两种角色分别对应着控制节点和计算节点。
  -  Master 节点由三个紧密协作的独立组件组合而成
    - 负责 API 服务的 kube-apiserver
    - 负责调度的 kube-scheduler
    - 以及负责容器编排的 kube-controller-manager。
    - 整个集群的持久化数据，则由 kube-apiserver 处理后保存在 Ectd 中。
  - 计算节点上最核心的部分，则是一个叫作 kubelet 的组件。
    - kubelet 主要负责同容器运行时（比如 Docker 项目）打交道。而这个交互所依赖的，是一个称作 CRI（Container Runtime Interface）的远程调用接口，这个接口定义了容器运行时的各项核心操作，比如：启动一个容器需要的所有参数。
      - 这也是为何，Kubernetes 项目并不关心你部署的是什么容器运行时、使用的什么技术实现，只要你的这个容器运行时能够运行标准的容器镜像，它就可以通过实现 CRI 接入到 Kubernetes 项目当中。
    - 具体的容器运行时，比如 Docker 项目，则一般通过 OCI 这个容器运行时规范同底层的 Linux 操作系统进行交互，即：把 CRI 请求翻译成对 Linux 操作系统的调用
    - 而kubelet 的另一个重要功能，则是调用网络插件和存储插件为容器配置网络和持久化存储。（CNI（Container Networking Interface）、CSI（Container Storage Interface））
    - kubelet 完全就是为了实现 Kubernetes 项目对容器的管理能力而重新实现的一个组件
  - 如何编排、管理、调度用户提交的作业？
    - 运行在大规模集群中的各种任务之间，实际上存在着各种各样的关系。这些关系的处理，才是作业编排和管理系统最困难的地方。
    - Kubernetes 项目对容器间的“访问”进行了分类，首先总结出了一类非常常见的“紧密交互”的关系，
      - Pod 是 Kubernetes 项目中最基础的一个对象
      - 在 Kubernetes 项目中，这些容器则会被划分为一个“Pod”，Pod 里的容器共享同一个 Network Namespace、同一组数据卷，从而达到高效率交换信息的目的。
- 围绕着容器和 Pod 不断向真实的技术场景扩展，我们就能够摸索出一幅以Kubernetes 项目核心功能的“全景图”。
  - 首先遇到了容器间“紧密协作”关系的难题，于是就扩展到了 Pod；
  - 有了 Pod 之后，我们希望能一次启动多个应用的实例，这样就需要Deployment 这个 Pod 的多实例管理器；
  - 而有了这样一组相同的 Pod 后，我们又需要通过一个固定的 IP 地址和端口以负载均衡的方式访问它，于是就有了 Service。
  - 如果现在两个不同 Pod 之间不仅有“访问关系”，还要求在发起时加上授权信息，Kubernetes 项目提供了一种叫作 Secret 的对象，它其实是一个保存在 Etcd 里的键值对数据
  - 除了应用与应用之间的关系外，应用运行的形态是影响“如何容器化这个应用”的第二个重要因素。
    - Kubernetes 定义了新的、基于 Pod 改进后的对象。比如 Job，用来描述一次性运行的Pod（比如，大数据任务）；
    - 再比如 DaemonSet，用来描述每个宿主机上必须且只能运行一个副本的守护进程服务；
    - 又比如 CronJob，则用于描述定时任务等等。
  - 相比之下，在 Kubernetes 项目中，我们所推崇的使用方法是：
    - 首先，通过一个“编排对象”，比如 Pod、Job、CronJob 等，来描述你试图管理的应用；
    - 然后，再为它定义一些“服务对象”，比如 Service、Secret、Horizontal Pod Autoscaler（自动水平扩展器）等。这些对象，会负责具体的平台级功能。
    - 这种使用方法，就是所谓的“声明式 API”。这种 API 对应的“编排对象”和“服务对象”，都是Kubernetes 项目中的 API 对象（API Object）。
    - 这就是 Kubernetes 最核心的设计理念
    - Kubernetes 项目所擅长的，是按照用户的意愿和整个系统的规则，完全自动化地处理好容器之间的各种关系。这种功能，就是我们经常听到的一个概念：编排。





