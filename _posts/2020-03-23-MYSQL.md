---
title: MYSQL（4）
categories:
- MYSQL
tags:
- MYSQL
---


## 如何判断一个数据库是不是出问题了

- select 1 判断
  - 通常情况下，我们建议把 innodb_thread_concurrency 设置为 64~128 之间的值
    - 实际上，在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙锁）的线程是不算在 128 里面的。
  - 在 show processlist 的结果里，看到的几千个连接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询。
    - 并发连接数达到几千个影响并不大，就是多占一些内存而已。我们应该关注的是并发查询，因为并发查询太高才是 CPU 杀手。
  - 同时在执行的语句超过了设置的 innodb_thread_concurrency 的值，这时候系统其实已经不行了，但是通过 select 1 来检测系统，会认为系统还是正常的。
- 查表判断
  - 为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问InnoDB 的场景。一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为health_check，里面只放一行数据，然后定期执行：
  - 空间满了以后，这种方法又会变得不好使
  - 我们知道，更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的。
- 更新判断
  - 节点可用性的检测都应该包含主库和备库。如果用更新来检测主库的话，那么备库也要进行更新检测。
    - 但，备库的检测也是要写 binlog 的。由于我们一般会把数据库 A 和 B 的主备关系设计为双 M 结构，所以在备库 B 上执行的检测命令，也要发回给主库 A。
    - 为了让主备之间的更新不产生冲突，我们可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键。
    - 由于 MySQL 规定了主库和备库的 server_id 必须不同（否则创建主备关系的时候就会报错），这样就可以保证主、备库各自的检测命令不会发生冲突。
  - 更新语句，如果失败或者超时，就可以发起主备切换了，为什么还会有判定慢的问题呢？
    - 你可以设想一个日志盘的 IO 利用率已经是 100% 的场景。这时候，整个系统响应非常慢，已经需要做主备切换了。
    - 但是你要知道，IO 利用率 100% 表示系统的 IO 是在工作的，每个请求都有机会获得 IO资源，执行自己的任务。而我们的检测使用的 update 命令，需要的资源很少，所以可能在拿到 IO 资源的时候就可以提交成功，并且在超时时间 N 秒未到达之前就返回给了检测系统。
    - 检测系统一看，update 命令没有超时，于是就得到了“系统正常”的结论。
    - 之所以会出现这个现象，根本原因是我们上面说的所有方法，都是基于外部检测的。外部检测天然有一个问题，就是随机性。
- 内部统计
  - MySQL 5.6 版本以后提供的 performance_schema 库，就在file_summary_by_event_name 表里统计了每次 IO 请求的时间。
  - file_summary_by_event_name 表里有很多行数据，我们先来看看event_name='wait/io/file/innodb/innodb_log_file’这一行。
    - 这一行表示统计的是 redo log 的写入时间
    - 第一组五列，是所有 IO 类型的统计
    - 第二组六列，是读操作的统计
    - 第三组六列，统计的是写操作。
    - 最后的第四组数据，是对其他类型数据的统计。在 redo log 里，你可以认为它们就是对fsync 的统计。
  - 在 performance_schema 库的 file_summary_by_event_name 表里，binlog 对应的是event_name = "wait/io/file/sql/binlog"这一行。各个字段的统计逻辑，与 redo log 的各个字段完全相同。
- 个人比较倾向的方案，是优先考虑 update 系统表，然后再配合增加检测performance_schema 的信息。







## 误删数据

- 误删行

  - 如果是使用 delete 语句误删了数据行，可以用 Flashback 工具通过闪回把数据恢复回来。
  - Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL
  - 我们不止要说误删数据的事后处理办法，更重要是要做到事前预防
    - 把 sql_safe_updates 参数设置为 on。这样一来，如果我们忘记在 delete 或者 update语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。
    - 代码上线前，必须经过 SQL 审计。
  - 使用 delete 命令删除的数据，你还可以用 Flashback 来恢复。而使用 truncate /drop table 和 drop database 命令删除的数据，就没办法通过 Flashback 来恢复了。为什么呢？
    - 这是因为，即使我们配置了 binlog_format=row，执行这三个命令时，记录的 binlog 还是 statement 格式。binlog 里面就只有一个 truncate/drop 语句，这些信息是恢复不出数据的。

- 误删库 / 表

  - 这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份 binlog

  - 假如有人中午 12 点误删了一个库，恢复数据的流程如下

    > 	1. 取最近一次全量备份，假设这个库是一天一备，上次备份是当天 0 点；
    >
    > 2. 用备份恢复出一个临时库；
    > 3. 从日志备份里面，取出凌晨 0 点之后的日志；
    > 4. 把这些日志，除了误删除数据的语句外，全部应用到临时库。

  - 为了加速数据恢复，如果这个临时库上有多个数据库，你可以在使用 mysqlbinlog 命令时，加上一个–database 参数，用来指定误删表所在的库。这样，就避免了在恢复数据时还要应用其他库日志的情况

  - 在应用日志的时候，需要跳过 12 点误操作的那个语句的 binlog：

    - 如果原实例没有使用 GTID 模式，只能在应用到包含 12 点的 binlog 文件的时候，先用–stop-position 参数执行到误操作之前的日志，然后再用–start-position 从误操作之后的日志继续执行；
    - 如果实例使用了 GTID 模式，就方便多了。假设误操作命令的 GTID 是 gtid1，那么只需要执行 set gtid_next=gtid1;begin;commit; 先把这个 GTID 加到临时实例的 GTID集合，之后按顺序执行 binlog 的时候，就会自动跳过误操作的语句。

  - 使用 mysqlbinlog 方法恢复数据还是不够快，主要原因有两个

    - 如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是mysqlbinlog 工具并不能指定只解析一个表的日志；
    - 用 mysqlbinlog 解析出日志应用，应用日志的过程就只能是单线程。

- 延迟复制备库

  - 延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。
  - 比如你把 N 设置为 3600，这就代表了如果主库上有数据被误删了，并且在 1 小时内发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行 stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据

  

  

  

  

  

## 查这么多数据，会不会把数据库内存打爆

- 全表扫描对 server 层的影响

  - 取数据和发数据的流程是这样的：

    - > ​	获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。
      > ​	重复获取行，直到 net_buffer 写满，调用网络接口发出去。
      > ​	如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。
      > ​	如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。

  - 也就是说，MySQL 是“边读边发的”，这个概念很重要。这就意味着，如果客户端接收得慢，会导致 MySQL 服务端由于结果发不出去，这个事务的执行时间变长。

    - 仅当一个线程处于“等待客户端接收结果”的状态，才会显示"Sending toclient"；而如果显示成“Sending data”，它的意思只是“正在执行”。

  - 现在你知道了，查询的结果是分段发给客户端的，因此扫描全表，查询返回大量的数据，并不会把内存打爆。

- 全表扫描对 InnoDB 的影响

  - 内存的数据页是在 Buffer Pool (BP) 中管理的，在 WAL 里 Buffer Pool 起到了加速更新的作用。而实际上，Buffer Pool 还有一个更重要的作用，就是加速查询。
    - InnoDB Buffer Pool 的大小是由参数 innodb_buffer_pool_size 确定的，一般建议设置成可用物理内存的 60%~80%。
  - InnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。
    - 在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域
    - 处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：
      - 存在的时间超过了 1 秒，就把它移动到链表头部；
      - 存在的时间短于 1 秒，位置保持不变
      - 1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。
  - 可以看到，这个策略最大的收益，就是在扫描这个大表的过程中，虽然也用到了 BufferPool，但是对 young 区域完全没有影响，从而保证了 Buffer Pool 响应正常业务的查询命中率。
    - Buffer Pool 对查询的加速效果，依赖于一个重要的指标，即：内存命中率。你可以在 show engine innodb status 结果中，查看一个系统当前的 BP 命中率	
    - “Buffer pool hit rate”字样，显示的就是当前的命中率

- “长事务”

  - 如果前面的语句有更新，意味着它们在占用着行锁，会导致别的语句更新被锁住；
  - 读的事务也有问题，会导致 undo log 不能被回收，导致回滚段空间膨胀。







## join

- 如果有两个大小不同的表做 join，应该用哪个表做驱动表呢？

  -  t2 里插入了 1000 行数据，在 t1 里插入的是 100 行数据。
  - 两个表都有一个主键索引 id 和一个索引 a，字段 b 上无索引

- Index Nested-Loop Join

  - > select * from t1 straight_join t2 on (t1.a=t2.a);
    >
    > 对驱动表 t1 做了全表扫描，扫描 100 行
    > 对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行；
    > 整个执行流程，总扫描行数是 200。

  - 怎么选择驱动表

    - 在这个 join 语句执行过程中，驱动表是走全表扫描，而被驱动表是走树搜索。

- Simple Nested-Loop Join

  - > select * from t1 straight_join t2 on (t1.a=t2.b);
    > 由于表 t2 的字段 b 上没有索引，因此每次到 t2 去匹配的时候，就要做一次全表扫描。

- Block Nested-Loop Join

  - 这时候，被驱动表上没有可用的索引，算法的流程是这样的

    - 把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；

    - 扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。

  - 在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是1100。由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做100 次判断，总共需要在内存中做的判断次数是：100*1000=10 万次。

    - 如果使用 Simple Nested-Loop Join 算法进行查询，扫描行数也是 10 万行。因此，从时间复杂度上来说，这两个算法是一样的。但是，Block Nested-Loop Join算法的这 10 万次判断是内存操作，速度上会快很多，性能也更好。

  - join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1的所有数据话，策略很简单，就是分段放

    - >  扫描表 t1，顺序读取数据行放入 join_buffer 中，join_buffer 满了，继续第 2 步；
      >  扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分
      > 清空 join_buffer；
      > 继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。
      > 这个流程才体现出了这个算法名字中“Block”的由来，表示“分块去 join”







## join语句优化

- Multi-Range Read 优化

  - Multi-RangeRead 优化 (MRR)。这个优化的主要目的是尽量使用顺序读盘。

  - 回表过程是一行行地查数据，还是批量地查数据？

    - 主键索引是一棵 B+ 树，在这棵树上，每次只能根据一个主键 id 查到一行数据。因此，回表肯定是一行行搜索主键索引的
    - 如果随着 a 的值递增顺序查询的话，id 的值就变成随机的，那么就会出现随机访问，性能相对较差。虽然“按行查”这个机制不能改，但是调整查询的顺序，还是能够加速的
    - 我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能
    - 这，就是 MRR 优化的设计思路

  - 执行流程

    - > 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;
      > 将 read_rnd_buffer 中的 id 进行递增排序；
      > 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。

- BNL 算法的性能问题

  - BNL 算法对系统的影响主要包括三个方面
    - 可能会多次扫描被驱动表，占用磁盘 IO 资源；
    - 判断 join 条件需要执行 M*N 次对比（M、N 分别是两张表的行数），如果是大表就会占用非常多的 CPU 资源；

    - 可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率。
      - 如果一个使用 BNL 算法的 join 语句，多次扫描一个冷表，而且这个语句执行时间超过 1 秒，就会在再次扫描冷表的时候，把冷表的数据页移到 LRU 链表头部。
        - 这种情况对应的，是冷表的数据量小于整个 Buffer Pool 的 3/8，能够完全放入 old 区域的情况。
      - 如果这个冷表很大，就会出现另外一种情况：业务正常访问的数据页，没有机会进入young 区域。
        - 由于我们的 join 语句在循环读磁盘和淘汰内存页，进入 old 区域的数据页，很可能在 1 秒之内就被淘汰了。这样，就会导致这个 MySQL 实例的 Buffer Pool 在这段时间内，young 区域的数据页没有被合理地淘汰。
  - 如果确认优化器会使用 BNL 算法，就需要做优化。优化的常见做法是，给被驱动表的 join 字段加上索引，把 BNL 算法转成 BKA 算法。

- Batched Key Access

  - MySQL 在 5.6 版本后开始引入的 BatchedKey Access(BKA) 算法了。这个 BKA 算法，其实就是对 NLJ 算法的优化。

  - 把表 t1 的数据取出来一部分，先放到一个临时内存。这个临时内存就是 join_buffer。

  - > 如果要使用 BKA 优化算法的话，你需要在执行 SQL 语句之前，先设置
    > 	set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
    > 	其中，前两个参数的作用是要启用 MRR。这么做的原因是，BKA 算法的优化要依赖于MRR。

- BNL 转 BKA

  - 一些情况下，我们可以直接在被驱动表上建索引，这时就可以直接转成 BKA 算法了

    - 有时候你确实会碰到一些不适合在被驱动表上建索引的情况

  - > 考虑使用临时表。使用临时表的大致思路是：
    > 	把表 t2 中满足条件的数据放在临时表 tmp_t 中；
    > 	为了让 join 使用 BKA 算法，给临时表 tmp_t 的字段 b 加上索引；
    > 	让表 t1 和 tmp_t 做 join 操作。

  - 不论是在原表上加索引，还是用有索引的临时表，我们的思路都是让 join 语句能够用上被驱动表上的索引，来触发 BKA 算法，提升查询性能。

  - 使用 BKA 算法的时候，并不是“先计算两个表 join 的结果，再跟第三个表 join”，而是直接嵌套查询的。













































