---
title: 计算机网络基础知识（2）
categories:
- 计算机网络
tags:
- Web
---

# Network



## ARP

（ARP地址解析协议,  RARP反向地址解析协议），我们习惯上把它们认为是链路层的协议，实际上，从分层的角度来看，更准确的说是，（应该是一种介于网络IP层与链路层之间的一种协议）

我们知道在ISO/OSI模型中，数据在传输的过程中，有不断封装过程，到了链路层的话(以太网传输)，在以太网的帧格式中会出现目的主机的MAC地址，但是我们从一开始就只知道目的主机的IP地址，所以这里用到了ARP协议

源主机先在自己的ARP缓冲区中寻找映射，如果有（直接填充于以太网帧中），如果没有，通过路由广播请求，这时一些联网的主机就会收到这个请求，并将这个请求传回网络层，对比IP地址，检验是否可以接受，如果不行，则直接丢失这个信息，如果可以那么回复ARP请求，并且将源主机的MAC地址加入到目的ARP缓冲区中，形成映射，源主机接受到请求后，将目的的MAC地址加入到ARP缓冲区，也形成映射，并将mac地址传输至连接层。此时转化完成

![img](https://img-blog.csdn.net/20160219211855357?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

**什么是ARP欺骗**

举个栗子：

| 主机 |     IP      |        MAC        |
| :--: | :---------: | :---------------: |
|  A   | 192.168.1.1 | 0A-11-22-33-44-01 |
|  B   | 192.168.1.2 | 0A-11-22-33-44-02 |
|  C   | 192.168.1.3 | 0A-11-22-33-44-03 |

> 1.主机A要和主机C通信，主机A发出ARP包询问谁是192.168.1.3?请回复192.168.1.1
>
> 2.这时主机B在疯狂的向主机A回复，我是192.168.1.3，我的地址是0A-11-22-33-44-02
>
> 3.由于ARP协议不会验证回复者的身份，造成主机A错误的将192.168.1.3的MAC映射为0A-11-22-33-44-02。

**ARP欺骗的分类**

> 1.主机欺骗，如同上面的栗子，主机B欺骗局域网中的主机A。
>
> 2.网关欺骗，局域网中的主机欺骗网关，从而获取其他主机的进流量。

**如何防御ARP欺骗**

ARP欺骗是通过重复应答实现的，那么只需要在本机添加一条静态的ARP映射，这样就不需要询问网关MAC地址了，这种方法只对主机欺骗有效。对于网关欺骗还需要在网关中也添加一条到主机的静态ARP映射。1.用管理身份运行命令提示符；输入netsh i i show in，查看一下本机有哪些网络连接

```
netsh i i show in
```

2.查看一下网关的MAC地址。注意如果正遭受ARP欺骗攻击，通过此方法查处的可能是虚假的MAC地址。输入arp -a命令查询本机的arp映射表，如果找不到网关的信息，可以先ping一下网关。

3.输入：netsh -c "i i" add neighbors 连接的Idx号 网关IP 网关MAC 添加一条静态映射,我已经添加过了，所以会显示 对象已存在

```
netsh -c "i i" add neighbors 连接的Idx号 网关IP 网关MAC
netsh -c "i i" add neighbors 9 10.60.12.1 4c-5e-0c-64-73-f5
```



## DNS

以访问知乎([http://www.zhihu.com](http://www.zhihu.com/))为例：

第一步：通过你的电脑系统的浏览器去访问[http://www.zhihu.com](http://www.zhihu.com/)，首先会去检査本机的 Hosts是否有URL映射关系，如果有，则进行映射完成域名解析！

第二步：如果没有，就从本地的DNS缓存里找映射关系，如果有，则进行映射完成解析！

第三步：如果前两者都没有找到，则将该请求发送到你的路由器（记住：路由器也有缓存)，此时你的ISP会询问根域名服务器（1.1.1.1 ): “我想访问一个.com后缀的域名”

第四步：这个时候根域名服务器上会找到.com域名服务器（比如你的域名注册商上NameCheap)，则会告诉你：试试（2.2.2.2)，接下来会通过（2.2.2.2)进一步在域名服务器上寻找[http://www.zhihu.com](http://www.zhihu.com/)，当找到域名服务器后，就到达DNS解析服务。比如例子里的域名服务商是（NameCheap)的，但是你不一定会使用NameCheap自带的DNS服务。比如图解里你的DNS可以使用其它的DNS服务商：Amazon S3、DNSMadeEasy、 NSOne 的

第五步：找到对应域名的DNS服务商后，即可最终返回给到你的电脑浏览器上，正常打开知乎（[http://www.zhihu.com](http://www.zhihu.com/))。

![img](https://pic2.zhimg.com/80/v2-ecef93d5119289285a42c295b8f0bac9_1440w.jpg?source=1940ef5c)

- 层次树状结构的联机分布式数据库系统
  - 产生于应用层上的域名系统 NDS就可以用来把互联网上的主机名转换成 IP 地址
  - 把待解析的域名放在 DNS 的请求报中，以 UDP 用户数据报方式发送给本地域名服务器。本地域名服务器在查找域名后，把对应的 IP 地址放在回答报文中返回。获得 IP 地址的后主机即可进行通信
- 域名解析过程
  - 域名解析过程
    - 本地域名服务器向根域名服务器的查询方式通常采取迭代查询
  - 递归查询
    - 主机向本地域名服务器的查询一般都采用递归查询



**DNS劫持 vs HTTP劫持**

开始正式介绍DNS劫持之前，先与HTTP劫持做一个比较，可能有助于有些同学对下文更容易理解更深入一点。

DNS劫持现象：你输入一个google.com网址，出来的是百度的页面

HTTP劫持现象：访问着github的页面，右下角出现了一个格格不入的广告弹窗

在dns解析过程中，有哪一环节出现问题的话，都可能会导致DNS解析错误，导致客户端（浏览器）得到一个假的ip地址，从而引导用户访问到这个冒名顶替，恶意的网站。

**下面大概说几种DNS劫持方法**

**1.本机DNS劫持**

攻击者通过某些手段使用户的计算机感染上木马病毒，或者恶意软件之后，恶意修改本地DNS配置，比如修改本地hosts文件，缓存等

**2. 路由DNS劫持**

很多用户默认路由器的默认密码，攻击者可以侵入到路由管理员账号中，修改路由器的默认配置

**3.攻击DNS服务器**

直接攻击DNS服务器，例如对DNS服务器进行DDOS攻击，可以是DNS服务器宕机，出现异常请求，还可以利用某些手段感染dns服务器的缓存，使给用户返回来的是恶意的ip地址

**2.DNS的防范**

> 就这上面的劫持方法，说几种方法手段

1.加强本地计算机病毒检查，开启防火墙等，防止恶意软件，木马病毒感染计算机

2.改变路由器默认密码，防止攻击者修改路由器的DNS配置指向恶意的DNS服务器

3.企业的话可以准备两个以上的域名，一旦一个域名挂掉，还可以使用另一个

4.用HTTP DNS 代替 Local DNS

> 对于DNS劫持，往往单靠个人设置很难解决，如果已经出现了劫持现象的话，对电脑进去杀毒，清理，检查hosts文件，核查网络设置的DNS配置（可以使用写公共的DNS服务器





## CDN

- 内容分发网络，解决的是如何将数据快速可靠从源站传递到用户

- 数据从服务器端交付到用户端，至少有4个地方可能会造成网络拥堵

  - 网站服务器接入互联网的链路
  - 用户接入互联网的链路
  - ISP互联，即因特网服务提供商之间的互联
  - 长距离传输时延问题

- 基本过程

  - 用户在浏览器中输入要访问的域名。 

  2. 浏览器向DNS服务器请求对域名进行解析。由于CDN对域名解析进行了调整，DNS服务器会最终将域名的解析权交给CDN专用DNS服务器。 
  3. CDN的DNS服务器将CDN的负载均衡设备IP地址返回给用户。 
  4. 用户向CDN的负载均衡设备发起内容URL访问请求。 

  - CDN负载均衡设备会为用户选择一台合适的缓存服务器提供服务。 
    5. 选择的依据包括：根据用户IP地址，判断哪一台服务器距离用户最近；根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需内容；查询各个服务器的负载情况，判断哪一台服务器的负载较小。 

  5. 用户向缓存服务器发出请求。
  6. 缓存服务器响应用户请求，将用户所需内容传送到用户。

7. CDN的工作原理：通过权威DNS服务器来实现最优节点的选择，通过缓存来减少源站的压力





## HTTP

- HTTP幂等性
  - 幂等性是数学中的一个概念，表达的是N次变换与1次变换的结果相同
  - HTTP POST和PUT，二者均可用于创建资源，更为本质的差别是在幂等性方面
    - POST所对应的URI并非创建的资源本身，而是资源的接收者
      - 两次相同的POST请求会在服务器端创建两份资源，它们具有不同的URI；所以，POST方法不具备幂等性
    - PUT所对应的URI是要创建或更新的资源本身
      - 对同一URI进行多次PUT的副作用和一次PUT是相同的；因此，PUT方法具有幂等性
- HTTP协议的瓶颈及其优化技巧都是基于TCP协议本身的特性
  - 三次握手有1.5个RTT（round-trip time）的延迟
  - 不同策略的http长链接方案
    - HTTP的长连接和短连接本质上是TCP长连接和短连接
  - TCP在建立连接的初期有慢启动
- http和socket长连接和短连接区别
  - Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口
  - 门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议
- HTTP2.0
  - HTTP1.x有以下几个主要缺点：
    - 一次只允许在一个TCP连接上发起一个请求
    - HTTP/1.1使用的流水线技术也只能部分处理请求并发，仍然会存在队列头阻塞问题，因此客户端在需要发起多次请求时，通常会采用建立多连接来减少延迟。
    - 单向请求，只能由客户端发起。
    - 请求报文与响应报文首部信息冗余量大。
    - 数据未压缩，导致数据的传输量大。
  - 多路复用 (Multiplexing)
    - 所谓多路复用，即在一个TCP连接中存在多个流
    - HTTP/2 通信都在一个连接上完成，这个连接可以承载任意数量的双向数据流。在过去， HTTP 性能优化的关键并不在于高带宽，而是低延迟
  - 二进制分帧
    - 很容易的去实现多流并行而不用依赖建立多个 TCP 连接，HTTP/2 把 HTTP 协议通信的基本单位缩小为一个一个的帧
    - HTTP2.0中，有两个概念非常重要：帧（frame）和流（stream）。
      帧是最小的数据单位，每个帧会标识出该帧属于哪个流，流是多个帧组成的数据流。
  - 首部压缩（Header Compression）
  - 服务端推送（Server Push）
- 哈希算法
  - 将任意长度的信息转换为较短的固定长度的值，通常其长度要比信息小得多，且算法不可逆。







## GET/POST

- 区别
  - GET请求在URL中传送的参数是有长度限制的，而POST没有。
    - 对于一个字节流的解析，必须分配buffer来保存所有要存储的数据。而URL这种东西必须当作一个整体看待，无法一块一块处理，于是就处理一个URL请求时必须分配一整块足够大的内存
  - 最直观的区别就是GET把参数包含在URL中，POST通过request body传递参数
  - GET和POST本质上没有区别
    - HTTP是基于TCP/IP的关于数据如何在万维网中如何通信的协议
    - HTTP只是个行为准则，而TCP才是GET和POST怎么实现的基本
    - GET和POST的底层也是TCP/IP，GET/POST都是TCP链接
    - GET产生一个TCP数据包；POST产生两个TCP数据包
  - 从攻击的角度，无论是GET还是POST都不够安全
    - HTTP本身是明文协议。每个HTTP请求和返回的每个byte都会在网络上传播，不管是url，header还是body
- ElasticSearch的_search接口使用GET，却用body来表达查询，因为查询很复杂





## RestTemplate

- RestTemplate能大幅简化了提交表单数据的难度，并且附带了自动转换JSON数据的功能

  | HTTP method | RestTemplate methods |
  | :---------- | :------------------- |
  | DELETE      | delete               |
  | GET         | getForObject         |
  |             | getForEntity         |
  | HEAD        | headForHeaders       |
  | OPTIONS     | optionsForAllow      |
  | POST        | postForLocation      |
  |             | postForObject        |
  | PUT         | put                  |
  | any         | exchange             |
  |             | execute              |

- 手动指定转换器(HttpMessageConverter)

  - 调用reseful接口传递的数据内容是json格式的字符串，返回的响应也是json格式的字符串
  - restTemplate.postForObject方法的请求参数RequestBean和返回参数ResponseBean都是java类。是RestTemplate通过HttpMessageConverter自动帮我们做了转换的操作
    - StringHttpMessageConverter来处text/plain;
    - MappingJackson2HttpMessageConverter来处理application/json;
    - MappingJackson2XmlHttpMessageConverter来处理application/xml

- RestTemplate直接使用一个HttpClient作为底层实现

- 设置拦截器(ClientHttpRequestInterceptor)

  - ```java
    // 1.实现ClientHttpRequestInterceptor接口
    
    
    RestTemplate restTemplate = new RestTemplate();
    // 2.向restTemplate中添加自定义的拦截器
    restTemplate.getInterceptors().add(new TokenInterceptor());
    ```

- getForObject()其实比getForEntity()多包含了将HTTP转成POJO的功能，但是getForObject没有处理response的能力。因为它拿到手的就是成型的pojo。省略了很多response的信息

- postForEntity

  - ```java
    // httpEntity
    HttpEntity<MultiValueMap<String, String>> request = new HttpEntity<>(map, headers);
    ResponseEntity<String> response = restTemplate.postForEntity( url, request , String.class );
    
    // MultiValueMap是Map的一个子类，它的一个key可以存储多个value
    
    // 为什么用MultiValueMap?因为HttpEntity接受的request类型是它
    
    // 为什么用HttpEntity是因为restTemplate.postForEntity方法虽然表面上接收的request是@Nullable Object request类型，但是你追踪下去会发现这个request是用HttpEntity来解析
    ```

- 使用exchange指定调用方式

  ```java
  HttpEntity<String> entity = new HttpEntity<>(jsonObj.toString(), headers);
  ResponseEntity<JSONObject> exchange = restTemplate.exchange(url,HttpMethod.GET, entity, JSONObject.class);
  ```







# Session&Cookie



## 概念

- HTTP协议是无状态的协议。一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。这就意味着服务器无法从连接上跟踪会话
  - 会话，指用户登录网站后的一系列动作
  - 常用的会话跟踪技术 是Cookie与Session
  - Cookie通过在客户端记录信息确定用户身份，Session通过在服务器端记录信息确定用户身份





## Cookie

- cookie的内容主要包括：名字，值，过期时间，路径和域。路径与域一起构成cookie的作用范围
  - 如果我们想让 www.china.com能够访问bbs.china.com设置的cookies，该怎么办? 我们可以把domain属性设置成“china.com”，并把path属性设置成“/”
- Cookie具有不可跨域名性



## Session

- 用户与服务器建立连接的同时，服务器会自动为其分配一个SessionId
- HttpSession是Servlet三大域对象之一（request、session、application（ServletContext））
- 禁用cookie
  - URL重写，就是把sessionId直接附加在URL路径的后面
    - 使用Response.encodeURL则可以直接得到路径+jsessionid的全部url路径，不需要自己手动拼接字符串了。然后将这个url返回给客户端，用户通过一个链接点击(通过refresh来刷新，再次访问本页面效果如下图)
  - 表单隐藏字段。就是服务器会自动修改表单，添加一个隐藏字段，以便在表单提交时能够把session id传递回服务器





## JWT

- 轻量级的认证规范，这个规范允许我们使用JWT在用户和服务器之间传递安全可靠的信息

- 整个 jwt 串会被置于 http 的 Header 或者 url 中

- 在 jwt 中以.分割三个部分

  - 一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名
  - jwt的第三部分是一个签名信息，这个签名信息由三部分组成：	
    - header (base64后的)
    - payload (base64后的)
    - secret	
    - 通过header中声明的加密方式进行加密

- jwt token泄露了怎么办

  - https
  - 返回 jwt 给客户端时设置 httpOnly=true 并且使用 cookie 而不是 LocalStorage 存储 jwt，这样可以防止 XSS 攻击和 CSRF 攻击

- 我们使用JWT的初衷就在于，我们可以不用通过读取状态来得知请求者的一些信息，因为JWT中自带了一些不敏感的信息，比如用户Id，权限列表，而且JWT不可伪造，所以我们直接通过解析JWT就能够知道一些原本需要从数据库/缓存里读取的数据。

  - 如果每一个请求到来的时候都要去读取状态并检测这个JWT是否有效，那么就和使用JWT的初衷相违背了，这是自相矛盾的。如果我都要去读取数据库和缓存了，那我为什么还要用JWT呢？为什么不直接给一个随机的字符串ID（比如SessionId），然后每次请求到来的时候通过这个Id取出当前的请求者信息不就完了？

- jwt 的特性天然不支持续签

  - 因为 payload 是参与签名的，一旦过期时间被修改，整个 jwt 串就变了

- jwt 不仅仅是作为身份认证，还在其 payload 中存储着会话信息，这是 jwt 和 session 的最大区别

- 什么场景该适合使用jwt？

  - 一次性验证，用户注册后需要发一封邮件让其激活账户
  - 单点登录系统
  - restful api 的无状态认证
    - JWT是自我校验的，所以是无状态的。JWT在客户端是不能做任何操作的，只有客户端发送请求时附带token，然后由服务端解析JWT后做自我校验
    - 服务端无需存储jwt令牌，通过特定的算法和密钥校验token，同时取出Payload中携带的用户ID，减少不必要的数据库查询

- 用户认证

  - 所谓用户认证（Authentication），就是让用户登录，并且在接下来的一段时间内让用户访问网站时可以使用其账户，而不需要再次登录的机制。

    > 小知识：可别把用户认证和用户授权（Authorization）搞混了。用户授权指的是规定并允许用户使用自己的权限，例如发布帖子、管理站点等。

    首先，服务器应用（下面简称“应用”）让用户通过 Web 表单将自己的用户名和密码发送到服务器的接口。这一过程一般是一个 HTTP POST 请求。建议的方式是通过 SSL 加密的传输（https 协议），从而避免敏感信息被嗅探。

    [![auth1](https://kirito.iocoder.cn/jwtauth1.png)](https://kirito.iocoder.cn/jwtauth1.png)auth1

    接下来，应用和数据库核对用户名和密码。

    [![auth2](https://kirito.iocoder.cn/jwtauth2.png)](https://kirito.iocoder.cn/jwtauth2.png)auth2

    核对用户名和密码成功后，应用将用户的 `id`（图中的 `user_id`）作为 JWT Payload 的一个属性，将其与头部分别进行 Base64 编码拼接后签名，形成一个 JWT。这里的 JWT 就是一个形同 `lll.zzz.xxx` 的字符串。

    [![auth3](https://kirito.iocoder.cn/jwtauth3.png)](https://kirito.iocoder.cn/jwtauth3.png)auth3

    应用将 JWT 字符串作为该请求 Cookie 的一部分返回给用户。注意，在这里必须使用 `HttpOnly` 属性来防止 Cookie 被 JavaScript 读取，从而避免 [跨站脚本攻击（XSS 攻击）](http://www.cnblogs.com/bangerlee/archive/2013/04/06/3002142.html)。

    [![auth4](https://kirito.iocoder.cn/jwtauth4.png)](https://kirito.iocoder.cn/jwtauth4.png)auth4

    在 Cookie 失效或者被删除前，用户每次访问应用，应用都会接受到含有 `jwt` 的 Cookie。从而应用就可以将 JWT 从请求中提取出来。

    [![auth5](https://kirito.iocoder.cn/jwtauth5.png)](https://kirito.iocoder.cn/jwtauth5.png)auth5

    应用通过一系列任务检查 JWT 的有效性。例如，检查签名是否正确；检查 Token 是否过期；检查 Token 的接收方是否是自己（可选）。

    [![auth6](https://kirito.iocoder.cn/jwtauth6.png)](https://kirito.iocoder.cn/jwtauth6.png)auth6

    应用在确认 JWT 有效之后，JWT 进行 Base64 解码（可能在上一步中已经完成），然后在 Payload 中读取用户的 id 值，也就是 `user_id` 属性。这里用户的 `id` 为 1025。

    应用从数据库取到 `id` 为 1025 的用户的信息，加载到内存中，进行 ORM 之类的一系列底层逻辑初始化。

    [![auth7](https://kirito.iocoder.cn/jwtauth7.png)](https://kirito.iocoder.cn/jwtauth7.png)auth7

    应用根据用户请求进行响应。

    [![auth8](https://kirito.iocoder.cn/jwtauth8.png)](https://kirito.iocoder.cn/jwtauth8.png)auth8

    ### 和 Session 方式存储 id 的差异

    Session 方式存储用户 id 的最大弊病在于要占用大量服务器内存，对于较大型应用而言可能还要保存许多的状态。一般而言，大型应用还需要借助一些 KV 数据库和一系列缓存机制来实现 Session 的存储。

    而 JWT 方式将用户状态分散到了客户端中，可以明显减轻服务端的内存压力。除了用户 id 之外，还可以存储其他的和用户相关的信息，例如该用户是否是管理员、用户所在的分桶（见 [《你所应该知道的 A/B 测试基础》一文] 等。

    虽说 JWT 方式让服务器有一些计算压力（例如加密、编码和解码），但是这些压力相比磁盘 I/O 而言或许是半斤八两。具体是否采用，需要在不同场景下用数据说话。

    ### 单点登录

    Session 方式来存储用户 id，一开始用户的 Session 只会存储在一台服务器上。对于有多个子域名的站点，每个子域名至少会对应一台不同的服务器，例如：

    - [www.taobao.com](http://www.taobao.com/)
    - nv.taobao.com
    - nz.taobao.com
    - login.taobao.com

    所以如果要实现在 `login.taobao.com` 登录后，在其他的子域名下依然可以取到 Session，这要求我们在多台服务器上同步 Session。

    使用 JWT 的方式则没有这个问题的存在，因为用户的状态已经被传送到了客户端。因此，我们只需要将含有 JWT 的 Cookie 的 `domain` 设置为顶级域名即可，例如

    ```
    Set-Cookie: jwt=lll.zzz.xxx; HttpOnly; max-age=980000; domain=.taobao.com
    ```

    注意 `domain` 必须设置为一个点加顶级域名，即 `.taobao.com`。这样，taobao.com 和 *.taobao.com 就都可以接受到这个 Cookie，并获取 JWT 了。



## jwt session

- http 无状态，所以为了实现有状态 http，才有了会话（session）的概念。
  - 会话(Session)是一个客户与服务器之间的不中断的请求响应序列。对客户的每个请求，服务器能够识别出请求来自于同一个客户。当一个未知的客户向Web应用程序发送第一个请求时就开始了一个会话。当客户明确结束会话或服务器在一个预定义的时限内不从客户接受任何请求时，会话就结束了。当会话结束后，服务器就忘记了客户以及客户的请求。
- 不管是“session id”，还是所谓“token”(如 jwt)，其实都是会话的一种实现方式。形式上“session id”和“token”都是“字符串”，这个“字符串”可以是任意的编码，本质上都是 credential（会话凭证）。
- 在各种 session 方案中，你会发现实现细节都不一样，flask session, django session, spring session, jwt 等等。但万变不离其宗， credential 的客户端保存方式，credential 的传输方式和会话信息的保存方式，都只是这几个流程的细节有改变而已，本质都是为了实现有状态的 http。

## OAuth2.0是什么

#### OAuth2.0是什么——豆瓣和QQ的故事

OAuth简单说就是一种授权的**协议**，只要授权方和被授权方遵守这个协议去写代码提供服务，那双方就是实现了OAuth模式。

举个例子，你想登录豆瓣去看看电影评论，但你丫的从来没注册过豆瓣账号，又不想新注册一个再使用豆瓣，怎么办呢？不用担心，豆瓣已经为你这种懒人做了准备，用你的qq号可以授权给豆瓣进行登录，请看。

**第一步：在豆瓣官网点击用qq登录**

**![img](https://images2017.cnblogs.com/blog/1096103/201708/1096103-20170824150221230-104373567.png)**

**第二步：跳转到qq登录页面输入用户名密码，然后点授权并登录**

 ![img](https://images2017.cnblogs.com/blog/1096103/201708/1096103-20170824151117089-994331290.png)

**第三步：跳回到豆瓣页面，成功登录**

![img](https://images2017.cnblogs.com/blog/1096103/201708/1096103-20170824151220418-2113396046.png)

 这几秒钟之内发生的事情，在**无知的用户视角**看来，就是在豆瓣官网上输了个qq号和密码就登录成功了。在一些**细心的用户视角**看来，页面经历了从豆瓣到qq，再从qq到豆瓣的两次页面跳转。但作为一群专业的程序员，我们还应该从**上帝视角**来看这个过程。

#### OAuth2.0是什么——上帝视角

　　简单来说，上述例子中的豆瓣就是**客户端**，QQ就是**认证服务器**，OAuth2.0就是客户端和认证服务器之间由于相互**不信任**而产生的一个**授权协议**。呵呵，要是相互信任那QQ直接把自己数据库给豆瓣好了，你直接在豆瓣输入qq账号密码查下数据库验证就登陆呗，还跳来跳去的多麻烦。

　　先上一张图，该图描绘了只几秒钟发生的所有事情用**上帝视角**来看的流程

![img](https://images2017.cnblogs.com/blog/1096103/201708/1096103-20170824142737402-1297004164.png)

 就这这张图，来说一下上述例子中的三个步骤在图中的表现。所用到的请求路径名称都是虚构的，所附带的请求参数忽略了一些非重点的。

如想了解每次的请求和响应的标准齐全的参数，还是去读那篇阮一峰的文章。http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html

**第一步：在豆瓣官网点击用qq登录**

　　当你点击用qq登录的小图标时，实际上是向豆瓣的服务器发起了一个 http://www.douban.com/leadToAuthorize 的请求，豆瓣服务器会响应一个**重定向地址**，指向qq授权登录

　　浏览器接到重定向地址 http://www.qq.com/authorize?callback=www.douban.com/callback ，再次访问。并注意到这次访问带了一个参数是callback，以便qq那边授权成功再次让浏览器发起这个callback请求。不然qq怎么知道你让我授权后要返回那个页面啊，每天让我授权的像豆瓣这样的网站这么多。

　　至于访问这个地址之后，qq那边做出怎样的回应，就是第二步的事情了。总之第一步即对应了图中的这些部分。

![img](https://images2017.cnblogs.com/blog/1096103/201708/1096103-20170824155817777-2073704717.png)

**第二步：跳转到qq登录页面输入用户名密码，然后点授权并登录**

　　上一步中浏览器接到重定向地址并访问 http://www.qq.com/authorize?callback=www.douban.com/callback

　　qq的服务器接受到了豆瓣访问的authorize，在次例中所给出的回应是跳转到qq的登录页面，用户输入账号密码点击授权并登录按钮后，一定还会访问qq服务器中校验用户名密码的方法，若校验成功，该方法会响应浏览器一个重定向地址，并附上一个**code（授权码）**。由于豆瓣只关心像qq发起authorize请求后会返回一个code，并不关心qq是如何校验用户的，并且这个过程每个授权服务器可能会做些个性化的处理，只要最终的结果是返回给浏览器一个重定向并附上code即可，所以这个过程在图中并没有详细展开。现把展开图画给大家。

![img](https://images2017.cnblogs.com/blog/1096103/201708/1096103-20170824161339668-1419889465.png)

**第三步：跳回到豆瓣页面，成功登录**

 这一步背后的过程其实是最繁琐的，但对于用户来说是完全感知不到的。用户在QQ登录页面点击授权登陆后，就直接跳转到豆瓣首页了，但其实经历了很多隐藏的过程。

首先接上一步，QQ服务器在判断登录成功后，使页面重定向到之前豆瓣发来的callback并附上code授权码，即 callback=www.douban.com/callback 

页面接到重定向，发起 http://www.douban.com/callback 请求

豆瓣服务器收到请求后，做了两件再次与QQ沟通的事，即模拟浏览器发起了两次请求。一个是用拿到的code去换token，另一个就是用拿到的token换取用户信息。最后将用户信息储存起来，返回给浏览器其首页的视图。到此OAuth2.0授权结束。

![img](https://images2017.cnblogs.com/blog/1096103/201708/1096103-20170824162606793-113527222.png)



## 微服务设计中的API网关模式

根据 Gartner 对微服务的定义：“微服务是范围狭窄、封装紧密、松散耦合、可独立部署且可独立伸缩的应用程序组件。”

与将模块高度耦合并部署为一个大的应用程序相比，微服务的目标是将应用程序充分分解或者解耦为松散耦合的许多微服务或者模块，这样做对下面几点有很大帮助：

- 每个微服务都可以独立于应用程序中的同级服务进行部署、升级、扩展、维护和重新启动。
- 通过自治的跨职能团队进行敏捷开发和敏捷部署。
- 运用技术时具备灵活性和可扩展性

在微服务架构中，我们根据各自的特定需求部署不同的松耦合服务，其中每个服务都有其更细粒度的 API 模型，用以服务于不同的客户端（Web，移动和第三方 API）。

1客户端到微服务的连接

![img](https://oscimg.oschina.net/oscnet/044c6408-bbc4-4856-92dc-89fb49f70d03.png)

在考虑客户端与每个已部署的微服务 **直接通信** 的问题时，应考虑以下挑战：

1. 如果微服务向客户端公开了细粒度的 API，则客户端应向每个微服务发出请求。在典型的单页中，可能需要进行 **多次服务器往返**，才能满足请求。对于较差的网络条件下运行的设备（例如移动设备），这可能会更糟。
2. 微服务中存在的 **多种通信协议**（例如 gRpc、thrift、REST、AMQP 等）使客户端很难轻松采用所有这些协议。
3. 必须在每个微服务中实现 **通用网关功能**（例如身份验证、授权、日志记录）。
4. 在不中断客户端连接的情况下，**很难在微服务中进行更改**。例如，在合并或划分微服务时，可能需要重新编写客户端部分代码。

2API 网关

为了解决上述挑战，人们引入了一个附加层，该附加层位于客户端和服务器之间，充当从客户端到服务器的反向代理路由请求。与面向对象设计的模式相似，它为封装底层系统架构的 API 提供了一个单一的入口，称为 API 网关。

简而言之，它的行为就像 API 管理员一样，但重要的是不要将 API 管理与 API Gateway 混为一谈。

![img](https://oscimg.oschina.net/oscnet/3810bf35-ea8d-40ac-ad63-9388734530e3.png)

3API 网关的功能

路由

网关封装了底层系统并与客户端分离，为客户端提供了与微服务系统进行通信的单个入口点。

整合

API 网关整合了一些边缘的重复功能，无需让每个微服务都实现它们。它包括如下功能：

- 认证和授权
- 服务发现集成
- 缓存响应结果
- 重试策略、熔断器、QoS
- 限速和节流
- 负载均衡
- log 日志、链路追踪、关联
- Header、query 字符串 以及 claims 转义
- IP 白名单
- IAM
- 集中式日志管理（服务之间的 transaction ID、错误日志等）
- 身份的提供方，验证与授权

4后端服务前端模式（BFF Backend for Frontend）

它是 API 网关模式的一种变体。它提供了基于客户端的多个网关，而不是提供给客户端一个单一的入口点。目的是根据客户端的需求提供量身定制的 API，从而消除了为所有客户端制作通用 API 造成的大量的浪费。

![img](https://oscimg.oschina.net/oscnet/c18ea4ad-e32e-4f0a-8386-e284bb09926e.png)

到底需要多少 BFF

BFF 的基本概念是为每种用户体验开发利基后端。菲尔·卡尔萨多（PhilCalçado） 的指导建议是“**一种体验，一种 BFF**”。如果跨客户端（IOS 客户端、Android 客户端、Web 浏览器等）的要求有很大差异，并且单个代理或 API 的发布时间有严格要求，则 BFF 是一个很好的解决方案。还应注意，更复杂的设计需要复杂的步骤。

GraphQL 与 BFF

GraphQL 是一种 API 的查询语言。PhilCalçado 提出 BFF 和 GraphQL 的想法是相似的，但不是互斥的概念。他补充说，BFF 与你端口的形状无关，而在于赋予客户端对应用程序的自治权，您可以在其中构建与许多 BFF 或 OSFA（one-size-fits-all）的 GraphQL API。

5著名的 API 网关

Netflix API 网关：Zuul

Netflix 的流媒体服务可在 1000 多种不同类型的设备（电视、机顶盒、智能手机、游戏系统、平板电脑等）上使用，在高峰时段可以每秒处理 50,000 个请求，这种需求是 OSFA （one-size-fits-all）的 REST API 难以满足的，因此他们为每个设备量身定制了 API 网关。

Netflix 的 Zuul 2 是所有进入 Netflix 云基础架构的请求的第一步。Zuul 2 大大改进了架构和功能，使我们的网关能够处理、路由和保护 Netflix 的云系统，并帮助为我们的 1.25 亿会员提供最佳体验。



亚马逊 API 网关

AWS 提供了完备的托管服务，用于创建、发布、维护、监视以及保护 REST、HTTP 和 WebSocket，开发人员可以在其中创建用于访问 AWS 或其他 Web 服务的 API，并将数据存储在 AWS 云上面。



Kong API 网关

Kong Gateway 是一个开源的，轻量级的微服务 API 网关，可提供无与伦比的延迟性能优化和可伸缩性。如果您只需要这些基础能力，那么它就是很合适的选项。只需要增加更多节点就可以轻松横向扩展。它以非常低的延迟来支持大量可变的工作负载。

其他 API 网关

- Apigee API Gateway
- MuleSoft
- Tyk.io
- Akana
- SwaggerHub
- Azure API Gateway
- Express API Gateway
- Karken D

选择正确的网关

评估标准里面，一些常见的指标包括简便性、开源还是专有、可伸缩性和灵活性、安全性、后续功能、社区、管理（支持情况、监控和部署）、环境配置（安装、配置、是否支持托管）、定价和文档等。

6API 组合与聚合

API 网关中的一些 API 请求直接映射到单个服务的 API 上，可以通过将请求路由到相应的微服务来提供服务。但是，在需要从多个微服务获得结果的复杂 API 操作的情况下，可以通过 **API 组合 / 聚合**（分散 - 收集机制）来提供服务。在需要同步通信的情况下，如果服务彼此依赖，则必须遵循链式组合模式。组合层必须支持很大一部分的 ESB / 集成功能，例如转换、编排、弹性和稳定性模式。

根容器的部署必须配备特殊的分发器和聚合器功能（或微服务）。分发者负责分解成细粒度的任务，并将这些任务分发给微服务实例。聚合器负责聚合业务工作流从组合微服务中得出的结果。

API 网关和聚合

具备复杂功能的网关会增大测试和部署的难度。强烈建议大家避免在 API 网关中进行聚合和数据转换。领域专属的功能更应该遵循软件开发实践的定义，在应用程序的代码中完成。Netflix API Gateway Zuul 2 从他们在 Zuul 到原始系统的网关中，删除了许多业务逻辑。 

![img](https://oscimg.oschina.net/oscnet/3ad4e5c6-a6c4-454f-a754-f5b041a23f45.png)

Service Mesh 与 API 网关

微服务中的 Service Mesh 是处理进程间通信的可配置网络基础结构层。这和通常称为 Sidecar 代理或 Sidecar 网关的东西很像。它提供了许多功能，例如：

- 负载均衡
- 服务发现
- 健康检查
- 安全性

从表面上看，**API 网关和 Service Mesh 似乎解决了相同的问题，因此好像是多余的。它们确实解决了相同的问题，但是应用在不同的场景**。API 网关被部署为业务解决方案的一部分，被外部的服务发现，处理纵向的流量（面对外部客户端），但是，Service Mesh 是用来处理横向流量（在不同的微服务之间）。

实现 Service Mesh 可避免在您自己的代码中出现一些弹性交互，例如熔断器、服务发现、健康检查以及服务观察。对于少量的微服务，应考虑使用其他替代方法来进行故障管理，因为 Service Mesh 集成可能代价太大了。但对于大量的微服务，它的收益是显著的。

结合这两种技术可能是确保应用程序正常运行时间和弹性伸缩能力的一种有效方法，同时又可以确保您的应用程序易于使用。将两者视为同样的产品是不对的，最好将两者视为在涉及微服务和 API 的部署中相辅相成的工具。

API 网关实现的注意事项：

- 可能产生的单点故障或者瓶颈
- 由于通过 API 网关进行了额外的网络跳转以及复杂性风险，响应时间增长了。





# Web安全





## XSS

- 有很多用户发送了同样类型的内容，而且这些内容都是一个带有诱惑性的问题和一个可以点击的链接。
- 简单来说，XSS 就是利用 Web 漏洞，在用户的浏览器中执行黑客定义的 JavaScript 脚本，这样一种攻击方式。
- 如何进行 XSS 防护？
  - 验证输入 OR 验证输出
  - 编码
  - 检测和过滤
  - CSP
    - CSP（Content Security Policy，内容安
      全策略）来提升 Web 的安全性。所谓 CSP，就是在服务端返回的 HTTP header 里面添加
      一个 Content-Security-Policy 选项，然后定义资源的白名单域名。浏览器就会识别这个字
      段，并限制对非白名单资源的访问。
    - 那我们为什么要限制外域资源的访问呢？这是因为 XSS 通常会受到长度的限制，导致黑客无法提交一段完整的 JavaScript 代码。为了解决这个问题，黑客会采取引用一个外域JavaScript 资源的方式来进行注入。



## SQL注入

- 通常来说，我们会将应用的用户信息存储在数据库中。每次用户登录时，都会执行一个相应的 SQL 语句。这时，黑客会通过构造一些恶意的输入参数，在应用拼接 SQL 语句的时候，去篡改正常的 SQL 语意，从而执行黑客所控制的 SQL 查询功能。这个过程，就相当于黑客“注入”了一段 SQL 代码到应用中。这就是我们常说的 SQL 注入。

- SELECT * FROM Users WHERE Username ="" AND Password ="" or ""=""

- 使用 PreparedStatement

  - 通过合理地使用 PreparedStatement，我们就能够避免 99.99% 的 SQL 注入问题。

  - 当数据库在处理一个 SQL 命令的时候，大致可以分为两个步骤：

    - 将 SQL 语句解析成数据库可使用的指令集。我们在使用 EXPLAIN 关键字分析 SQL 语句，就是干的这个事情；
    - 将变量代入指令集，开始实际执行。之所以在批量处理 SQL 的时候能够提升性能，就是因为这样做避免了重复解析 SQL 的过程。

  - SQL 注入是在解析的过程中生效的，用户的输入会影响 SQL 解析的结果。因此，我们可以通过使用 PreparedStatement，将 SQL 语句的解析和实际执行过程分开，只在执行的过程中代入用户的操作。这样一来，无论黑客提交的参数怎么变化，数据库都不会去执行额外的逻辑，也就避免了 SQL 注入的发生。

  - ```java
    1 String sql = "SELECT * FROM Users WHERE UserId = ?"; 
    2 PreparedStatement statement = connection.prepareStatement(sql); 
    3 statement.setInt(1, userId); 
    4 ResultSet results = statement.executeQuery();
    
    
    // 如果你在使用 PreparedStatement 的时候，还是通过字符串拼接来构造 SQL语句，那仍然是将解析和执行放在了一块，也就不会产生相应的防护效果了。
    
    1 String sql = "SELECT * FROM Users WHERE UserId = " + userId; 
    2 PreparedStatement statement = connection.prepareStatement(sql); 
    3 ResultSet results = statement.executeQuery();
    ```







## CSRF/SSRF

- 在平常使用浏览器访问各种网页的时候，是否遇到过，自己的银行应用突然发起了一笔转账，又或者，你的微博突然发送了一条内容？

- 为了能够准确地代表你的身份，浏览器通常会在 Cookie 中存储一些必要的身份信息。所以，在我们使用一个网页的时候，只需要在首次访问的时候登录就可以了。

  - 黑客正是利用这一点，来编写带有恶意JavaScript 脚本的网页，通过“钓鱼”的方式诱导你访问。然后，黑客会通过这些JavaScript 脚本窃取你保存在网页中的身份信息，通过仿冒你，让你的浏览器发起伪造的请求，最终执行黑客定义的操作。而这一切对于你自己而言都是无感知的。这就是CSRF（Cross-Site Request Forgery，跨站请求伪造）攻击。

- 和 XSS 一样，CSRF 也可以仿冒用户去进行一些功能操作的请求，比如修改密码、转账等等，相当于绕过身份认证，进行未授权的操作。

- 行业内标准的 CSRF 防护方法是CSRFToken

  - CSRF 是通过自动提交表单的形式来发起攻击的。所以，在前面转账的例子中，黑客可以通过抓包分析出 http://bank.com/transfer 这个接口所需要的参数，从而构造对应的 form 表单。因此，我们只需要在这个接口中，加入一个黑客无法猜到的参数，就可以有效防止 CSRF 了。这就是 CSRF Token 的工作原理。
  - 因为 CSRF Token 是每次用户正常访问页面时，服务端随机生成返回给浏览器的。所以，每一次正常的转账接口调用，都会携带不同的 CSRF Token。黑客没有办法进行提前猜测，也就没有办法构造出正确的表单了。

- SSRF：同样的原理，发生在服务端又会发生什么？

  - 我们知道，服务端也有代理请求的功能：用户在浏览器中输入一个 URL（比如某个图片资源），然后服务端会向这个 URL 发起请求，通过访问其他的服务端资源来完成正常的页面展示。
  - 这个时候，只要黑客在输入中提交一个内网 URL，就能让服务端发起一个黑客定义的内网
    请求，从而获取到内网数据。这就是SSRF（Server Side Request Forgery，服务端请求伪造）的原理。而服务端作为内网设备，通常具备很高的权限，所以，这个伪造的请求往往
    因为能绕过大部分的认证和授权机制，而产生很严重的后果。
  - 比方说，当我们在百度中搜索图片时，会涉及图片的跨域加载保护，百度不会直接在页面中加载图片的源地址，而是将地址通过 GET 参数提交到百度服务器，然后百度服务器请求到对应的图片，再返回到页面展示出来。
  - 这个过程中，百度服务器实际上会向另外一个 URL 地址发起请求。利用这个代理发起请求的功能，黑客可以通过提交一个内网的地址，实现对内网任意服务的访问。这就是 SSRF 攻击的实现过程，也就是我们常说的“内网穿透”。

- 因为 SSRF 最终的结果，是接受代理请求的服务端发生数据泄漏。所以，SSRF防护不仅仅涉及接收 URL 的服务端检测，也需要接受代理请求的服务端进行配合。在这种情况下，我们就需要用到请求端限制，它的防护措施主要包括两个方面。

  - 第一，为其他业务提供的服务接口尽量使用 POST，避免 GET 的使用。因为，在 SSRF 中
    （以及大部分的 Web 攻击中），发起一个 POST 请求的难度是远远大于 GET 请求的。
  - 第二，为其他业务提供的服务接口，最好每次都进行验证。通过 SSRF，黑客只能发起请求，并不能获取到服务端存储的验证信息（如认证的 key 和 secret 等）。因此，只要接受代理请求的端对每次请求都进行完整的验证，黑客无法成功通过验证，也就无法完成请求了。

  



