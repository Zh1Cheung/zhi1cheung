---
title: Spark内核原理进阶
categories:
- Spark
- Big Data
tags:
- Spark



---


     
## Spark内核原理进阶-union算子内部实现原理剖析


![](http://i2.51cto.com/images/blog/201810/04/5133f9d8ba04420a773e2c072fc8a03d.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)


## 内核原理进阶-groupByKey算子内部实现原理剖析

![](http://i2.51cto.com/images/blog/201810/04/b9c713d5033b708d3ab513d8c563746d.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)

一般来说，在执行shuffle类的算子的时候，比如groupByKey、reduceByKey、join等。

其实算子内部都会隐式地创建几个RDD出来。那些隐式创建的RDD，主要是作为这个操作的一些中间数据的表达，以及作为stage划分的边界。

因为有些隐式生成的RDD，可能是ShuffledRDD，dependency就是ShuffleDependency，DAGScheduler的源码，就会将这个RDD作为新的stage的第一个rdd，划分出来。



groupByKey等shuffle算子，都会创建一些隐式RDD。比如说这里，ShuffledRDD，作为一个shuffle过程中的中间数据的代表。

依赖这个ShuffledRDD创建出来一个新的stage（stage1）。ShuffledRDD会去触发shuffle read操作。从上游stage的task所在节点，拉取过来相同的key，做进一步的聚合。

对ShuffledRDD中的数据执行一个map类的操作，主要是对每个partition中的数据，都进行一个映射和聚合。这里主要是将每个key对应的数据都聚合到一个Iterator集合中。


## Spark内核原理进阶-reduceByKey算子内部实现原理剖析

![](http://i2.51cto.com/images/blog/201810/04/e6f5e68dcd6d0fa9503bed1bf38960e0.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)



reduceByKey，看了内部原理之后，跟groupByKey的异同之处，在哪里？

1、不同之处：reduceByKey，多了一个rdd，MapPartitionsRDD，存在于stage0的，主要是代表了进行本地数据归约之后的rdd。所以，要网络传输的数据量，以及磁盘IO等，会减少，性能更高。

2、相同之处：后面进行shuffle read和聚合的过程基本和groupByKey类似。都是ShuffledRDD，去做shuffle read。然后聚合，聚合后的数据就是最终的rdd。wordCounts rdd。

## Spark内核原理进阶-distinct算子内部实现原理剖析

![](http://i2.51cto.com/images/blog/201810/04/33321dfa1b0c7373bc991ba05ca99b8d.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)


distinct算子的原理

1、首先，自己先给每个值打上一个v2，变成一个tuple

2、reduceByKey(...仅仅返回一个value)

3、将去重后的数据，从tuple还原为单值


## Spark内核原理进阶-cogroup算子内部实现原理剖析


![](http://i2.51cto.com/images/blog/201810/04/a136d10cf89c36a248df2f62162c8259.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)




cogroup算子

1、基础的算子

2、在我们大量的实践中，很少遇到说要用cogroup算子的情况

3、cogroup算子是其他很多算子的基础，比如join


## Spark内核原理进阶-intersection算子内部实现原理剖析


![](http://i2.51cto.com/images/blog/201810/04/aa59b1587dd31b4d2b4783e97070b258.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)





intersection算子原理

1、map，tuple

2、cogroup，聚合两个rdd的key

3、filter，过滤掉两个集合中任意一个集合为空的key

4、map，还原出单key






## Spark内核原理进阶-join算子内部实现原理剖析






![](http://i2.51cto.com/images/blog/201810/04/f14002888f3bfb48bb8d76dbf0dc194c.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)





join算子的原理

1、cogroup，聚合两个rdd的key

2、flatMap，聚合后的每条数据，都可能返回多条数据
将每个key对应的两个集合的所有元素，做了一个笛卡尔积




## Spark内核原理进阶-sortByKey算子内部实现原理剖析





![](http://i2.51cto.com/images/blog/201810/04/162dea80cdc02da33dea0b5be6356200.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)






sortByKey

1、ShuffledRDD，做shuffle read，将相同的key拉到一个partition中来

2、mapPartitions，对每个partitions内的key进行全局的排序




## Spark内核原理进阶-cartesian算子内部实现原理剖析






![](http://i2.51cto.com/images/blog/201810/04/cc55d13440106bd045aa0e0544def74b.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)





## Spark内核原理进阶-coalesce算子内部实现原理剖析





![](http://i2.51cto.com/images/blog/201810/04/ca7f29f6c40da2f01863449bed9d37b4.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)




## Spark内核原理进阶-repartition算子内部实现原理剖析



![](http://i2.51cto.com/images/blog/201810/04/9faa7a15690dca5812b2ab3c05812c19.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)

repartition算子

1、map，附加了前缀，根据要重分区成几个分区，计算出前缀

2、shuffle->colesceRDD

3、去掉前缀，得到最终重分区好的RDD
