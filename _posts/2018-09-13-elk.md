---
title: elasticsearch(二)
categories:
- ELK
tags:
- elasticsearch


---

### Elasticsearch对复杂分布式机制的透明隐藏特性

![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928083249967-47083242.png)

Elasticsearch是一套分布式的系统，分布式是为了应对大数据量
隐藏了复杂的分布式机制

分片机制（我们之前随随便便就将一些document插入到es集群中去了，我们有没有care过数据怎么进行分片的，数据到哪个shard中去）

cluster discovery（集群发现机制，我们之前在做那个集群status从yellow转green的实验里，直接启动了第二个es进程，那个进程作为一个node自动就发现了集群，并且加入了进去，还接受了部分数据，replica shard）

shard负载均衡（举例，假设现在有3个节点，总共有25个shard要分配到3个节点上去，es会自动进行均匀分配，以保持每个节点的均衡的读写负载请求）

shard副本，请求路由，集群扩容，shard重分配


### Elasticsearch的垂直扩容与水平扩容

垂直扩容：采购更强大的服务器，成本非常高昂，而且会有瓶颈，假设世界上最强大的服务器容量就是10T，但是当你的总数据量达到5000T的时候，你要采购多少台最强大的服务器啊

水平扩容：业界经常采用的方案，采购越来越多的普通服务器，性能比较一般，但是很多普通服务器组织在一起，就能构成强大的计算和存储能力

普通服务器：1T，1万，100万
强大服务器：10T，50万，500万

扩容对应用程序的透明性

### 增减或减少节点时的数据rebalance

保持负载均衡



### master节点

（1）创建或删除索引
（2）增加或删除节点



### 节点平等的分布式架构

（1）节点对等，每个节点都能接收所有的请求
（2）自动请求路由
（3）响应收集


### shard&replica机制

（1）index包含多个shard

（2）每个shard都是一个最小工作单元，承载部分数据，lucene实例，完整的建立索引和处理请求的能力

（3）增减节点时，shard会自动在nodes中负载均衡

（4）primary shard和replica shard，每个document肯定只存在于某一个primary shard以及其对应的replica shard中，不可能存在于多个primary shard

（5）replica shard是primary shard的副本，负责容错，以及承担读请求负载

（6）primary shard的数量在创建索引的时候就固定了，replica shard的数量可以随时修改

（7）primary shard的默认数量是5，replica默认是1，默认有10个shard，5个primary shard，5个replica shard

（8）primary shard不能和自己的replica shard放在同一个节点上（否则节点宕机，primary shard和副本都丢失，起不到容错的作用），但是可以和其他primary shard的replica shard放在同一个节点上




### 单node环境下创建index

（1）单node环境下，创建一个index，有3个primary shard，3个replica shard

（2）集群status是yellow

（3）这个时候，只会将3个primary
shard分配到仅有的一个node上去，另外3个replica shard是无法分配的

（4）集群可以正常工作，但是一旦出现节点宕机，数据全部丢失，而且集群不可用，无法承接任何请求

    PUT /test_index
    {
       "settings" : {
          "number_of_shards" : 3,
          "number_of_replicas" : 1
       }
    }



### 2个node环境下replica shard如何分配

（1）replica shard分配：3个primary shard，3个replica shard，1 node

（2）primary ---> replica同步

（3）读请求：primary/replica


![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928084009053-1001556250.png)


### 横向扩容过程，如何超出扩容极限，以及如何提升容错性

![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928084123149-1996934458.png)

（1）primary&replica自动负载均衡，6个shard，3 primary，3 replica

（2）每个node有更少的shard，IO/CPU/Memory资源给每个shard分配更多，每个shard性能更好

（3）扩容的极限，6个shard（3 primary，3 replica），最多扩容到6台机器，每个shard可以占用单台服务器的所有资源，性能最好

（4）超出扩容极限，动态修改replica数量，9个shard（3primary，6 replica），扩容到9台机器，比3台机器时，拥有3倍的读吞吐量

（5）3台机器下，9个shard（3 primary，6 replica），资源更少，但是容错性更好，最多容纳2台机器宕机，6个shard只能容纳0台机器宕机

（6）这里的这些知识点，你综合起来看，就是说，一方面告诉你扩容的原理，怎么扩容，怎么提升系统整体吞吐量；另一方面要考虑到系统的容错性，怎么保证提高容错性，让尽可能多的服务器宕机，保证数据不丢失



![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928084124808-2056565173.png)



### Elasticsearch容错机制：master选举，replica容错，数据恢复


（1）9 shard，3 node

（2）master node宕机，自动master选举，red

（3）replica容错：新master将replica提升为primary shard，yellow

（4）重启宕机node，master copy replica到该node，使用原有的shard并同步宕机后的修改，green


![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928084339889-1392669576.png)




### _index元数据


（1）代表一个document存放在哪个index中

（2）类似的数据放在一个索引，非类似的数据放不同索引：product index（包含了所有的商品），sales index（包含了所有的商品销售数据），inventory index（包含了所有库存相关的数据）。如果你把比如product，sales，human resource（employee），全都放在一个大的index里面，比如说company index，不合适的。

（3）index中包含了很多类似的document：类似是什么意思，其实指的就是说，这些document的fields很大一部分是相同的，你说你放了3个document，每个document的fields都完全不一样，这就不是类似了，就不太适合放到一个index里面去了。

（4）索引名称必须是小写的，不能用下划线开头，不能包含逗号：product，website，blog

### _type元数据

（1）代表document属于index中的哪个类别（type）

（2）一个索引通常会划分为多个type，逻辑上对index中有些许不同的几类数据进行分类：因为一批相同的数据，可能有很多相同的fields，但是还是可能会有一些轻微的不同，可能会有少数fields是不一样的，举个例子，就比如说，商品，可能划分为电子商品，生鲜商品，日化商品，等等。

（3）type名称可以是大写或者小写，但是同时不能用下划线开头，不能包含逗号

### _id元数据

（1）代表document的唯一标识，与index和type一起，可以唯一标识和定位一个document

（2）我们可以手动指定document的id（put /index/type/id），也可以不指定，由es自动为我们创建一个id




![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928084728978-698456349.png)





### 手动指定document id

（1）根据应用情况来说，是否满足手动指定document id的前提：

一般来说，是从某些其他的系统中，导入一些数据到es时，会采取这种方式，就是使用系统中已有数据的唯一标识，作为es中document的id。举个例子，比如说，我们现在在开发一个电商网站，做搜索功能，或者是OA系统，做员工检索功能。这个时候，数据首先会在网站系统或者IT系统内部的数据库中，会先有一份，此时就肯定会有一个数据库的primary key（自增长，UUID，或者是业务编号）。如果将数据导入到es中，此时就比较适合采用数据在数据库中已有的primary key。

如果说，我们是在做一个系统，这个系统主要的数据存储就是es一种，也就是说，数据产生出来以后，可能就没有id，直接就放es一个存储，那么这个时候，可能就不太适合说手动指定document id的形式了，因为你也不知道id应该是什么，此时可以采取下面要讲解的让es自动生成id的方式。

（2）put /index/type/id

    PUT /test_index/test_type/2
    {
      "test_content": "my test"
    }

### 自动生成document id

    （1）post /index/type
    
    POST /test_index/test_type
    {
      "test_content": "my test"
    }
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "AVp4RN0bhjxldOOnBxaE",
      "_version": 1,
      "result": "created",
      "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
      },
      "created": true
    }

（2）自动生成的id，长度为20个字符，URL安全，base64编码，GUID，分布式系统并行生成时不可能会发生冲突




![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928084837661-1347898945.png)



### _source元数据

    put /test_index/test_type/1
    {
      "test_field1": "test field1",
      "test_field2": "test field2"
    }
    
    get /test_index/test_type/1
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "1",
      "_version": 2,
      "found": true,
      "_source": {
        "test_field1": "test field1",
        "test_field2": "test field2"
      }
    }

_source元数据：就是说，我们在创建一个document的时候，使用的那个放在request body中的json串，默认情况下，在get的时候，会原封不动的给我们返回回来。



### 定制返回结果

定制返回的结果，指定_source中，返回哪些field

    GET /test_index/test_type/1?_source=test_field1,test_field2
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "1",
      "_version": 2,
      "found": true,
      "_source": {
        "test_field2": "test field2"
      }
    }



### document的全量替换

（1）语法与创建文档是一样的，如果document id不存在，那么就是创建；如果document id已经存在，那么就是全量替换操作，替换document的json串内容

（2）document是不可变的，如果要修改document的内容，第一种方式就是全量替换，直接对document重新建立索引，替换里面所有的内容

（3）es会将老的document标记为deleted，然后新增我们给定的一个document，当我们创建越来越多的document的时候，es会在适当的时机在后台自动删除标记为deleted的document


### document的强制创建

（1）创建文档与全量替换的语法是一样的，有时我们只是想新建文档，不想替换文档，如果强制进行创建呢？

（2）PUT /index/type/id?op_type=create，PUT /index/type/id/_create

### document的删除

![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928090026206-1073389912.png)
（1）DELETE /index/type/id

（2）不会理解物理删除，只会将其标记为deleted，当数据越来越多的时候，在后台自动删除


### Elasticsearch并发冲突问题

![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928090101547-1983922069.png)



### 悲观锁与乐观锁两种并发控制方案

![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928090237274-1439897424.png)



### Elasticsearch内部如何基于_version进行乐观锁并发控制

（1）_version元数据

    PUT /test_index/test_type/6
    {
      "test_field": "test test"
    }
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "6",
      "_version": 1,
      "result": "created",
      "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
      },
      "created": true
    }
    

第一次创建一个document的时候，它的_version内部版本号就是1；以后，每次对这个document执行修改或者删除操作，都会对这个_version版本号自动加1；哪怕是删除，也会对这条数据的版本号加1


    {
      "found": true,
      "_index": "test_index",
      "_type": "test_type",
      "_id": "6",
      "_version": 4,
      "result": "deleted",
      "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
      }
    }

我们会发现，在删除一个document之后，可以从一个侧面证明，它不是立即物理删除掉的，因为它的一些版本号等信息还是保留着的。先删除一条document，再重新创建这条document，其实会在delete version基础之上，再把version号加1

![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928090819717-1020846958.png)



### 基于_version进行乐观锁并发控制


（1）先构造一条数据出来

    PUT /test_index/test_type/7
    {
      "test_field": "test test"
    }

（2）模拟两个客户端，都获取到了同一条数据

    GET test_index/test_type/7
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "7",
      "_version": 1,
      "found": true,
      "_source": {
        "test_field": "test test"
      }
    }

（3）其中一个客户端，先更新了一下这个数据

同时带上数据的版本号，确保说，es中的数据的版本号，跟客户端中的数据的版本号是相同的，才能修改

    PUT /test_index/test_type/7?version=1 
    {
      "test_field": "test client 1"
    }
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "7",
      "_version": 2,
      "result": "updated",
      "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
      },
      "created": false
    }

（4）另外一个客户端，尝试基于version=1的数据去进行修改，同样带上version版本号，进行乐观锁的并发控制

    PUT /test_index/test_type/7?version=1 
    {
      "test_field": "test client 2"
    }
    
    {
      "error": {
        "root_cause": [
          {
            "type": "version_conflict_engine_exception",
            "reason": "[test_type][7]: version conflict, current version [2] is different than the one provided [1]",
            "index_uuid": "6m0G7yx7R1KECWWGnfH1sw",
            "shard": "3",
            "index": "test_index"
          }
        ],
        "type": "version_conflict_engine_exception",
        "reason": "[test_type][7]: version conflict, current version [2] is different than the one provided [1]",
        "index_uuid": "6m0G7yx7R1KECWWGnfH1sw",
        "shard": "3",
        "index": "test_index"
      },
      "status": 409
    }

（5）在乐观锁成功阻止并发问题之后，尝试正确的完成更新

    GET /test_index/test_type/7
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "7",
      "_version": 2,
      "found": true,
      "_source": {
        "test_field": "test client 1"
      }
    }

基于最新的数据和版本号，去进行修改，修改后，带上最新的版本号，可能这个步骤会需要反复执行好几次，才能成功，特别是在多线程并发更新同一条数据很频繁的情况下

    PUT /test_index/test_type/7?version=2 
    {
      "test_field": "test client 2"
    }
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "7",
      "_version": 3,
      "result": "updated",
      "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
      },
      "created": false
    }


### 基于external version进行乐观锁并发控制




external version

es提供了一个feature，就是说，你可以不用它提供的内部_version版本号来进行并发控制，可以基于你自己维护的一个版本号来进行并发控制。举个列子，加入你的数据在mysql里也有一份，然后你的应用系统本身就维护了一个版本号，无论是什么自己生成的，程序控制的。这个时候，你进行乐观锁并发控制的时候，可能并不是想要用es内部的_version来进行控制，而是用你自己维护的那个version来进行控制。

?version=1
?version=1&version_type=external

version_type=external，唯一的区别在于，_version，只有当你提供的version与es中的_version一模一样的时候，才可以进行修改，只要不一样，就报错；当version_type=external的时候，只有当你提供的version比es中的_version大的时候，才能完成修改

es，_version=1，?version=1，才能更新成功
es，_version=1，?version>1&version_type=external，才能成功，比如说?version=2&version_type=external

（1）先构造一条数据

    PUT /test_index/test_type/8
    {
      "test_field": "test"
    }
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "8",
      "_version": 1,
      "result": "created",
      "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
      },
      "created": true
    }

（2）模拟两个客户端同时查询到这条数据

    GET /test_index/test_type/8
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "8",
      "_version": 1,
      "found": true,
      "_source": {
        "test_field": "test"
      }
    }

（3）第一个客户端先进行修改，此时客户端程序是在自己的数据库中获取到了这条数据的最新版本号，比如说是2

    PUT /test_index/test_type/8?version=2&version_type=external
    {
      "test_field": "test client 1"
    }
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "8",
      "_version": 2,
      "result": "updated",
      "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
      },
      "created": false
    }

（4）模拟第二个客户端，同时拿到了自己数据库中维护的那个版本号，也是2，同时基于version=2发起了修改

    PUT /test_index/test_type/8?version=2&version_type=external
    {
      "test_field": "test client 2"
    }
    
    {
      "error": {
        "root_cause": [
          {
            "type": "version_conflict_engine_exception",
            "reason": "[test_type][8]: version conflict, current version [2] is higher or equal to the one provided [2]",
            "index_uuid": "6m0G7yx7R1KECWWGnfH1sw",
            "shard": "1",
            "index": "test_index"
          }
        ],
        "type": "version_conflict_engine_exception",
        "reason": "[test_type][8]: version conflict, current version [2] is higher or equal to the one provided [2]",
        "index_uuid": "6m0G7yx7R1KECWWGnfH1sw",
        "shard": "1",
        "index": "test_index"
      },
      "status": 409
    }

（5）在并发控制成功后，重新基于最新的版本号发起更新

    GET /test_index/test_type/8
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "8",
      "_version": 2,
      "found": true,
      "_source": {
        "test_field": "test client 1"
      }
    }

    PUT /test_index/test_type/8?version=3&version_type=external
    {
      "test_field": "test client 2"
    }
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "8",
      "_version": 3,
      "result": "updated",
      "_shards": {
        "total": 2,
        "successful": 1,
        "failed": 0
      },
      "created": false
    }



### 什么是partial update？

PUT /index/type/id，创建文档&替换文档，就是一样的语法

一般对应到应用程序中，每次的执行流程基本是这样的：

（1）应用程序先发起一个get请求，获取到document，展示到前台界面，供用户查看和修改

（2）用户在前台界面修改数据，发送到后台

（3）后台代码，会将用户修改的数据在内存中进行执行，然后封装好修改后的全量数据

（4）然后发送PUT请求，到es中，进行全量替换

（5）es将老的document标记为deleted，然后重新创建一个新的document

partial update

    post /index/type/id/_update 
    {
       "doc": {
          "要修改的少数几个field即可，不需要全量的数据"
       }
    }

看起来，好像就比较方便了，每次就传递少数几个发生修改的field即可，不需要将全量的document数据发送过去

### 图解partial update实现原理以及其优点

![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928092552879-322372563.png)




### partial update

    PUT /test_index/test_type/10
    {
      "test_field1": "test1",
      "test_field2": "test2"
    }
    
    POST /test_index/test_type/10/_update
    {
      "doc": {
        "test_field2": "updated test2"
      }
    }


### 基于groovy脚本进行partial update


es，其实是有个内置的脚本支持的，可以基于groovy脚本实现各种各样的复杂操作
基于groovy脚本，如何执行partial update
es scripting module，

    PUT /test_index/test_type/11
    {
      "num": 0,
      "tags": []
    }

（1）内置脚本

    POST /test_index/test_type/11/_update
    {
       "script" : "ctx._source.num+=1"
    }
    
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "11",
      "_version": 2,
      "found": true,
      "_source": {
        "num": 1,
        "tags": []
      }
    }

（2）外部脚本

    ctx._source.tags+=new_tag
    
    POST /test_index/test_type/11/_update
    {
      "script": {
        "lang": "groovy", 
        "file": "test-add-tags",
        "params": {
          "new_tag": "tag1"
        }
      }
    }

（3）用脚本删除文档

    ctx.op = ctx._source.num == count ? 'delete' : 'none'
    
    POST /test_index/test_type/11/_update
    {
      "script": {
        "lang": "groovy",
        "file": "test-delete-document",
        "params": {
          "count": 1
        }
      }
    }

（4）upsert操作

    POST /test_index/test_type/11/_update
    {
      "doc": {
        "num": 1
      }
    }
    
    {
      "error": {
        "root_cause": [
          {
            "type": "document_missing_exception",
            "reason": "[test_type][11]: document missing",
            "index_uuid": "6m0G7yx7R1KECWWGnfH1sw",
            "shard": "4",
            "index": "test_index"
          }
        ],
        "type": "document_missing_exception",
        "reason": "[test_type][11]: document missing",
        "index_uuid": "6m0G7yx7R1KECWWGnfH1sw",
        "shard": "4",
        "index": "test_index"
      },
      "status": 404
    }

如果指定的document不存在，就执行upsert中的初始化操作；如果指定的document存在，就执行doc或者script指定的partial update操作

    POST /test_index/test_type/11/_update
    {
       "script" : "ctx._source.num+=1",
       "upsert": {
           "num": 0,
           "tags": []
       }
    }



### partial update内置乐观锁并发控制

![image](https://img2018.cnblogs.com/blog/1279115/201809/1279115-20180928093652309-951830402.png)


### mget批量查询api


1、批量查询的好处

就是一条一条的查询，比如说要查询100条数据，那么就要发送100次网络请求，这个开销还是很大的
如果进行批量查询的话，查询100条数据，就只要发送1次网络请求，网络请求的性能开销缩减100倍

2、mget的语法

（1）一条一条的查询

    GET /test_index/test_type/1
    GET /test_index/test_type/2

（2）mget批量查询

    GET /_mget
    {
       "docs" : [
          {
             "_index" : "test_index",
             "_type" :  "test_type",
             "_id" :    1
          },
          {
             "_index" : "test_index",
             "_type" :  "test_type",
             "_id" :    2
          }
       ]
    }
    
    {
      "docs": [
        {
          "_index": "test_index",
          "_type": "test_type",
          "_id": "1",
          "_version": 2,
          "found": true,
          "_source": {
            "test_field1": "test field1",
            "test_field2": "test field2"
          }
        },
        {
          "_index": "test_index",
          "_type": "test_type",
          "_id": "2",
          "_version": 1,
          "found": true,
          "_source": {
            "test_content": "my test"
          }
        }
      ]
    }

（3）如果查询的document是一个index下的不同type种的话

    GET /test_index/_mget
    {
       "docs" : [
          {
             "_type" :  "test_type",
             "_id" :    1
          },
          {
             "_type" :  "test_type",
             "_id" :    2
          }
       ]
    }

（4）如果查询的数据都在同一个index下的同一个type下，最简单了

    GET /test_index/test_type/_mget
    {
       "ids": [1, 2]
    }

3、mget的重要性

可以说mget是很重要的，一般来说，在进行查询的时候，如果一次性要查询多条数据的话，那么一定要用batch批量操作的api
尽可能减少网络开销次数，可能可以将性能提升数倍，甚至数十倍，非常非常之重要






### bulk批量增删改


课程大纲

1、bulk语法

    POST /_bulk
    { "delete": { "_index": "test_index", "_type": "test_type", "_id": "3" }} 
    { "create": { "_index": "test_index", "_type": "test_type", "_id": "12" }}
    { "test_field":    "test12" }
    { "index":  { "_index": "test_index", "_type": "test_type", "_id": "2" }}
    { "test_field":    "replaced test2" }
    { "update": { "_index": "test_index", "_type": "test_type", "_id": "1", "_retry_on_conflict" : 3} }
    { "doc" : {"test_field2" : "bulk test1"} }

每一个操作要两个json串，语法如下：

    {"action": {"metadata"}}
    {"data"}

举例，比如你现在要创建一个文档，放bulk里面，看起来会是这样子的：

    {"index": {"_index": "test_index", "_type", "test_type", "_id": "1"}}
    {"test_field1": "test1", "test_field2": "test2"}

有哪些类型的操作可以执行呢？
（1）delete：删除一个文档，只要1个json串就可以了

（2）create：PUT /index/type/id/_create，强制创建

（3）index：普通的put操作，可以是创建文档，也可以是全量替换文档

（4）update：执行的partial update操作

bulk api对json的语法，有严格的要求，每个json串不能换行，只能放一行，同时一个json串和一个json串之间，必须有一个换行

    {
      "error": {
        "root_cause": [
          {
            "type": "json_e_o_f_exception",
            "reason": "Unexpected end-of-input: expected close marker for Object (start marker at [Source: org.elasticsearch.transport.netty4.ByteBufStreamInput@5a5932cd; line: 1, column: 1])\n at [Source: org.elasticsearch.transport.netty4.ByteBufStreamInput@5a5932cd; line: 1, column: 3]"
          }
        ],
        "type": "json_e_o_f_exception",
        "reason": "Unexpected end-of-input: expected close marker for Object (start marker at [Source: org.elasticsearch.transport.netty4.ByteBufStreamInput@5a5932cd; line: 1, column: 1])\n at [Source: org.elasticsearch.transport.netty4.ByteBufStreamInput@5a5932cd; line: 1, column: 3]"
      },
      "status": 500
    }
    
    {
      "took": 41,
      "errors": true,
      "items": [
        {
          "delete": {
            "found": true,
            "_index": "test_index",
            "_type": "test_type",
            "_id": "10",
            "_version": 3,
            "result": "deleted",
            "_shards": {
              "total": 2,
              "successful": 1,
              "failed": 0
            },
            "status": 200
          }
        },
        {
          "create": {
            "_index": "test_index",
            "_type": "test_type",
            "_id": "3",
            "_version": 1,
            "result": "created",
            "_shards": {
              "total": 2,
              "successful": 1,
              "failed": 0
            },
            "created": true,
            "status": 201
          }
        },
        {
          "create": {
            "_index": "test_index",
            "_type": "test_type",
            "_id": "2",
            "status": 409,
            "error": {
              "type": "version_conflict_engine_exception",
              "reason": "[test_type][2]: version conflict, document already exists (current version [1])",
              "index_uuid": "6m0G7yx7R1KECWWGnfH1sw",
              "shard": "2",
              "index": "test_index"
            }
          }
        },
        {
          "index": {
            "_index": "test_index",
            "_type": "test_type",
            "_id": "4",
            "_version": 1,
            "result": "created",
            "_shards": {
              "total": 2,
              "successful": 1,
              "failed": 0
            },
            "created": true,
            "status": 201
          }
        },
        {
          "index": {
            "_index": "test_index",
            "_type": "test_type",
            "_id": "2",
            "_version": 2,
            "result": "updated",
            "_shards": {
              "total": 2,
              "successful": 1,
              "failed": 0
            },
            "created": false,
            "status": 200
          }
        },
        {
          "update": {
            "_index": "test_index",
            "_type": "test_type",
            "_id": "1",
            "_version": 3,
            "result": "updated",
            "_shards": {
              "total": 2,
              "successful": 1,
              "failed": 0
            },
            "status": 200
          }
        }
      ]
    }

bulk操作中，任意一个操作失败，是不会影响其他的操作的，但是在返回结果里，会告诉你异常日志

    POST /test_index/_bulk
    { "delete": { "_type": "test_type", "_id": "3" }} 
    { "create": { "_type": "test_type", "_id": "12" }}
    { "test_field":    "test12" }
    { "index":  { "_type": "test_type" }}
    { "test_field":    "auto-generate id test" }
    { "index":  { "_type": "test_type", "_id": "2" }}
    { "test_field":    "replaced test2" }
    { "update": { "_type": "test_type", "_id": "1", "_retry_on_conflict" : 3} }
    { "doc" : {"test_field2" : "bulk test1"} }
    
    POST /test_index/test_type/_bulk
    { "delete": { "_id": "3" }} 
    { "create": { "_id": "12" }}
    { "test_field":    "test12" }
    { "index":  { }}
    { "test_field":    "auto-generate id test" }
    { "index":  { "_id": "2" }}
    { "test_field":    "replaced test2" }
    { "update": { "_id": "1", "_retry_on_conflict" : 3} }
    { "doc" : {"test_field2" : "bulk test1"} }

2、bulk size最佳大小

bulk request会加载到内存里，如果太大的话，性能反而会下降，因此需要反复尝试一个最佳的bulk size。一般从1000~5000条数据开始，尝试逐渐增加。另外，如果看大小的话，最好是在5~15MB之间。











