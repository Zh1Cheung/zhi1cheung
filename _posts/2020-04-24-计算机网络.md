---
title: 计算机网络基础知识（1）
categories:
- 计算机网络
tags:
- 计算机网络
---







## 协议三要素

- 语法
  - 这一段内容要符合一定的规则和格式
- 语义
  - 这一段内容要代表某种意义
- 顺序
  - 先干啥，后干啥





## MTU1500

- 最大传输单元（ Maximum Transmission Unit）

- MTU是二层MAC层的概念。MAC层有MAC的头，以太网规定MAC头带正文合起来，不允许超过1500个字节。MTU指的是IP头+IP数据部分长度

- MTU 大小是不包含二层头部和尾部的，MTU 1500表示二层MAC帧大小不超过1518. MAC 头14 字节，尾4字节。可以抓包验证

- 为什么标准以太网帧长度上限为1518字节

  - IP头total length为两个byte，理论上IP packet可以有65535 byte，加上Ethernet Frame头和尾，可以有65535 +14 + 4 = 65553 byte。如果在10Mbps以太网上，将会占用共享链路长达50ms，这将严重影响其它主机的通信，特别是对延迟敏感的应用是无法接受的。
  - 由于线路质量差而引起的丢包，发生在大包的概率也比小包概率大得多，所以大包在丢包率较高的线路上不是一个好的选择。
  - 但是如果选择一个比较小的长度，传输效率又不高，拿TCP应用来说，如果选择以太网长度为218byte，TCP payload = 218 - Ethernet Header - IP Header - TCP Header = 218 - 18 - 20 - 20 = 160 byte
  - 那有效传输效率= 160 / 218 = 73%
  - 而如果以太网长度为1518，那有效传输效率= 1460 / 1518 = 96%
  - 通过比较，选择较大的帧长度，有效传输效率更高，而更大的帧长度同时也会造成上述的问题，于是最终选择一个折衷的长度：1518 byte ! 对应的IP packet 就是 1500 byte，这就是最大传输单元MTU的由来。

  



## 无类型域间选路（CIDR）

- 32位的IP地址一分为二，前面是网络号，后面是主机号

  - > 10.100.122.2/24
    > 	后面24的意思是，32位中，前24位是网络号，后8位是主机号。





## 动态主机配置协议（DHCP）

- 他只需要配置一段共享的IP地址。每一台新接入的机器都通DHCP协议，来这个共享的IP地址里申请，然后自动配置好就可以了。
  - 如果是数据中心里面的服务器，IP一旦配置好，基本不会变，这就相当于买房自己装修。DHCP的方式就相当于租房。你不用装修，都是帮你配置好的。你暂时用一下，用完退租就可以了。





## 预启动执行环境（PXE）

- 网络管理员不仅能自动分配IP地址，还能帮你自动安装操作系统！
- 所以管理员希望的不仅仅是自动分配IP地址，还要自动安装系统。装好系统之后自动分配IP地址，直接启动就能用了，这样当然最好了！
  - 首先，启动BIOS。这是一个特别小的小系统，只能干特别小的一件事情。其实就是读取硬盘的MBR启动扇区，将GRUB启动起来；然后将权力交给GRUB，GRUB加载内核、加载作为根文件系统的initramfs文件；然后将权力交给内核；最后内核启动，初始化整个操作系统。





## 数据链路层

- ARP协议，也就是已知IP地址，求MAC地址的协议。
- 交换机怎么知道每个口的电脑的MAC地址呢？这需要交换机会学习。
  - 一台MAC1电脑将一个包发送给另一台MAC2电脑，当这个包到达交换机的时候，一开始交换机也不知道MAC2的电脑在哪个口，所以没办法，它只能将包转发给除了来的那个口之外的其他所有的口。
  - 交换机会记住，MAC1是来自一个明确的口。以后有包的目的地址是MAC1的，直接发送到这个口就可以了。
  - 当交换机作为一个关卡一样，过了一段时间之后，就有了整个网络的一个结构了，这个时候，基本上不用广播了，全部可以准确转发。当然，每个机器的IP地址会变，所在的口也会变，因而交换机上的学习的结果，我们称为转发表，是有一个过期时间的。
- 广播风暴
  - ARP广播时，交换机会将一个端口收到的包转发到其它所有的端口上
  - 比如数据包经过交换机A到达交换机B，交换机B又将包复制为多份广播出去。如果整个局域网存在一个环路，使得数据包又重新回到了最开始的交换机A，这个包又会被A再次复制多份广播出去。如此循环，数据包会不停得转发，而且越来越多，最终占满带宽，或者使解析协议的硬件过载，行成广播风暴。





## 交换机与 VLAN

- STP协议

  - 最小生成树，计算机网络中，生成树的算法叫作STP

  - Priority Vector，优先级向量。可以比喻为实力 （值越小越牛）

    - > [Root Bridge ID, Root Path Cost, Bridge ID, and Port ID]
      >
      > ​	老大的ID
      > ​	我距离我的老大的距离
      > ​	我自己的ID

- 如何解决广播问题和安全问题？

  - VLAN，或者叫虚拟局域网
    - 使用VLAN，一个交换机上会连属于多个局域网的机器，那交换机怎么区分哪个机器属于哪个局域网呢？
    - 我们只需要在原来的二层的头上加一个TAG，里面有一个VLAN ID，一共12位。为什么是12位呢？因为12位可以划分4096个VLAN。
    - 只有相同VLAN的包，才会互相转发，不同VLAN的包，是看不到的。这样广播问题和安全问题就都能够解决了。
  - 交换机之间怎么连接呢
    - 对于支持VLAN的交换机，有一种口叫作Trunk口。可以允许多个VLAN通过,可以接收和发送多个VLAN 报文。交换机之间可以通过这种口相互连接。

  





## ICMP与ping

- ICMP协议的格式
  - ping是基于ICMP协议工作的。ICMP，就是互联网控制报文协议。这里面的关键词是“控制”，那具体是怎么控制的呢？
  - ICMP报文是封装在IP包里面的。
- 查询报文类型
  - 常用的ping就是查询报文，是一种主动请求，并且获得主动应答的ICMP协议。
- 差错报文类型
  - 举几个ICMP差错报文的例子：终点不可达为3，源抑制为4，超时为11，重定向为5







## 网关

- 在任何一台机器上，当要访问另一个IP地址的时候，都会先判断，这个目标IP地址，和当前机器的IP地址，是否在同一个网段。怎么判断同一个网段呢？需要CIDR和子网掩码
  - 如果不是同一网段，这就需要发往默认网关Gateway
  - 网关往往是一个路由器，是一个三层转发的设备
    - 把MAC头和IP都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备。
    - 很多情况下，人们把网关就叫作路由器。其实不完全准确，而另一种比喻更加恰当：路由器是一台设备，它有五个网口或者网卡，相当于有五只手，分别连着五个局域网。每只手的IP地址都和局域网的IP地址相同的网段，每只手都是它握住的那个局域网的网关。
    - 任何一个想发往其他局域网的包，都会到达其中一只手，被拿进来，拿下MAC头和IP头，看看，根据自己的路由算法，选择另一只手，加上IP头和MAC头，然后扔出去。
- 静态路由，其实就是在路由器上，配置一条一条规则。
- IP头和MAC头哪些变、哪些不变？
  - MAC地址是一个局域网内才有效的地址，MAC地址只要过网关，就必定会改变，因为已经换了局域网。两者主要的区别在于IP地址是否改变。不改变IP地址的网关，我们称为转发网关；改变IP地址的网关，我们称为NAT网关
  - 现在大家每家都有家用路由器，家里的网段都是192.168.1.x，所以你肯定访问不了你邻居家的这个私网的IP地址的。所以，当我们家里的包发出去的时候，都被家用路由器NAT成为了运营商的地址了。







## 路由协议

- 如何配置路由

  - 路由器就是一台网络设备，它有多张网卡。当一个入口的网络包送到路由器时，它会根据一个本地的转发信息库，来决定如何正确地转发流量。这个转发信息库通常被称为路由表。

  - > 一张路由表中会有多条路由规则。每一条规则至少包含这三项信息
    > 	目的网络
    > 	出口设备
    > 	下一跳网关
    >
    > 
    >
    > 通过route命令和ip route命令都可以进行查询或者配置
    > 	ip route add 10.176.48.0/20 via 10.173.32.1 dev eth0
    > 	10.176.48.0/20这个目标网络，要从eth0端口出去，经过10.173.32.1。

- 如何配置策略路由

  - 除了可以根据目的ip地址配置路由外，还可以根据多个参数来配置路由，这就称为策略路由。

    - > ip rule add from 192.168.1.0/24 table 10 
      >
      > ip rule add from 192.168.2.0/24 table 20
      >
      > 表示从192.168.1.10/24这个网段来的，使用table 10中的路由表
      >
      > 而从192.168.2.0/24网段来的，使table20的路由表。
      >
      > 
      >
      > ip route add default via 60.190.27.189 dev eth3 table chao

    - > 在一条路由规则中，也可以走多条路径
      >
      > ip route add default scope global nexthop via 100.100.100.1 weight 1 nexthop via 200.200.200.1 weight 2
      >
      > 下一跳有两个地方，分别是100.100.100.1和200.200.200.1，权重分别为1比2。

- 动态路由算法

  - 距离矢量路由算法
    - 这种算法的基本思路是，每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是要到目标路由器，从那条线出去，另一个是到目标路由器的距离。
    - 每个路由器都知道自己和邻居之间的距离，每过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。
    - 第一个问题就是好消息传得快，坏消息传得慢。
    - 第二个问题是，每次发送的时候，要发送整个全局路由表
  - 链路状态路由算法
    - 当一个路由器启动的时候，首先是发现邻居，向邻居say hello，邻居都回复。然后计算和邻居的距离，发送一个echo，要求马上返回，除以二就是距离。然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。这样每个路由器都能够收到它和邻居之间的关系的信息。因而，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用Dijkstra算法，找到两点之间的最短路径。
    - 不像距离距离矢量路由协议那样，更新时发送整个路由表。链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了带宽和CPU利用率。而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛。

- 动态路由协议

  - 基于距离矢量路由算法的BGP
    - 我们称为外网路由协议（BGP）
    - 每个自治系统都有边界路由器，通过它和外面的世界建立联系。
  - 基于链路状态路由算法的OSPF(开放式最短路径优先)
    - 主要用在数据中心内部，用于路由决策，因而称为内部网关协议（IGP）。
    - 有了等价路由，到一个地方去可以有相同的两个路线，可以分摊流量，还可以当一条路不通的时候，走另外一条路
      - 一般应用的接入层会有负载均衡LVS。它可以和OSPF一起，实现高吞吐量的接入层设计。
  - BGP基于TCP，OSPF基于UDP 







## UDP协议

- TCP和UDP有哪些区别？

  - TCP是面向连接的，UDP是面向无连接的
    - 所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。
  - TCP提供可靠交付,通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达。
    - UDP继承了IP的特性，不保证不丢失，不保证按顺序到达。
  - TCP是面向字节流的。
    - 而UDP继承了IP的特性，基于数据报的，一个一个地发，一个一个地收。
  - TCP是可以有拥塞控制的
- MAC层定义了本地局域网的传输行为，IP层定义了整个网络端到端的传输行为
- 当我们看到UDP包头的时候，有源端口号和目标端口号,UDP除了端口号，再没有其他的了
- UDP的三大使用场景

  - 需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用
    - DHCP就是基于UDP协议的
  - 不需要一对一沟通，建立连接，而是可以广播的应用
    - UDP的不面向连接的功能，可以使得可以承载广播或者多播的协议。DHCP就是一种广播的形式，就是基于UDP协议的。
  - 需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候。（当前很多应用都是要求低时延的）
- 基于UDP的“城会玩”的例子

  - 网页或者APP的访问

    - 目前的HTTP协议，往往采取多个数据通道共享一个连接的情况，这样本来为了加快传输速度，但是TCP的严格顺序策略使得哪怕共享通道，前一个不来，后一个和前一个即便没关系，也要等着，时延也会加大。
    - QUIC（全称Quick UDP Internet Connections，快速UDP互联网连接）

  - 流媒体的协议

    - 直播

  - 实时游戏

    - 游戏对实时要求较为严格的情况下，采用自定义的可靠UDP协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成的影响。

  - IoT物联网

    - 物联网领域终端资源少
    - 物联网对实时性要求也很高
- UDP 常用于以下几个方面： 1.包总量较少的通信（DNS、SNMP等）； 2.视频、音频等多媒体通信（即时通信）； 3.限定于 LAN 等特定网络中的应用通信； 4.广播通信（广播、多播）。
  - 而且以现在的应用场景，UDP协议一般用作短消息的传输，或者对结果的完整度没有太高要求的情况，比如，音频、视频等普通数据，即使丢几个包，对结果的影响也不会太大，但是UDP对网络质量要求较高，尤其是处理大文件数据时，大面积的丢包会使文件直接损坏，根本无法使用 
- **TCP和UDP可以同时监听相同的端口吗**
  - 使用netstat -an自己看看就知道了，IP数据包首部有个叫做协议的字段，指出了上层协议是TCP还是UDP还是其他P。
    协议字段（报头检验和前面那个），其值为6，则为TCP；
    其值为17，则为UDP。
  - Stack overflow:许多协议已经做到了这一点，例如DNS可在udp / 53和tcp / 53上运行。

## TCP协议

- TCP包头格式

  - 源端口号和目标端口号

  - 序号。解决乱序的问题

  - 确认序号。发出去的包应该有确认

  - 状态位。SYN是发起一个连接，ACK是回复，RST是重新连接，FIN是结束连接等

  - 窗口大小。TCP要做流量控制

  - > 顺序问题 ，稳重不乱；
    > 丢包问题，承诺靠谱；
    > 连接维护，有始有终；
    > 流量控制，把握分寸；
    > 拥塞控制，知进知退。

- TCP的三次握手

  - 进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备。实质上其实就是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号，交换TCP窗口大小信息。
  - TCP初始序列号为什么是随机的
    - 在TCP的三次握手中，采用随机产生的初始化序列号进行请求，这样做主要是出于网络安全的因素着想。如果不是随机产生初始序列号，黑客将会以很容易的方式获取到你与其他主机之间通信的初始化序列号，并且伪造序列号进行攻击，这已经成为一种很常见的网络攻击手段。
  - 第三次握手的原因
    - 避免已经失效的连接请求报文段占用服务器的连接资源。
    - 假如A发送的连接请求报文段并没有丢失，而是因为在某些网络节点长时间滞留，在收到A发送的这个已失效的请求报文段之后，没有第三次握手的确认
    - 造成一种假象：B认为和A的连接已经建立，一直等待A发送数据，而A认为自己没有发送请求连接，不理睬B的确认。
  - 过程
    - A：SYN=1 seq=x
    - B：SYN=1 ACK=1 seq=y ack=x+1
    - A：ACK=1 seq=x+1 ack=y+1
  - 过程
  - 一开始，客户端和服务端都处于CLOSED状态。先是服务端主动监听某个端口，处于LISTEN状态。
    - 客户端主动发起连接SYN，之后处于SYN-SENT状态。
    - 服务端收到发起的连接，返回SYN,ACK客户端的SYN，之后处于SYN-RCVD状态
    - 客户端收到服务端发送的SYN和ACK之后，发送ACK的ACK，之后处于ESTABLISHED状态，因为它一发一收成功了
    - 服务端收到ACK的ACK之后，处于ESTABLISHED状态，因为它也一发一收了。

- 状态

  > LISTEN - 侦听来自远方TCP端口的连接请求； 
  > SYN-SENT -在发送连接请求后等待匹配的连接请求； 
  > SYN-RECEIVED - 在收到和发送一个连接请求后等待对连接请求的确认； 
  > ESTABLISHED- 代表一个打开的连接，数据可以传送给用户； 
  > FIN-WAIT-1 - 等待远程TCP的连接中断请求，或先前的连接中断请求的确认；
  > FIN-WAIT-2 - 从远程TCP等待连接中断请求；
  > CLOSE-WAIT - 等待从本地用户发来的连接中断请求； 
  > CLOSING -等待远程TCP对连接中断的确认； 
  > LAST-ACK - 等待原来发向远程TCP的连接中断请求的确认； 
  > TIME-WAIT -等待足够的时间以确保远程TCP接收到连接中断请求的确认； 
  > CLOSED - 没有任何连接状态；

  

- TCP四次挥手

  - 因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，“你发的FIN报文我收到了”。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。

  - 过程

    - A：FIN=1 seq=u
    - B：ACK=1 seq=v ack=u+1
    - B：FIN=1 ACK=1 seq=w ack=u+1
    - A：ACK=1 seq=u+1 ack=w+1

  - 过程

    - 刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求，则：

      1、第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于**CLOSED_WAIT1**状态。

      2、第二次握手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 **CLOSE_WAIT2**状态。

      3、第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 **LAST_ACK** 的状态。

      4、第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 **TIME_WAIT** 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态

      5、服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。

    - 按说A可以跑路了，但是最后的这个ACK万一B收不到呢？

      - 则B会重新发一个“B不玩了”，这个时候A已经跑路了的话，B就再也收不到ACK了，因而TCP协议要求A最后等待一段时间TIME_WAIT
      - 这个时间要足够长，长到如果B没收到ACK的话，“B说不玩了”会重发的，A会重新发一个ACK并且足够时间到达B。
      - A直接跑路还有一个问题是，A的端口就直接空出来了，但是B不知道，B原来发过的很多包很可能还在路上，如果A的端口被一个新的应用占用了，这个新的应用会收到上个连接中B发过来的包
      - B超过了2MSL的时间，依然没有收到它发的FIN的ACK，怎么办呢？按照TCP的原理，B当然还会重发FIN，这个时候A再收到这个包之后，A就表示，我已经在这里等了这么长时间了，已经仁至义尽了，之后的我就都不认了，于是就直接发送RST，B就知道A早就跑了。
        - RFC 793 中虽然指出了 TCP 连接需要在 `TIME_WAIT` 中**等待 2 倍的 MSL**，但是并没有解释清楚这里的两倍是从何而来，比较合理的解释是 — 网络中可能存在来自发起方的数据段，当这些发起方的数据段被服务端处理后又会向客户端发送响应，所以一来一回需要等待 2 倍的时间[5](https://draveness.me/whys-the-design-tcp-time-wait/#fn:5)。
        - **RFC 793 文档将 MSL 的时间设置为 120 秒，即两分钟**，然而这并不是一个经过严密推断的数值，而是工程上的选择，如果根据服务历史上的经验要求我们改变操作系统的设置，也是没有任何问题的；实际上，较早版本的 Linux 就开始将 `TIME_WAIT` 的等待时间 [`TCP_TIMEWAIT_LEN`](https://github.com/torvalds/linux/blob/bd2463ac7d7ec51d432f23bf0e893fb371a908cd/include/net/tcp.h#L121) 设置成 60 秒，以便更快地复用 TCP 连接资源

  - **TCP 的 `TIME_WAIT` 状态有着非常重要的作用，它是保证 TCP 协议可靠性不可缺失的设计**

  - **`TIME_WAIT` 只在主动断开连接的一方出现**，被动断开连接的一方会直接进入 `CLOSED` 状态，进入 `TIME_WAIT` 的客户端需要等待 2 MSL 才可以真正关闭连接。**TCP 协议需要 `TIME_WAIT` 状态的原因和客户端需要等待两个 MSL 不能直接进入 `CLOSED` 状态的原因是一样的**：

    - 防止延迟的数据段被其他使用相同源地址、源端口、目的地址以及目的端口的 TCP 连接收到；

    - 保证 TCP 连接的远程被正确关闭，即等待被动关闭连接的一方收到 `FIN` 对应的 `ACK` 消息；

      - 从 RFC 793 对 `TIME_WAIT` 状态的定义中，我们可以发现该状态的另一个重要作用，等待足够长的时间以确定远程的 TCP 连接接收到了其发出的终止连接消息 `FIN` 对应的 `ACK`
      - 如果客户端等待的时间不够长，当服务端还没有收到 `ACK` 消息时，客户端就重新与服务端建立 TCP 连接就会造成以下问题 — 服务端因为没有收到 `ACK` 消息，所以仍然认为当前连接是合法的，客户端重新发送 `SYN` 消息请求握手时会收到服务端的 `RST` 消息，连接建立的过程就会被终止

    - **TIME-WAIT 较短导致的握手终止**

      - 在默认情况下，**如果客户端等待足够长的时间就会遇到以下两种情况**：

      1. 服务端正常收到了 `ACK` 消息并关闭当前 TCP 连接；
      2. 服务端没有收到 `ACK` 消息，重新发送 `FIN` 关闭连接并等待新的 `ACK` 消息；

      - **只要客户端等待 2 MSL 的时间，客户端和服务端之间的连接就会正常关闭，新创建的 TCP 连接收到影响的概率也微乎其微，保证了数据传输的可靠性。**
      - **TCP 的 `TIME_WAIT` 状态有着非常重要的作用，它是保证 TCP 协议可靠性不可缺失的设计**，如果能通过加机器解决的话就尽量加机器，如果不能解决的话，我们就需要理解其背后的设计原理并尽可能避免修改默认的配置，就像 Linux 手册中说的一样，在修改这些配置时应该咨询技术专家的建议；在这里，我们再重新回顾一下 TCP 协议中 `TIME_WAIT` 状态存在的原因，**如果客户端等待的时间不够长，那么使用相同端口号重新与远程建立连接时会造成以下问题**：
        - 因为数据段的网络传输时间不确定，所以可能会收到上一次 TCP 连接中未被收到的数据段；
        - 因为客户端发出的 `ACK` 可能还没有被服务端接收，服务端可能还处于 `LAST_ACK` 状态，所以它会回复 `RST` 消息终止新连接的建立；

- 顺序问题和丢包问题都有可能发生，所以我们先来看确认与重发的机制。

  - 时间必须大于往返时间RTT，否则会引起不必要的重传
    - 超时间隔加倍。每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送
  - 超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？
    - 有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。
    - 例如，接收方发现6、8、9都已经接收了，就是7没来，那肯定是丢了，于是发送三个6的ACK，要求下一个是7。客户端收到3个，就会发现7的确又丢了，不等超时，马上重发。
  - 还有一种方式称为Selective Acknowledgment （SACK）。这种方式需要在TCP头里加一个SACK的东西，可以将缓存的地图发送给发送方。例如可以发送ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是7丢了

- tcp如何实现可靠性传输

  - 确认机制、重传机制、滑动窗口

- 流量控制问题

  - 滑动窗口
  - 发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。

- 拥塞控制问题

  - 拥塞控制的问题，也是通过窗口的大小来控制的
  - 滑动窗口rwnd是怕发送方把接收方缓存塞满，而拥塞窗口cwnd，是怕把网络塞满。
    - TCP发送包常被比喻为往一个水管里面灌水，而TCP的拥塞控制就是在不堵塞，不丢包的情况下，尽量发挥带宽。
  - TCP的拥塞控制主要来避免两种现象，包丢失和超时重传
    - 一旦出现了这些现象就说明，发送速度太快了
  - 慢启动、指数增长、超过sshresh后线性增长、拥塞后这个时候，将sshresh设为cwnd/2，将cwnd设为1，重新开始慢启动。
    - 快速重传算法：cwnd减半为cwnd/2，然后sshthresh = cwnd，线性增长
  - TCP的拥塞控制主要来避免的两个现象都是有问题的。
    - 第一个问题是丢包并不代表着通道满了，也可能是管子本来就漏水
    - 第二个问题是TCP的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实TCP只要填满管道就可以了，不应该接着填，直到连缓存也填满。

- TCP BBR拥塞算法

  - 企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。
  - 设备缓存会导致延时
    - 假如经过设备的包都不需要进入缓存，那么得到的速度是最快的。进入缓存且等待，等待的时间就是额外的延时。BBR就是为了避免这些问题。
    - 充分利用带宽；降低buffer占用率。
  - 快速下降后重新慢启动，整个过程对于带宽来说是浪费的。
  - BBR如何解决延时
    - S1：慢启动开始时，以前期的延迟时间为延迟最小值Tmin。然后监控延迟值是否达到Tmin的n倍
      - 达到这个阀值后，判断带宽已经消耗尽并且使用了一定的缓存，进入排空阶段。
    - S2：指数降低发送速率，直至延迟不再降低
    - S3：协议进入稳定运行状态。交替探测带宽和延迟，且大多数时间下都处于带宽探测阶段。
  - BBR是如何探测最大带宽和最小延时呢？首先有一点就是最大带宽和最小延时是无法同时得到的。
    - 探测最大带宽的方法就是尽量多发数据，把网络中的buffer占满，带宽在一段时间内不会增加，这样可以得到此时的最大带宽。
    - 探测最小RTT的方法就是尽量把buffer腾空，让数据交付延时尽量低。
    - 由此，BBR就引入了基于不同探测阶段的状态机。

- **顺序问题、丢包问题、流量控制都是通过滑动窗口来解决的**

- **拥塞控制是通过拥塞窗口来解决的，**相当于往管道里面倒水，快了容易溢出，慢了浪费带宽，要摸着石头过河，找到最优值。

- 应用场景

  - ![img](https://pic4.zhimg.com/v2-06bdd52997add27938607b33edea4068_b.jpg)

- TCP 适合金融等大多数领域，UDP适合游戏和娱乐场景

  当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP（如视频传输、实时通信等）。


- **如果服务端的机器挂了，而客户端去连接会发生什么？如果是服务端的进程挂了，客户端去连接会发生什么？**

  - 如果是机器挂了，说明操作系统也没了，那么客户端在建立连接的时候，只会发送第一次握手的包，当然收不到，然后重试几次，就不试了。
  - 如果是进程挂了，那么操作系统还在，操作系统会代替进程向客户端发送一个RESET的包，此时客户端就知道通信的那个进程没了，直接关闭连接。

- 长连接与短连接

  **TCP 本身并没有长短连接的区别** ，长短与否，完全取决于我们怎么用它。

  - 短连接：每次通信时，创建 Socket；一次通信结束，调用 socket.close()。这就是一般意义上的短连接，短连接的好处是管理起来比较简单，存在的连接都是可用的连接，不需要额外的控制手段。
  - 长连接：每次通信完毕后，不会关闭连接，这样可以做到连接的复用。 **长连接的好处是省去了创建连接的耗时。**

  短连接和长连接的优势，分别是对方的劣势。想要图简单，不追求高性能，使用短连接合适，这样我们就不需要操心连接状态的管理；想要追求性能，使用长连接，我们就需要担心各种问题：比如 **端对端连接的维护，连接的保活** 。

  长连接还常常被用来做数据的推送，我们大多数时候对通信的认知还是 request/response 模型，但 TCP 双工通信的性质决定了它还可以被用来做双向通信。在长连接之下，可以很方便的实现 push 模型。

- 连接的保活

  这个话题就有的聊了，会牵扯到比较多的知识点。首先需要明确一点，为什么需要连接的保活？当双方已经建立了连接，但因为网络问题，链路不通，这样长连接就不能使用了。需要明确的一点是，通过 netstat，lsof 等指令查看到连接的状态处于 `ESTABLISHED` 状态并不是一件非常靠谱的事，因为连接可能已死，但没有被系统感知到，更不用提假死这种疑难杂症了。如果保证长连接可用是一件技术活。


   - 连接的保活：KeepAlive

     首先想到的是 TCP 中的 KeepAlive 机制。KeepAlive 并不是 TCP 协议的一部分，但是大多数操作系统都实现了这个机制（所以需要在操作系统层面设置 KeepAlive 的相关参数）。KeepAlive 机制开启后，在一定时间内（一般时间为 7200s，参数 `tcp_keepalive_time`）在链路上没有数据传送的情况下，TCP 层将发送相应的 KeepAlive 探针以确定连接可用性，探测失败后重试 10（参数 `tcp_keepalive_probes`）次，每次间隔时间 75s（参数 `tcp_keepalive_intvl`），所有探测失败后，才认为当前连接已经不可用。

     在 Netty 中开启 KeepAlive：

     ```
     bootstrap.option(ChannelOption.SO_KEEPALIVE, true)
     ```

     Linux 操作系统中设置 KeepAlive 相关参数，修改 `/etc/sysctl.conf` 文件：

     ```
     net.ipv4.tcp_keepalive_time=90
     net.ipv4.tcp_keepalive_intvl=15
     net.ipv4.tcp_keepalive_probes=2
     ```

     **KeepAlive 机制是在网络层面保证了连接的可用性** ，但站在应用框架层面我们认为这还不够。主要体现在三个方面：

     - KeepAlive 的开关是在应用层开启的，但是具体参数（如重试测试，重试间隔时间）的设置却是操作系统级别的，位于操作系统的 `/etc/sysctl.conf` 配置中，这对于应用来说不够灵活。
     - KeepAlive 的保活机制只在链路空闲的情况下才会起到作用，假如此时有数据发送，且物理链路已经不通，操作系统这边的链路状态还是 `ESTABLISHED`，这时会发生什么？自然会走 TCP 重传机制，要知道默认的 TCP 超时重传，指数退避算法也是一个相当长的过程。
     - KeepAlive 本身是面向网络的，并不面向于应用，当连接不可用，可能是由于应用本身的 GC 频繁，系统 load 高等情况，但网络仍然是通的，此时，应用已经失去了活性，连接应该被认为是不可用的。

     我们已经为应用层面的连接保活做了足够的铺垫，下面就来一起看看，怎么在应用层做连接保活。

   - 连接的保活：应用层心跳

     终于点题了，文题中提到的 **心跳** 便是一个本文想要重点强调的另一个重要的知识点。上一节我们已经解释过了，网络层面的 KeepAlive 不足以支撑应用级别的连接可用性，本节就来聊聊应用层的心跳机制是实现连接保活的。

     如何理解应用层的心跳？简单来说，就是客户端会开启一个定时任务，定时对已经建立连接的对端应用发送请求（这里的请求是特殊的心跳请求），服务端则需要特殊处理该请求，返回响应。如果心跳持续多次没有收到响应，客户端会认为连接不可用，主动断开连接。不同的服务治理框架对心跳，建连，断连，拉黑的机制有不同的策略，但大多数的服务治理框架都会在应用层做心跳，Dubbo/HSF 也不例外。

   - 应用层心跳的设计细节

     以 Dubbo 为例，支持应用层的心跳，客户端和服务端都会开启一个 `HeartBeatTask`，客户端在 `HeaderExchangeClient` 中开启，服务端将在 `HeaderExchangeServer` 开启。文章开头埋了一个坑：Dubbo 为什么在服务端同时维护 `Map<String,Channel>` 呢？主要就是为了给心跳做贡献，心跳定时任务在发现连接不可用时，会根据当前是客户端还是服务端走不同的分支，客户端发现不可用，是重连；服务端发现不可用，是直接 close。

   - 注意和 HTTP 的 KeepAlive 区别对待

     - HTTP 协议的 KeepAlive 意图在于连接复用，同一个连接上串行方式传递请求 - 响应数据
     - TCP 的 KeepAlive 机制意图在于保活、心跳，检测连接错误。

   


## 套接字 Socket

- 基于TCP协议的Socket程序函数调用过程
  - TCP的服务端要先监听一个端口，一般是先调用bind函数
  - 在内核中，为每个Socket维护两个队列。一个是已经建立了连接的队列，这时候连接三次握手已经完毕，处于established状态；一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于syn_rcvd的状态。
  - 当服务端有了IP和端口号，就可以调用listen函数进行监听
  - 接下来，服务端调用accept函数，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。
  - 在服务端等待的时候，客户端可以通过connect函数发起连接，内核会给客户端分配一个临时的端口。一旦握手成功，服务端的accept就会返回另一个Socket。
    - 监听的 Socket 和真正用来传数据的 Socket 是两个，一个叫作监听 Socket，一个叫作已连接 Socket。
  - 连接建立成功之后，双方开始通过read和write函数来读写数据
  - ![img](https://static001.geekbang.org/resource/image/77/92/77d5eeb659d5347874bda5e8f711f692.jpg)
  - TCP 的 Socket 就是一个文件流，是非常准确的。因为，Socket 在 Linux 中就是以文件的形式存在的。除此之外，还存在文件描述符。写入和读出，也是通过文件描述符。
    - 在内核中，Socket 是一个文件，那对应就有文件描述符。每一个进程都有一个数据结构 task_struct，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。文件描述符是一个整数，是这个数组的下标。
    - 这个数组中的内容是一个指针，指向内核中所有打开的文件的列表。既然是一个文件，就会有一个 inode，只不过 Socket 对应的 inode 不像真正的文件系统一样，保存在硬盘上的，而是在内存中的。在这个 inode 中，指向了 Socket 在内核中的 Socket 结构。
    - 在这个结构里面，主要的是两个队列，一个是发送队列，一个是接收队列。在这两个队列里面保存的是一个缓存 sk_buff。这个缓存里面能够看到完整的包的结构
- 基于UDP协议的Socket程序函数调用过程
  - UDP是没有连接的，所以不需要三次握手，也就不需要调用listen和connect，但是，UDP的的交互仍然需要IP和端口号，因而也需要bind。
  - UDP是没有维护连接状态的，因而不需要每对连接建立一组Socket，而是只要有一个Socket，就能够和多个客户端通信
  - 每次通信的时候，都调用sendto和recvfrom，都可以传入IP地址和端口。
  - ![img](https://static001.geekbang.org/resource/image/77/ef/778687d1a02ffc0c24078c33be2ac1ef.jpg)
- 手写socket
  - http://www.52im.net/thread-1722-1-1.html
- 服务端最大并发 TCP 连接数远不能达到理论上限。首先主要是文件描述符限制，按照上面的原理，Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目；另一个限制是内存，按上面的数据结构，每个 TCP 连接都要占用一定内存，操作系统是有限的。
  - 多进程方式
    - 这就相当于你是一个代理，在那里监听来的请求。一旦建立了一个连接，就会有一个已连接 Socket，这时候你可以创建一个子进程，然后将基于已连接 Socket 的交互交给这个新的子进程来做。
    - 在 Linux 下，创建子进程使用 fork 函数。通过名字可以看出，这是在父进程的基础上完全拷贝一个子进程。在 Linux 内核中，会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到了哪一行程序的进程。显然，复制的时候在调用 fork，复制完毕之后，父进程和子进程都会记录当前刚刚执行完 fork。这两个进程刚复制完的时候，几乎一模一样，只是根据 fork 的返回值来区分到底是父进程，还是子进程。如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。
    - 因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的，因而父进程刚才因为 accept 创建的已连接 Socket 也是一个文件描述符，同样也会被子进程获得。
    - 接下来，子进程就可以通过这个已连接 Socket 和客户端进行互通了，当通信完毕之后，就可以退出进程，那父进程如何知道子进程干完了项目，要退出呢？还记得 fork 返回的时候，如果是整数就是父进程吗？这个整数就是子进程的 ID，父进程可以通过这个 ID 查看子进程是否完成项目，是否需要退出。
  - 多线程方式
    - 在 Linux 下，通过 pthread_create 创建一个线程，也是调用 do_fork。不同的是，虽然新的线程在 task 列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，还是共享的，只不过多了一个引用而已。
    - 新的线程也可以通过已连接 Socket 处理请求，从而达到并发处理的目的。上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程。一台机器无法创建很多进程或者线程。
    - 有个 C10K，它的意思是一台机器要维护 1 万个连接，就要创建 1 万个进程或者线程，那么操作系统是无法承受的。如果维持 1 亿用户在线需要 10 万台服务器，成本也太高了。
  - IO 多路复用：一个线程维护多个 Socket
    - 由于 Socket 是文件描述符，因而某个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中，这就是项目进度墙，然后调用 select 函数来监听文件描述符集合是否有变化。一旦有变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化。
  - IO 多路复用：从“派人盯着”到“有事通知“
    - 上面 select 函数还是有问题的，因为每次 Socket 所在的文件描述符集合中有 Socket 发生变化的时候，都需要通过轮询的方式，也就是需要将全部项目都过一遍的方式来查看进度，这大大影响了一个项目组能够支撑的最大的项目数量。因而使用 select，能够同时盯的项目数量由 FD_SETSIZE 限制。
    - 如果改成事件通知的方式，情况就会好很多，项目组不需要通过轮询挨个盯着这些项目，而是当项目进度发生变化的时候，主动通知项目组，然后项目组再根据项目进展情况做相应的操作。能完成这件事情的函数叫 epoll，它在内核中的实现不是通过轮询的方式，而是通过注册 callback 函数的方式，当某个文件描述符发送变化的时候，就会主动通知。
    - 假设进程打开了 Socket m, n, x 等多个文件描述符，现在需要通过 epoll 来监听是否这些 Socket 都有事件发生。其中 epoll_create 创建一个 epoll 对象，也是一个文件，也对应一个文件描述符，同样也对应着打开文件列表中的一项。在这项里面有一个红黑树，在红黑树里，要保存这个 epoll 要监听的所有 Socket。
    - 当 epoll_ctl 添加一个 Socket 的时候，其实是加入这个红黑树，同时红黑树里面的节点指向一个结构，将这个结构挂在被监听的 Socket 的事件列表中。当一个 Socket 来了一个事件的时候，可以从这个列表中得到 epoll 对象，并调用 call back 通知它。
    - 这种通知方式使得监听的 Socket 数据增加的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了。上限就为系统定义的、进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题的利器。











