---
title: elasticsearch(十二)
categories:
- ELK
tags:
- elasticsearch


---


### 基于doc value正排索引的聚合内部原理



聚合分析的内部原理是什么？？？？aggs，term，metric avg max，执行一个聚合操作的时候，内部原理是怎样的呢？用了什么样的数据结构去执行聚合？是不是用的倒排索引？

搜索+聚合，写个示例

    GET /test_index/test_type/_search 
    {
    	"query": {
    		"match": {
    			"search_field": "test"
    		}
    	},
    	"aggs": {
    		"group_by_agg_field": {
    			"terms": {
    				"field": "agg_field"
    			}
    		}
    	}
    }

纯用倒排索引来实现的弊端

es肯定不是纯用倒排索引来实现聚合+搜索的

    search_field
    
    doc1: hello world test1, test2
    doc2: hello test
    doc3: world	test
    
    hello	doc1,doc2
    world	doc1,doc3
    test1	doc1
    test2	doc1
    test 	doc2,doc3
    
    "query": {
    	"match": {
    		"search_field": "test"
    	}
    }
    
    test --> doc2,doc3 --> search result, doc2,doc3
    
    agg_field
    
    doc2: agg1
    doc3: agg2


    100万个值
    ...
    ...
    ...
    ...
    agg1	doc2
    agg2	doc3

doc2, doc3, search result --> 实际上，要搜索到doc2的agg_field的值是多少，doc3的agg_field的值是多少

doc2和doc3的agg_field的值之后，就可以根据值进行分组，实现terms bucket操作

doc2的agg_field的值是多少，这个时候，如果你手上只有一个倒排索引，你该怎么办？？？你要扫描整个倒排索引，去一个一个的搜，拿到每个值，比如说agg1，看一下，它是不是doc2的值，拿到agg2,看一下，是不是doc2的值，直到找到doc2的agg_field的值，在倒排索引中

如果用纯倒排索引去实现聚合，现实不现实啊？？？性能是很低下的。。。搜索，search，搜倒排索引，搜那个term，就结束了。。。聚合，搜索出了1万个doc，每个doc都要在倒排索引中搜索出它的那个聚合field的值

倒排索引+正排索引（doc value）的原理和优势

doc value：正排索引

    search_field
    
    doc1: hello world test1, test2
    doc2: hello test
    doc3: world	test
    
    hello	doc1,doc2
    world	doc1,doc3
    test1	doc1
    test2	doc1
    test 	doc2,doc3
    
    "query": {
    	"match": {
    		"search_field": "test"
    	}
    }
    
    test --> doc2,doc3 --> search result, doc2,doc3

doc value数据结构，正排索引



    ...
    ...
    ...
    100万个
    doc2: agg1
    doc3: agg2

倒排索引的话，必须遍历完整个倒排索引才可以。。。。

因为可能你要聚合的那个field的值，是分词的，比如说hello world my name --> 一个doc的聚合field的值可能在倒排索引中对应多个value

所以说，当你在倒排索引中找到一个值，发现它是属于某个doc的时候，还不能停，必须遍历完整个倒排索引，才能说确保找到了每个doc对应的所有terms，然后进行分组聚合

    ...
    ...
    ...
    100万个
    doc2: agg1 hello world
    doc3: agg2 test hello

我们有没有必要搜索完整个正排索引啊？？1万个doc --> 搜 -> 可能跟搜索到15000次，就搜索完了，就找到了1万个doc的聚合field的所有值了，然后就可以执行分组聚合操作了






### doc value机制内核级原理深入探秘


1、doc value原理

（1）index-time生成

PUT/POST的时候，就会生成doc value数据，也就是正排索引

（2）核心原理与倒排索引类似

正排索引，也会写入磁盘文件中，然后呢，os cache先进行缓存，以提升访问doc value正排索引的性能
如果os cache内存大小不足够放得下整个正排索引，doc value，就会将doc value的数据写入磁盘文件中

（3）性能问题：给jvm更少内存，64g服务器，给jvm最多16g

es官方是建议，es大量是基于os cache来进行缓存和提升性能的，不建议用jvm内存来进行缓存，那样会导致一定的gc开销和oom问题
给jvm更少的内存，给os cache更大的内存
64g服务器，给jvm最多16g，几十个g的内存给os cache
os cache可以提升doc value和倒排索引的缓存和查询效率

2、column压缩

    doc1: 550
    doc2: 550
    doc3: 500

合并相同值，550，doc1和doc2都保留一个550的标识即可

（1）所有值相同，直接保留单值

（2）少于256个值，使用table encoding模式：一种压缩方式

（3）大于256个值，看有没有最大公约数，有就除以最大公约数，然后保留这个最大公约数
    
    doc1: 36
    doc2: 24
    
    6 --> doc1: 6, doc2: 4 --> 保留一个最大公约数6的标识，6也保存起来

（4）如果没有最大公约数，采取offset结合压缩的方式：

3、disable doc value

如果的确不需要doc value，比如聚合等操作，那么可以禁用，减少磁盘空间占用

    PUT my_index
    {
      "mappings": {
        "my_type": {
          "properties": {
            "my_field": {
              "type":       "keyword"
              "doc_values": false 
            }
          }
        }
      }
    }

### string field聚合实验以及fielddata原理初探



1、对于分词的field执行aggregation，发现报错。。。

    GET /test_index/test_type/_search 
    {
      "aggs": {
        "group_by_test_field": {
          "terms": {
            "field": "test_field"
          }
        }
      }
    }
    
    {
      "error": {
        "root_cause": [
          {
            "type": "illegal_argument_exception",
            "reason": "Fielddata is disabled on text fields by default. Set fielddata=true on [test_field] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory."
          }
        ],
        "type": "search_phase_execution_exception",
        "reason": "all shards failed",
        "phase": "query",
        "grouped": true,
        "failed_shards": [
          {
            "shard": 0,
            "index": "test_index",
            "node": "4onsTYVZTjGvIj9_spWz2w",
            "reason": {
              "type": "illegal_argument_exception",
              "reason": "Fielddata is disabled on text fields by default. Set fielddata=true on [test_field] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory."
            }
          }
        ],
        "caused_by": {
          "type": "illegal_argument_exception",
          "reason": "Fielddata is disabled on text fields by default. Set fielddata=true on [test_field] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory."
        }
      },
      "status": 400
    }

对分词的field，直接执行聚合操作，会报错，大概意思是说，你必须要打开fielddata，然后将正排索引数据加载到内存中，才可以对分词的field执行聚合操作，而且会消耗很大的内存

2、给分词的field，设置fielddata=true，发现可以执行，但是结果却。。。

    POST /test_index/_mapping/test_type 
    {
      "properties": {
        "test_field": {
          "type": "text",
          "fielddata": true
        }
      }
    }
    
    {
      "test_index": {
        "mappings": {
          "test_type": {
            "properties": {
              "test_field": {
                "type": "text",
                "fields": {
                  "keyword": {
                    "type": "keyword",
                    "ignore_above": 256
                  }
                },
                "fielddata": true
              }
            }
          }
        }
      }
    }
    
    GET /test_index/test_type/_search 
    {
      "size": 0, 
      "aggs": {
        "group_by_test_field": {
          "terms": {
            "field": "test_field"
          }
        }
      }
    }
    
    {
      "took": 23,
      "timed_out": false,
      "_shards": {
        "total": 5,
        "successful": 5,
        "failed": 0
      },
      "hits": {
        "total": 2,
        "max_score": 0,
        "hits": []
      },
      "aggregations": {
        "group_by_test_field": {
          "doc_count_error_upper_bound": 0,
          "sum_other_doc_count": 0,
          "buckets": [
            {
              "key": "test",
              "doc_count": 2
            }
          ]
        }
      }
    }

如果要对分词的field执行聚合操作，必须将fielddata设置为true

3、使用内置field不分词，对string field进行聚合

    GET /test_index/test_type/_search 
    {
      "size": 0,
      "aggs": {
        "group_by_test_field": {
          "terms": {
            "field": "test_field.keyword"
          }
        }
      }
    }
    
    {
      "took": 3,
      "timed_out": false,
      "_shards": {
        "total": 5,
        "successful": 5,
        "failed": 0
      },
      "hits": {
        "total": 2,
        "max_score": 0,
        "hits": []
      },
      "aggregations": {
        "group_by_test_field": {
          "doc_count_error_upper_bound": 0,
          "sum_other_doc_count": 0,
          "buckets": [
            {
              "key": "test",
              "doc_count": 2
            }
          ]
        }
      }
    }

如果对不分词的field执行聚合操作，直接就可以执行，不需要设置fieldata=true

4、分词field+fielddata的工作原理

doc value --> 不分词的所有field，可以执行聚合操作 --> 如果你的某个field不分词，那么在index-time，就会自动生成doc value --> 针对这些不分词的field执行聚合操作的时候，自动就会用doc value来执行

分词field，是没有doc value的。。。在index-time，如果某个field是分词的，那么是不会给它建立doc value正排索引的，因为分词后，占用的空间过于大，所以默认是不支持分词field进行聚合的

分词field默认没有doc value，所以直接对分词field执行聚合操作，是会报错的

对于分词field，必须打开和使用fielddata，完全存在于纯内存中。。。结构和doc value类似。。。如果是ngram或者是大量term，那么必将占用大量的内存。。。

如果一定要对分词的field执行聚合，那么必须将fielddata=true，然后es就会在执行聚合操作的时候，现场将field对应的数据，建立一份fielddata正排索引，fielddata正排索引的结构跟doc value是类似的，但是只会讲fielddata正排索引加载到内存中来，然后基于内存中的fielddata正排索引执行分词field的聚合操作

如果直接对分词field执行聚合，报错，才会让我们开启fielddata=true，告诉我们，会将fielddata uninverted index，正排索引，加载到内存，会耗费内存空间

为什么fielddata必须在内存？因为大家自己思考一下，分词的字符串，需要按照term进行聚合，需要执行更加复杂的算法和操作，如果基于磁盘和os cache，那么性能会很差



### fielddata内存控制以及circuit breaker断路器


1、fielddata核心原理

fielddata加载到内存的过程是lazy加载的，对一个analzyed field执行聚合时，才会加载，而且是field-level加载的

一个index的一个field，所有doc都会被加载，而不是少数doc
不是index-time创建，是query-time创建

2、fielddata内存限制

indices.fielddata.cache.size: 20%，超出限制，清除内存已有fielddata数据

fielddata占用的内存超出了这个比例的限制，那么就清除掉内存中已有的fielddata数据

默认无限制，限制内存使用，但是会导致频繁evict和reload，大量IO性能损耗，以及内存碎片和gc

3、监控fielddata内存使用

    GET /_stats/fielddata?fields=*
    GET /_nodes/stats/indices/fielddata?fields=*
    GET /_nodes/stats/indices/fielddata?level=indices&fields=*

4、circuit breaker

如果一次query load的feilddata超过总内存，就会oom --> 内存溢出

circuit breaker会估算query要加载的fielddata大小，如果超出总内存，就短路，query直接失败

indices.breaker.fielddata.limit：fielddata的内存限制，默认60%

indices.breaker.request.limit：执行聚合的内存限制，默认40%

indices.breaker.total.limit：综合上面两个，限制在70%以内


### fielddata预加载机制以及序号标记预加载

如果真的要对分词的field执行聚合，那么每次都在query-time现场生产fielddata并加载到内存中来，速度可能会比较慢

我们是不是可以预先生成加载fielddata到内存中来？？？

1、fielddata预加载

    POST /test_index/_mapping/test_type
    {
      "properties": {
        "test_field": {
          "type": "string",
          "fielddata": {
            "loading" : "eager" 
          }
        }
      }
    }

query-time的fielddata生成和加载到内存，变为index-time，建立倒排索引的时候，会同步生成fielddata并且加载到内存中来，这样的话，对分词field的聚合性能当然会大幅度增强

2、序号标记预加载

global ordinal原理解释
    
    doc1: status1
    doc2: status2
    doc3: status2
    doc4: status1

有很多重复值的情况，会进行global ordinal标记

    status1 --> 0
    status2 --> 1
    
    doc1: 0
    doc2: 1
    doc3: 1
    doc4: 0

建立的fielddata也会是这个样子的，这样的好处就是减少重复字符串的出现的次数，减少内存的消耗

    POST /test_index/_mapping/test_type
    {
      "properties": {
        "test_field": {
          "type": "string",
          "fielddata": {
            "loading" : "eager_global_ordinals" 
          }
        }
      }
    }


### 海量bucket优化机制：从深度优先到广度优先


当buckets数量特别多的时候，深度优先和广度优先的原理，

我们的数据，是每个演员的每个电影的评论

每个演员的评论的数量 --> 每个演员的每个电影的评论的数量

评论数量排名前10个的演员 --> 每个演员的电影取到评论数量排名前5的电影

    {
      "aggs" : {
        "actors" : {
          "terms" : {
             "field" :        "actors",
             "size" :         10,
             "collect_mode" : "breadth_first" 
          },
          "aggs" : {
            "costars" : {
              "terms" : {
                "field" : "films",
                "size" :  5
              }
            }
          }
        }
      }
    }

深度优先的方式去执行聚合操作的

    actor1            actor2            .... actor
film1 film2 film3   film1 film2 film3   ...film

比如说，我们有10万个actor，最后其实是主要10个actor就可以了

但是我们已经深度优先的方式，构建了一整颗完整的树出来了，10万个actor，每个actor平均有10部电影，10万 + 100万 --> 110万的数据量的一颗树

裁剪掉10万个actor中的99990 actor，99990 * 10 = film，剩下10个actor，每个actor的10个film裁剪掉5个，110万 --> 10 * 5 = 50个

构建了大量的数据，然后裁剪掉了99.99%的数据，浪费了

广度优先的方式去执行聚合

actor1    actor2    actor3    ..... n个actor

10万个actor，不去构建它下面的film数据，10万 --> 99990，10个actor，构建出film，裁剪出其中的5个film即可，10万 -> 50个

10倍


### 关系型与document类型数据模型对比


关系型数据库的数据模型

es的document数据模型

    public class Department {
    	
    	private Integer deptId;
    	private String name;
    	private String desc;
    	private List<Employee> employees;
    
    }
    
    public class Employee {
    	
    	private Integer empId;
    	private String name;
    	private Integer age;
    	private String gender;
    	private Department dept;
    
    }

关系型数据库中

    department表
    
    dept_id
    name
    desc
    
    employee表
    
    emp_id
    name
    age
    gender
    dept_id

三范式 --> 将每个数据实体拆分为一个独立的数据表，同时使用主外键关联关系将多个数据表关联起来 --> 确保没有任何冗余的数据

一份数据，只会放在一个数据表中 --> dept name，部门名称，就只会放在department表中，不会在employee表中也放一个dept name，如果说你要查看某个员工的部门名称，那么必须通过员工表中的外键，dept_id，找到在部门表中对应的记录，然后找到部门名称

es文档数据模型
    
    {
    	"deptId": "1",
    	"name": "研发部门",
    	"desc": "负责公司的所有研发项目",
    	"employees": [
    		{
    			"empId": "1",
    			"name": "张三",
    			"age": 28,
    			"gender": "男"
    		},
    		{
    			"empId": "2",
    			"name": "王兰",
    			"age": 25,
    			"gender": "女"
    		},
    		{
    			"empId": "3",
    			"name": "李四",
    			"age": 34,
    			"gender": "男"
    		}
    	]
    }

es，更加类似于面向对象的数据模型，将所有由关联关系的数据，放在一个doc json类型数据中，整个数据的关系，还有完整的数据，都放在了一起


### 通过应用层join实现用户与博客的关联


1、构造用户与博客数据

在构造数据模型的时候，还是将有关联关系的数据，然后分割为不同的实体，类似于关系型数据库中的模型

案例背景：博客网站

我们会模拟各种用户发表各种博客，然后针对用户和博客之间的关系进行数据建模，同时针对建模好的数据执行各种搜索/聚合的操作

    PUT /website/users/1 
    {
      "name":     "小鱼儿",
      "email":    "xiaoyuer@sina.com",
      "birthday":      "1980-01-01"
    }
    
    PUT /website/blogs/1
    {
      "title":    "我的第一篇博客",
      "content":     "这是我的第一篇博客，开通啦！！！"
      "userId":     1 
    }

一个用户对应多个博客，一对多的关系，做了建模

建模方式，分割实体，类似三范式的方式，用主外键关联关系，将多个实体关联起来

2、搜索小鱼儿发表的所有博客

    GET /website/users/_search 
    {
      "query": {
        "term": {
          "name.keyword": {
            "value": "小鱼儿"
          }
        }
      }
    }
    
    {
      "took": 91,
      "timed_out": false,
      "_shards": {
        "total": 5,
        "successful": 5,
        "failed": 0
      },
      "hits": {
        "total": 1,
        "max_score": 0.2876821,
        "hits": [
          {
            "_index": "website",
            "_type": "users",
            "_id": "1",
            "_score": 0.2876821,
            "_source": {
              "name": "小鱼儿",
              "email": "xiaoyuer@sina.com",
              "birthday": "1980-01-01"
            }
          }
        ]
      }
    }

比如这里搜索的是，1万个用户的博客，可能第一次搜索，会得到1万个userId

    GET /website/blogs/_search 
    {
      "query": {
        "constant_score": {
          "filter": {
            "terms": {
              "userId": [
                1
              ]
            }
          }
        }
      }
    }

第二次搜索的时候，要放入terms中1万个userId，才能进行搜索，这个时候性能比较差了
    
    {
      "took": 4,
      "timed_out": false,
      "_shards": {
        "total": 5,
        "successful": 5,
        "failed": 0
      },
      "hits": {
        "total": 1,
        "max_score": 1,
        "hits": [
          {
            "_index": "website",
            "_type": "blogs",
            "_id": "1",
            "_score": 1,
            "_source": {
              "title": "小鱼儿的第一篇博客",
              "content": "大家好，我是小鱼儿，这是我写的第一篇博客！",
              "userId": 1
            }
          }
        ]
      }
    }

上面的操作，就属于应用层的join，在应用层先查出一份数据，然后再查出一份数据，进行关联

3、优点和缺点

优点：数据不冗余，维护方便

缺点：应用层join，如果关联数据过多，导致查询过大，性能很差

### 通过数据冗余实现用户与博客的关联


1、构造冗余的用户和博客数据

第二种建模方式：用冗余数据，采用文档数据模型，进行数据建模，实现用户和博客的关联

    PUT /website/users/1
    {
      "name":     "小鱼儿",
      "email":    "xiaoyuer@sina.com",
      "birthday":      "1980-01-01"
    }
    
    PUT /website/blogs/1
    {
      "title": "小鱼儿的第一篇博客",
      "content": "大家好，我是小鱼儿。。。",
      "userInfo": {
        "userId": 1,
        "username": "小鱼儿"
      }
    }

冗余数据，就是说，将可能会进行搜索的条件和要搜索的数据，放在一个doc中

2、基于冗余用户数据搜索博客

    GET /website/blogs/_search 
    {
      "query": {
        "term": {
          "userInfo.username.keyword": {
            "value": "小鱼儿"
          }
        }
      }
    }

就不需要走应用层的join，先搜一个数据，找到id，再去搜另一份数据

直接走一个有冗余数据的type即可，指定要的搜索条件，即可搜索出自己想要的数据来

3、优点和缺点

优点：性能高，不需要执行两次搜索
缺点：数据冗余，维护成本高 --> 每次如果你的username变化了，同时要更新user type和blog type

一般来说，对于es这种NoSQL类型的数据存储来讲，都是冗余模式....

当然，你要去维护数据的关联关系，也是很有必要的，所以一旦出现冗余数据的修改，必须记得将所有关联的数据全部更新



### 对每个用户发表的博客进行分组

1、构造更多测试数据

    PUT /website/users/3
    {
      "name": "黄药师",
      "email": "huangyaoshi@sina.com",
      "birthday": "1970-10-24"
    }
    
    PUT /website/blogs/3
    {
      "title": "我是黄药师",
      "content": "我是黄药师啊，各位同学们！！！",
      "userInfo": {
        "userId": 1,
        "userName": "黄药师"
      }
    }
    
    PUT /website/users/2
    {
      "name": "花无缺",
      "email": "huawuque@sina.com",
      "birthday": "1980-02-02"
    }
    
    PUT /website/blogs/4
    {
      "title": "花无缺的身世揭秘",
      "content": "大家好，我是花无缺，所以我的身世是。。。",
      "userInfo": {
        "userId": 2,
        "userName": "花无缺"
      }
    }

2、对每个用户发表的博客进行分组

比如说，小鱼儿发表的那些博客，花无缺发表了哪些博客，黄药师发表了哪些博客

    GET /website/blogs/_search 
    {
      "size": 0, 
      "aggs": {
        "group_by_username": {
          "terms": {
            "field": "userInfo.username.keyword"
          },
          "aggs": {
            "top_blogs": {
              "top_hits": {
                "_source": {
                  "include": "title"
                }, 
                "size": 5
              }
            }
          }
        }
      }
    }



### 对文件系统进行数据建模以及文件搜索实战


数据建模，对类似文件系统这种的有多层级关系的数据进行建模

1、文件系统数据构造

    PUT /fs
    {
      "settings": {
        "analysis": {
          "analyzer": {
            "paths": { 
              "tokenizer": "path_hierarchy"
            }
          }
        }
      }
    }
    
    path_hierarchy tokenizer讲解
    
    /a/b/c/d --> path_hierarchy -> /a/b/c/d, /a/b/c, /a/b, /a
    
    fs: filesystem
    
    PUT /fs/_mapping/file
    {
      "properties": {
        "name": { 
          "type":  "keyword"
        },
        "path": { 
          "type":  "keyword",
          "fields": {
            "tree": { 
              "type":     "text",
              "analyzer": "paths"
            }
          }
        }
      }
    }
    
    PUT /fs/file/1
    {
      "name":     "README.txt", 
      "path":     "/workspace/projects/helloworld", 
      "contents": "这是我的第一个elasticsearch程序"
    }
    
    2、对文件系统执行搜索
    
    文件搜索需求：查找一份，内容包括elasticsearch，在/workspace/projects/hellworld这个目录下的文件
    
    GET /fs/file/_search 
    {
      "query": {
        "bool": {
          "must": [
            {
              "match": {
                "contents": "elasticsearch"
              }
            },
            {
              "constant_score": {
                "filter": {
                  "term": {
                    "path": "/workspace/projects/helloworld"
                  }
                }
              }
            }
          ]
        }
      }
    }
    
    {
      "took": 2,
      "timed_out": false,
      "_shards": {
        "total": 5,
        "successful": 5,
        "failed": 0
      },
      "hits": {
        "total": 1,
        "max_score": 1.284885,
        "hits": [
          {
            "_index": "fs",
            "_type": "file",
            "_id": "1",
            "_score": 1.284885,
            "_source": {
              "name": "README.txt",
              "path": "/workspace/projects/helloworld",
              "contents": "这是我的第一个elasticsearch程序"
            }
          }
        ]
      }
    }

搜索需求2：搜索/workspace目录下，内容包含elasticsearch的所有的文件

    /workspace/projects/helloworld    doc1
    /workspace/projects               doc1
    /workspace                        doc1
    
    GET /fs/file/_search 
    {
      "query": {
        "bool": {
          "must": [
            {
              "match": {
                "contents": "elasticsearch"
              }
            },
            {
              "constant_score": {
                "filter": {
                  "term": {
                    "path.tree": "/workspace"
                  }
                }
              }
            }
          ]
        }
      }
    }





