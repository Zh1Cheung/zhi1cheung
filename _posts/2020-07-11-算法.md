---
title: 基础算法
categories:
- 数据结构
tags:
- 算法
- 数据结构



---





## 图

- 我们就拿微信举例子吧。我们可以把每个用户看作一个顶点。如果两个用户之间互加好友， 那就在两者之间建立一条边。所以，整个微信的好友关系就可以用一张图来表示。其中，每 个用户有多少个好友，对应到图中，就叫作顶点的**度**（degree），就是跟顶点相连接的边 的条数。

  - 无向图中有“度”这个概念，表示一个顶点有多少条边。在有向图中，我们 把度分为**入度**（In-degree）和**出度**（Out-degree）。 
  - **带权图**（weighted graph）。在带权图中，每条边都有一个权重 （weight），我们可以通过这个权重来表示 QQ 好友间的亲密度。

- **邻接矩阵存储方法**

  - 邻接矩阵的底层依赖一个二维数组。对于无向图来说，如果顶点 i 与顶点 j 之间有边，我们 就将 A[i][j] 和 A[j][i] 标记为 1；对于有向图来说，如果顶点 i 到顶点 j 之间，有一条箭头从 顶点 i 指向顶点 j 的边，那我们就将 A[i][j] 标记为 1。同理，如果有一条箭头从顶点 j 指向 顶点 i 的边，我们就将 A[j][i] 标记为 1。对于带权图，数组中就存储相应的权重。
  - ![img](https://img-blog.csdnimg.cn/2019010810523518.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2l0eXFpbmc=,size_16,color_FFFFFF,t_70)

- **邻接表存储方法**

  - 每个顶点对 应一条链表，链表中存储的是与这个顶点相连接的其他顶点。另外我需要说明一下，图中画 的是一个有向图的邻接表存储方式，每个顶点对应的链表里面，存储的是指向的顶点。对于 无向图来说，也是类似的，不过，每个顶点的链表中存储的，是跟这个顶点有边相连的顶 点
  - ![img](https://img-blog.csdnimg.cn/20190108113426161.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2l0eXFpbmc=,size_16,color_FFFFFF,t_70)

- 针对微 博用户关系，假设我们需要支持下面这样几个操作： 

  > 判断用户 A 是否关注了用户 B； 
  >
  > 判断用户 A 是否是用户 B 的粉丝； 
  >
  > 用户 A 关注用户 B； 
  >
  > 用户 A 取消关注用户 B； 
  >
  > 根据用户名称的首字母排序，分页获取用户的粉丝列表； 
  >
  > 根据用户名称的首字母排序，分页获取用户的关注列表。 

  - 关于如何存储一个图，前面我们讲到两种主要的存储方法，邻接矩阵和邻接表。因为社交网 络是一张稀疏图，使用邻接矩阵存储比较浪费存储空间。所以，这里我们采用邻接表来存 储。 
    - 不过，用一个邻接表来存储这种有向图是不够的。我们去查找某个用户关注了哪些用户非常 容易，但是如果要想知道某个用户都被哪些用户关注了，也就是用户的粉丝列表，是非常困 难的。 
    - 基于此，我们需要一个逆邻接表。邻接表中存储了用户的关注关系，逆邻接表中存储的是用 户的被关注关系。对应到图上，邻接表中，每个顶点的链表中，存储的就是这个顶点指向的 顶点，逆邻接表中，每个顶点的链表中，存储的是指向这个顶点的顶点。如果要查找某个用户关注了哪些用户，我们可以在邻接表中查找；如果要查找某个用户被哪些用户关注了，我 们从逆邻接表中查找
  - 基础的邻接表不适合快速判断两个用户之间是否是关注与被关注的关系，所以我们选择改进 版本，将邻接表中的链表改为支持快速查找的动态数据结构。选择哪种动态数据结构呢？红 黑树、跳表、有序动态数组还是散列表呢？ 因为我们需要按照用户名称的首字母排序，分页来获取用户的粉丝列表或者关注列表，用跳 表这种结构再合适不过了。这是因为，跳表插入、删除、查找都非常高效，时间复杂度是 O(logn)，空间复杂度上稍高，是 O(n)。最重要的一点，跳表中存储的数据本来就是有序 的了，分页获取粉丝列表或关注列表，就非常高效。 

- 但是如果像微博那样有上亿的用户，数据 规模太大，我们就无法全部存储在内存中了。这个时候该怎么办呢？

  - 我们可以通过哈希算法等数据分片方式，将邻接表存储在不同的机器上。你可以看下面这幅 图，我们在机器 1 上存储顶点 1，2，3 的邻接表，在机器 2 上，存储顶点 4，5 的邻接 表。逆邻接表的处理方式也一样。当要查询顶点与顶点关系的时候，我们就利用同样的哈希 算法，先定位顶点所在的机器，然后再在相应的机器上查找。 

    

  

## **深度和广度优先搜索**

- 给你一个用户，如何找出这个用户的所有三度（其中包含一度、二度和三度）好友关系

  - 社交网络可以用图来表示。这个问题就非常适合用图的广度优先搜索算法来解决，因为广度优先搜索是层层往外推进的。首先，遍历与起始顶点最近的一层顶点，也就是用户的一度好友，然后再遍历与用户距离边数为2的顶点，也就是二度好友关系，以及与用户距离边数为3的顶点，也就是三度好友关系。
  - 我们只需要稍加改造一下广度优先搜索代码，用一个数组来记录每个顶点与起始顶点的距离，非常容易就可以找出三度好友关系。

- BFS

  - 广度优先搜索（Breadth-First-Search），我们平常都把简称为 BFS。直观地讲，它其实就 是一种“地毯式”层层推进的搜索策略，即先查找离起始顶点最近的，然后是次近的，依次 往外搜索。

  - ![img](https://img-blog.csdnimg.cn/20190505105237135.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1ODAwMzEx,size_16,color_FFFFFF,t_70)

  - 这里面，bfs() 函数就是基于之前定义的，图的广度优先搜索的代码实现。其中 s 表示起始 顶点，t 表示终止顶点。我们搜索一条从 s 到 t 的路径。实际上，这样求得的路径就是从 s 到 t 的最短路径。 

    - ```java
      public void bfs(int s, int t) {
      			if (s == t) {
      				return;
      			}
      			boolean[] visited = new boolean[v];
      			visited[s] = true;
      			Queue<Integer> queue = new LinkedList<>();
      			queue.add(s);
      			int[] prev = new int[v];
      			for(int i = 0; i < v; ++i) {
      				prev[i] = -1;
      			}
      			while(queue.size() != 0) {
      				int w = queue.poll();
      				for(int i = 0; i < adj[w].size(); ++i){
      					int q = adj[w].get(i);
      					if( !visited[q]) {
      						prev[q] = w;
      						if(q == t) {
      							print(prev, s, t);
      							return;
      						}
      						visited[q] = true;
      						queue.add(q);
      					}
      				}
      			}
      		}
      		private void print(int[] prev, int s, int t) { //递归打印 s -> t 的路径
      			if(prev[t] != -1 && t != s) {
      				print(prev, s, prev[t]);
      			}
      			System.out.println(t + " ");
      		}
      
      ```

    - **visited** 是用来记录已经被访问的顶点，用来避免顶点被重复访问。如果顶点q 被访问，那相应的 visited[q]会被设置为true。

    - **queue**是一个队列，用来存储已经被访问、但相连的顶点还没被访问的顶点。因为广度优先搜索是逐层访问的，也就是说，我们只有把第k层的顶点都访问完之后，才能访问第 k+1 层的顶点。当我们访问到第 k 层顶点的时候，我们需要把第k 层的顶点记录下来，稍后才能通过第k 层顶点来找到 k+1 层的顶点。所以，我们用这个队列来实现记录功能。

    - **prev**用来记录搜索路径。当我们从顶点 s 开始，广度优先搜索到顶点 t 后，prev 数组中存储的就是搜索的路径。不过，这个路径是反向存储的。 prev[w] 存储的是w 是从哪个前驱顶点遍历过来的。比如，我们通过顶点2的邻接表访问到顶点3，那prev[3]就等于2。为了正向打印出路径，我们需要递归地来打印，你可以看下 print()函数的实现方式

  - ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190124165136602.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2V2ZXJ5X19kYXk=,size_16,color_FFFFFF,t_70)

  - 再来看下，广度优先算法的时间、空间复杂度是多少？

    - 最坏情况下，终止顶点 t 离起始顶点 s 很远，需要遍历完整整个图才能找到。这个时候，每个顶点都要进出一遍队列，每个边也都会被访问一次，所以，广度优先的时间复杂度是O(V+E)，其中，V表示顶点的个数，E表示边的个数。当然，对于一个连通图来说，也就是说一个图中的所有顶点都是连通的，E肯定要大于等于V-1,所以广度优先搜索的时间复杂度也可以简写为O(E)。
    - 广度优先搜索的空间消耗主要在几个辅助变量 visited 数组、queue队列、prev数组上。这三个存储空间的大小都不会超过顶点的个数，所以空间复杂度的O(V)。

- dfs

  - 深度优先搜索（Depth-First-Search）,简称DFS。最直观例子就是“走迷宫”。

    - 假设你站在迷宫的某个岔路口，然后想找到出口。你随意选择一个岔路口来走，走着走着发现不能的时候，你就回退到上一个岔路口，重新选择一条路继续走，直到最终找到出口。这种走法就是一种深度优先搜索策略。

  - 如下图，搜索的起始顶点是 s，终止顶点是 t，我们希望在图中寻找一条从顶点 s 到顶点 t 的路径。如果映射到迷宫那个例子，s 就是你起始所在的位置，t 就是出口。

    ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190125093407972.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2V2ZXJ5X19kYXk=,size_16,color_FFFFFF,t_70)

    我用深度递归算法，把整个搜索的的路径标记出来。这里面实线箭头表示遍历，虚线箭头表示回退。从图中我们可以看出，深度优先搜索找出来的路径，并不是顶点 s 到顶点 t 的最短路径。

    实际上，深度优先搜索用的是一种比较著名的算法思想——回溯思想。

  - 深度优先搜索代码实现里，有个比较特殊的变量 found，它的作用是，当我们已经找到终止基点 t 之后，就不用再递归继续查找了。

  - ```java
    boolean found = false; // 全局变量或者成员变量
     
     	public void dfs(int s, int t) {
     		found = false;
     		boolean[] visited = new boolean[v];
     		int[] prev = new int[v];
     		
     		for(int i = 0; i < v; ++i) {
     			prev[i] = -1;
     		}
     		recurDfs(s, t, visited, prev);
     		print(prev, s, t);
     	}
     	
     	private void recurDfs(int w, int t, boolean[] visited, int[] prev) {
     		if(found == true) {
     			return;
     		}
     		visited[w] = true;
     		if(w == t) {
     			found = true;
     			return;
     		}
     		for(int i = 0; i <adj[w].size(); ++i) {
     			int q = adj[w].get(i);
     			if(!visited[q]) {
     				prev[q] = w;
     				recurDfs(q, t, visited, prev);
     			}
     		}
     	}
    ```

    - 理解了深度做搜索算法之后，我们来看，深度优先搜索的时间、空间复杂度是多少。
      - 从前面的图可以看出，每条边最多会被访问两次，一次是遍历，一次是回退。所以图上的深度优先搜索算法的时间复杂度是O(E)，E表示边的个数。
      - 深度优先算法的消耗内存主要是 visited、prev数组和递归调用栈。 visited、prev数组的大小跟顶点的个数V成正比，递归调用栈的最大深度不会超过顶点的个数，所以总的空间复杂度是O(V)。

  

  

## **贪心算法**

- 贪心算法有很多经典的应用，比如霍夫曼编码（Huffman Coding）、Prim 和 Kruskal 最小生成树算法、还有 Dijkstra 单源最短路径算法。最小生成树算法和最短路径算法我们后面会讲到，所以我们今天讲下霍夫曼编码，看看**它是如何利用贪心算法来实现对数据压缩编码，有效节省数据存储空间的**

- 贪心算法解决问题的步骤

  - 假设我们有一个可以容纳 100kg 物品的背包，可以装各种物品。我们有以下 5 种豆子，每种豆子的总量和总价值都各不相同。为了让背包中所装物品的总价值最大，我们如何选择在背包中装哪些豆子？每种豆子又该装多少呢？

    ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190128151721340.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdXNoZW5neGlfcm9vdA==,size_16,color_FFFFFF,t_70)
    实际上，这个问题很简单，就是按**照单价从大到小来装**就行了，对吧？

    以上本质上借助的就是贪心算法。结合这个例子，我总结一下贪心算法解决问题的步骤，我们一起来看看。

    - **第一步，当我们看到这类问题的时候，首先要联想到贪心算法：针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大**

    类比到刚刚的例子，限制值就是重量不能超过 100kg，期望值就是物品的总价值。这组数据就是 5 种豆子。我们从中选出一部分，满足重量不超过 100kg，并且总价值最大。

    - **第二步，我们尝试看下这个问题是否可以用贪心算法解决**：每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。

    类比到刚刚的例子，我们每次都从剩下的豆子里面，选择单价最高的，也就是重量相同的情况下，对价值贡献最大的豆子。

    - **第三步，我们举几个例子看下贪心算法产生的结果是否是最优的**。大部分情况下，举几个例子验证一下就可以了。严格地证明贪心算法的正确性，是非常复杂的，需要涉及比较多的数学推理。

    **实际上，用贪心算法解决问题的思路，并不总能给出最优解。**

- 如何用贪心算法实现霍夫曼编码？假设我人一个包含1000个字符的文件，每个字符占1个byte（1byte=8bits），存储这1000字符就一共需要8000bits，那有没有更加节省空间的存储方式呢？

  假设我们分析发现，这1000个字符中只包含6种不同字符，假设它们分别是a, b, c, d, e, f。而3个二进制位（bit）就可以表示8种不同的字符，所以，为了尽量减少存储空间，每个字符我们用3个二进制来表示。那存储这1000个字符只需要3000bits就可以了。不过，还有没有更加节省空间的存储方式呢？

  *a(000)、b(001)、c(010)、d(011)、e(100)、f(101)*

  霍夫曼编码要全场了，它广泛用于数据压缩，其压缩率通常在20%~90%之间。

  霍夫曼验证码不仅会考察文本中有多少个不同字符，还会考察每个字符出现的频率，根据频率的不同，选择不同长度的编码。霍夫曼编码试图用这种不等长的编码方法，来进一步增加压缩的效率。如何给不同频率的字符选择不同长度的编码呢？根据贪心思想，我们可以把出现频率比较多的字符，用稍微短一些的编码，出现频率比较少的字符，用稍微长一些的编码。

  对于等长的编码来说，我们解压缩很简单。比如刚才那个例子中，我们用3个bit表示一个字符。在解压的时候，我们每次从文本中读取3位二进制码，然后翻译成对应的字符。但是，霍夫曼编码是不等长的，每次应该读取1位还是2位、3位等等来解压缩的呢？这个问题就导致霍夫曼编码解压缩来比较复杂。为了避免解压缩过程中的歧义，霍夫曼要求各个字符的编码之间，不会出现某个编码是另一个编码前缀的情况。

  [![贪心算法： 如何用贪心算法实现Huffman压缩编码_第5张图片](https://img.it610.com/image/info8/8bdc2f8ac3294ea8b9c3867aa1bb39c9.jpg)](https://img.it610.com/image/info8/8bdc2f8ac3294ea8b9c3867aa1bb39c9.jpg)

  假设这6个字符出现的频率从高到低依次是a、b、c、d、e、f。我们把它们编码下面这个样子，任何一个字符的编码都不是另一个的前缀，在解压缩的时候，我们每次会读取尽可能长的可解压的二进制，所以在解压的时候，也不会有歧义。经过这各编码压缩之后，这1000个字符，只需要2100bits就可以了。[![贪心算法： 如何用贪心算法实现Huffman压缩编码_第6张图片](https://img.it610.com/image/info8/8d8d5e5260374584abb0192419a23d6a.jpg)](https://img.it610.com/image/info8/8d8d5e5260374584abb0192419a23d6a.jpg)

  尽管霍夫曼编码的思想并不难理解，但是根据字符出现频率的不同，给不同的字符进行不同长度的编码呢？这里的处理稍微有些技巧。

  我们每个字符看作一个节点，并且辅带看把频率放到优先级队列中。我们从队列中取出频率最小的两个节点A、B，然后新那一个节点C，把频率设置为两个节点的频率之和，并把这个新节点C作为节点A、B的父节点。最后两把C节点放到优先级队列中。重复这个过程，直到队列中没有了数据。
  [![贪心算法： 如何用贪心算法实现Huffman压缩编码_第7张图片](https://img.it610.com/image/info8/0756cd546b03460ebe2cfbc57fc41619.jpg)](https://img.it610.com/image/info8/0756cd546b03460ebe2cfbc57fc41619.jpg)

  现在，给每一条边画一个权值，指向左子节点的边我们统统标记为0，指向右子节点的过，我们统统标记为1，那从根节点到叶子节点的路径就是叶子节点对应字符的霍夫曼编码。
  [![贪心算法： 如何用贪心算法实现Huffman压缩编码_第8张图片](https://img.it610.com/image/info8/5f3ba61959094cde9e1e9f0876175125.jpg)](https://img.it610.com/image/info8/5f3ba61959094cde9e1e9f0876175125.jpg)

  

##  **动态规划**

- 一个模型三个特征

  - 首先，我们来看，什么是“**一个模型**”？它指的是动态规划适合解决的问题的模型。我把这个模型定义为“**多阶段决策最优解模型**”

  - “**三个特征**”？它们分别是**最优子结构**、**无后效性**和**重复子问题**

    - **1.** **最优子结构**

      最优子结构指的是，问题的最优解包含子问题的最优解。反过来说就是，我们可以通过子问题的最优解，推导出问题的最优解。如果我们把最优子结构，对应到我们前面定义的动态规划问题模型上，那我们也可以理解为，后面阶段的状态可以通过前面阶段的状态推导出来。

      **2.** **无后效性**

      无后效性有两层含义，第一层含义是，在推导后面阶段的状态的时候，我们只关心前面阶段的状态值，不关心这个状态是怎么一步一步推导出来的。第二层含义是，某阶段状态一旦确定，就不受之后阶段的决策影响。无后效性是一个非常“宽松”的要求。只要满足前面提到的动态规划问题模型，其实基本上都会满足无后效性。

      **3.** **重复子问题**

      这个概念比较好理解。前面一节，我已经多次提过。如果用一句话概括一下，那就是，不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态。

- 我们把状态定义为 min_dist(i, j)，其中 i 表示行，j 表示列。min_dist 表达式的值表示从 (0, 0) 到达 (i, j) 的最短路径长度。所以，这个问题是一个多阶段决策最优解问题，符合动态规划的模型。

  - 如果我们走到 (i, j) 这个位置，我们只能通过 (i-1, j)，(i, j-1) 这两个位置移动过来，也就是说，我们想要计算 (i, j) 位置对应的状态，只需要关心 (i-1, j)，(i, j-1) 两个位置对应的状态，并不关心棋子是通过什么样的路线到达这两个位置的。而且，我们仅仅允许往下和往右移动，不允许后退，所以，前面阶段的状态确定之后，不会被后面阶段的决策所改变，所以，这个问题符合“无后效性”这一特征。
  - 刚刚定义状态的时候，我们把从起始位置 (0, 0) 到 (i, j) 的最小路径，记作 min_dist(i, j)。因为我们只能往右或往下移动，所以，我们只有可能从 (i, j-1) 或者 (i-1, j) 两个位置到达 (i, j)。也就是说，到达 (i, j) 的最短路径要么经过 (i, j-1)，要么经过 (i-1, j)，而且到达 (i, j) 的最短路径肯定包含到达这两个位置的最短路径之一。换句话说就是，min_dist(i, j) 可以通过 min_dist(i, j-1) 和 min_dist(i-1, j) 两个状态推导出来。这就说明，这个问题符合“最优子结构”。
  - 我们可以用回溯算法来解决这个问题。如果你自己写一下代码，画一下递归树，就会发现，递归树中有重复的节点。重复的节点表示，从左上角到节点对应的位置，有多种路线，这也能说明这个问题中存在重复子问题。

- **两种动态规划解题思路总结**

  - **状态转移表法**

    ```java
    private int minDist = Integer.MAX_VALUE; // 全局变量或者成员变量
    // 调用方式：minDistBacktracing(0, 0, 0, w, n);
    public void minDistBT(int i, int j, int dist, int[][] w, int n) {
      // 到达了 n-1, n-1 这个位置了，这里看着有点奇怪哈，你自己举个例子看下
      if (i == n && j == n) {
        if (dist < minDist) minDist = dist;
        return;
      }
      if (i < n) { // 往下走，更新 i=i+1, j=j
        minDistBT(i + 1, j, dist+w[i][j], w, n);
      }
      if (j < n) { // 往右走，更新 i=i, j=j+1
        minDistBT(i, j+1, dist+w[i][j], w, n);
      }
    }
    ```

    

  - **状态转移方程法**

    ```java
    private int[][] matrix = {{1，3，5，9}, {2，1，3，4}，{5，2，6，7}，{6，8，4，3}};
    private int n = 4;
    private int[][] mem = new int[4][4];
    public int minDist(int i, int j) { // 调用 minDist(n-1, n-1);
      if (i == 0 && j == 0) return matrix[0][0];
      if (mem[i][j] > 0) return mem[i][j];
      int minLeft = Integer.MAX_VALUE;
      if (j-1 >= 0) {
        minLeft = minDist(i, j-1);
      }
      int minUp = Integer.MAX_VALUE;
      if (i-1 >= 0) {
        minUp = minDist(i-1, j);
      }
    
      int currMinDist = matrix[i][j] + Math.min(minLeft, minUp);
      mem[i][j] = currMinDist;
      return currMinDist;
    }
    ```

    

- **四种算法思想比较分析**
  
  - 如果我们将这四种算法思想分一下类，那贪心、回溯、动态规划可以归为一类，而分治单独可以作为一类，因为它跟其他三个都不大一样。为什么这么说呢？前三个算法解决问题的模型，都可以抽象成我们今天讲的那个多阶段决策最优解模型，而分治算法解决的问题尽管大部分也是最优解问题，但是，大部分都不能抽象成多阶段决策模型。
  
  - 回溯算法是个“万金油”。基本上能用的动态规划、贪心解决的问题，我们都可以用回溯算法解决。回溯算法相当于穷举搜索。穷举所有的情况，然后对比得到最优解。不过，回溯算法的时间复杂度非常高，是指数级别的，只能用来解决小规模数据的问题。对于大规模数据的问题，用回溯算法解决的执行效率就很低了。
  
  - 尽管动态规划比回溯算法高效，但是，并不是所有问题，都可以用动态规划来解决。能用动态规划解决的问题，需要满足三个特征，最优子结构、无后效性和重复子问题。在重复子问题这一点上，动态规划和分治算法的区分非常明显。分治算法要求分割成的子问题，不能有重复子问题，而动态规划正好相反，动态规划之所以高效，就是因为回溯算法实现中存在大量的重复子问题。
  
  - 贪心算法实际上是动态规划算法的一种特殊情况。它解决问题起来更加高效，代码实现也更加简洁。不过，它可以解决的问题也更加有限。它能解决的问题需要满足三个条件，最优子结构、无后效性和贪心选择性（这里我们不怎么强调重复子问题）。
      - 其中，最优子结构、无后效性跟动态规划中的无异。“贪心选择性”的意思是，通过局部最优的选择，能产生全局的最优选择。每一个阶段，我们都选择当前看起来最优的决策，所有阶段的决策完成之后，最终由这些局部最优解构成全局最优解。





## 二分查找

- 假设我们有 1000 万个整数数据，每个数据占 8 个字节，**如何设计数据结构和算法，快速判断某个整数是否出现在这 1000 万数据中？** 我们希望这个功能不要占用太多的内存空间，最多不要超过 100MB，你会怎么做呢？
  - 虽然大部分情况下，用二分查找可以解决的问题，用散列表、二叉树都可以解决。但是，不管是散列表还是二叉树，都会需要比较多的额外的内存空间。如果用散列表或者二叉树来存储这 1000 万的数据，用 100MB 的内存肯定是存不下的。而二分查找底层依赖的是数组，除了数据本身之外，不需要额外存储其他信息，是最省内存空间的存储方式，所以刚好能在限定的内存大小下解决这个问题。



- 总结升华一下

  - 二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。
  - 每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。

- O(logn) 惊人的查找速度

  - 我们假设数据大小是 n，每次查找后数据都会缩小为原来的一半，也就是会除以 2。最坏情况下，直到查找区间被缩小为空，才停止。
  - O(logn) 这种**对数时间复杂度**。这是一种极其高效的时间复杂度，有的时候甚至比时间复杂度是常量级 O(1) 的算法还要高效
    - 因为 logn 是一个非常“恐怖”的数量级，即便 n 非常非常大，对应的 logn 也很小。比如 n 等于 2 的 32 次方，这个数很大了吧？大约是 42 亿。也就是说，如果我们在 42 亿个数据中用二分查找一个数据，最多需要比较 32 次。

- 二分查找的递归与非递归实现

  - **最简单的情况**就是**有序数组中不存在重复元素**，我们在其中用二分查找值等于给定值的数据。

    - ```java
      public int bsearch(int[] a, int n, int value) {
        int low = 0;
        int high = n - 1;
       
        while (low <= high) {
          int mid = (low + high) / 2;
          if (a[mid] == value) {
            return mid;
          } else if (a[mid] < value) {
            low = mid + 1;
          } else {
            high = mid - 1;
          }
        }
       
        return -1;
      }
      ```

    - **容易出错的 3 个地方**。

      - 1. 循环退出条件

        注意是 low<=high，而不是 low<high。

      - 2.mid 的取值

        实际上，mid=(low+high)/2 这种写法是有问题的。因为如果 low 和 high 比较大的话，两者之和就有可能会**溢出**。改进的方法是将 mid 的计算方式写成 low+(high-low)/2。更进一步，如果要将性能优化到极致的话，我们可以将这里的除以 2 操作转化成**位运算** low+((high-low)>>1)。因为相比除法运算来说，计算机处理位运算要快得多。

      - 3.low 和 high 的更新

        low=mid+1，high=mid-1。注意这里的 +1 和 -1，如果直接写成 low=mid 或者 high=mid，就可能会发生**死循环**。比如，当 high=3，low=3 时，如果 a[3] 不等于 value，就会导致一直循环不退出。

      - ```java
        // 二分查找的递归实现
        public int bsearch(int[] a, int n, int val) {
          return bsearchInternally(a, 0, n - 1, val);
        }
         
        private int bsearchInternally(int[] a, int low, int high, int value) {
          if (low > high) return -1;
         
          int mid =  low + ((high - low) >> 1);
          if (a[mid] == value) {
            return mid;
          } else if (a[mid] < value) {
            return bsearchInternally(a, mid+1, high, value);
          } else {
            return bsearchInternally(a, low, mid-1, value);
          }
        }
        ```

        

    - 二分查找应用场景的局限性

      - 首先，二分查找依赖的是顺序表结构，简单点说就是**数组**。
      - 那二分查找能否依赖其他数据结构呢？比如链表。答案是不可以的，主要原因是二分查找算法需要按照下标随机访问元素。我们在数组和链表那两节讲过，数组按照下标随机访问数据的时间复杂度是 O(1)，而链表随机访问的时间复杂度是 O(n)。所以，如果数据使用链表存储，二分查找的时间复杂就会变得很高。
      - 其次，二分查找针对的是**有序数据**。
        - 如果数据没有序，我们需要先排序。前面章节里我们讲到，排序的时间复杂度最低是 O(nlogn)。
        - 所以，二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中。针对动态变化的数据集合，二分查找将不再适用。那针对动态数据集合，如何在其中快速查找某个数据呢？
          - 二叉树
      - **数据量太小不适合二分查找**
        - 不过，这里有一个例外。如果数据之间的比较操作非常耗时，不管数据量大小，我都推荐使用二分查找。比如，数组中存储的都是长度超过 300 的字符串，如此长的两个字符串之间比对大小，就会非常耗时。我们需要尽可能地减少比较次数，而比较次数的减少会大大提高性能，这个时候二分查找就比顺序遍历更有优势。
      - **数据量太大也不适合二分查找**
        - 二分查找的底层需要依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存的要求比较苛刻。比如，我们有 1GB 大小的数据，如果希望用数组来存储，那就需要 1GB 的连续内存空间。
        - 注意这里的“连续”二字，也就是说，即便有 2GB 的内存空间剩余，但是如果这剩余的 2GB 内存空间都是零散的，没有连续的 1GB 大小的内存空间，那照样无法申请一个 1GB 大小的数组。而我们的二分查找是作用在数组这种数据结构之上的，所以太大的数据用数组存储就比较吃力了，也就不能用二分查找了。

- 如果数据使用链表存储，二分查找的时间复杂就会变得很高，那查找的时间复杂度究竟是多少呢

  - 假设链表长度为n，二分查找每次都要找到中间点(计算中忽略奇偶数差异):
    第一次查找中间点，需要移动指针n/2次；
    第二次，需要移动指针n/4次；
    第三次需要移动指针n/8次；
    ......
    以此类推，一直到1次为值

    总共指针移动次数(查找次数) = n/2 + n/4 + n/8 + ...+ 1，这显然是个等比数列，根据等比数列求和公式：Sum = n - 1.

    最后算法时间复杂度是：O(n-1)，忽略常数，记为O(n)，时间复杂度和顺序查找时间复杂度相同  

  - 其实是查找中点的次数，数组查找中点只需要一次就可以搞定，链表需要移动 n 个元素，数组最后找到了中点，就执行了 k 次，k =logn 时间复杂度是 O(logn)，而链表找找到中点需要移动指针（n+n/2+n/4+...+n/2^k）= n-1 次, 时间复杂度是 O(n)

- 假设我们有 12 万条这样的 IP 区间与归属地的对应关系，如何快速定位出一个 IP 地址的归属地呢

  - 现在这个问题应该很简单了。如果 IP 区间与归属地的对应关系不经常更新，我们可以先预处理这 12 万条数据，让其按照起始 IP 从小到大排序。如何来排序呢？我们知道，IP 地址可以转化为 32 位的整型数。所以，我们可以将起始地址，按照对应的整型值的大小关系，从小到大进行排序。
  - 然后，这个问题就可以转化为我刚讲的第四种变形问题“在有序数组中，查找最后一个小于等于某个给定值的元素”了。
  - 当我们要查询某个 IP 归属地时，我们可以先通过二分查找，找到最后一个起始 IP 小于等于这个 IP 的 IP 区间，然后，检查这个 IP 是否在这个 IP 区间内，如果在，我们就取出对应的归属地显示；如果不在，就返回未查找到。

- 变体一：查找第一个值等于给定值的元素

  - ```java
    public int bsearch(int[] a, int n, int value) {
      int low = 0;
      int high = n - 1;
      while (low <= high) {
        int mid =  low + ((high - low) >> 1);
        if (a[mid] > value) {
          high = mid - 1;
        } else if (a[mid] < value) {
          low = mid + 1;
        } else {
     // 如果 mid 等于 0，那这个元素已经是数组的第一个元素，那它肯定是我们要找的；如果 mid 不等于 0，但 a[mid] 的前一个元素 a[mid-1] 不等于 value，那也说明 a[mid] 就是我们要找的第一个值等于给定值的元素。
    
    // 如果经过检查之后发现 a[mid] 前面的一个元素 a[mid-1] 也等于 value，那说明此时的 a[mid] 肯定不是我们要查找的第一个值等于给定值的元素。那我们就更新 high=mid-1，因为要找的元素肯定出现在 [low, mid-1] 之间。
          if ((mid == 0) || (a[mid - 1] != value)) return mid;
          else high = mid - 1;
        }
      }
      return -1;
    }
    ```

    

- 变体二：查找最后一个值等于给定值的元素

  - ```java
    public int bsearch(int[] a, int n, int value) {
      int low = 0;
      int high = n - 1;
      while (low <= high) {
        int mid =  low + ((high - low) >> 1);
        if (a[mid] > value) {
          high = mid - 1;
        } else if (a[mid] < value) {
          low = mid + 1;
        } else {
    // 我们还是重点看第 11 行代码。如果 a[mid] 这个元素已经是数组中的最后一个元素了，那它肯定是我们要找的；如果 a[mid] 的后一个元素 a[mid+1] 不等于 value，那也说明 a[mid] 就是我们要找的最后一个值等于给定值的元素。
    
    // 如果我们经过检查之后，发现 a[mid] 后面的一个元素 a[mid+1] 也等于 value，那说明当前的这个 a[mid] 并不是最后一个值等于给定值的元素。我们就更新 low=mid+1，因为要找的元素肯定出现在 [mid+1, high] 之间。
    
    ```

    

- 变体三：查找第一个大于等于给定值的元素

  - ```java
    public int bsearch(int[] a, int n, int value) {
      int low = 0;
      int high = n - 1;
      while (low <= high) {
        int mid =  low + ((high - low) >> 1);
        if (a[mid] >= value) {
          if ((mid == 0) || (a[mid - 1] < value)) return mid;
          else high = mid - 1;
        } else {
          low = mid + 1;
        }
      }
      return -1;
    }
    ```

    

- 变体四：查找最后一个小于等于给定值的元素

  - ```java
    public int bsearch7(int[] a, int n, int value) {
      int low = 0;
      int high = n - 1;
      while (low <= high) {
        int mid =  low + ((high - low) >> 1);
        if (a[mid] > value) {
          high = mid - 1;
        } else {
          if ((mid == n - 1) || (a[mid + 1] > value)) return mid;
          else low = mid + 1;
        }
      }
      return -1;
    }
    ```

    

