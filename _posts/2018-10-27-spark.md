---
title: Spark-User Behavior Analysis
categories:
- Spark
- Big Data
tags:
- Spark



---


 

# Spark用户行为分析

## 一、环境搭建
 
- CentOS 6.4
- hadoop-2.5.0-cdh5.3.6
- hive-0.13.1-cdh5.3.6
- zookeeper-3.4.5-cdh5.3.6
- kafka_2.9.2-0.8.1
- flume-ng-1.5.0-cdh5.3.6
- spark-1.5.1-bin-hadoop2.4

## 二、流程介绍

### 离线日志采集流程介绍

- 我们的数据从哪里来?
->发送请求到后台服务器，Nginx接收请求并进行转发
->1.Nginx来接收请求，并且后端接入Tomcat集群/Jetty集群，来进行高并发访问下的负载均衡。
  2.Nginx，或者是Tomcat，你进行适当配置之后，所有请求的数据都会作为log存储起来
  3.可能有多份日志文件，因为有多个web服务器。
  	1.一个日志转移的工具，比如自己用linux的crontab定时调度一个shell脚本/python脚本
  	2.或者自己用java开发一个后台服务，用quartz这样的框架进行定时调度
  	3.然后作为一份日志文件，给转移到flume agent正在监控的目录中。
->1.flume agent启动起来以后, 可以实时的监控linux系统上面的某一个目录,看其中是否有新的文件进来
  2.只要发现有新的日志文件进来，那么flume就会走后续的channel和sink。
  3.通常来说，sink都会配置为HDFS。
->flume负责将每天的一份log文件，传输到HDFS上
->HDFS用来存储每天的log数据
  1.使用Hadoop MapReduce，自己开发MR作业,可以用crontab定时调度工具来定时每天执行一次
  2.Oozie来进行定时调度
  3.针对HDFS里的原始日志进行数据清洗，写入HDFS中另外一个文件
  4.HDFS：存储一份经过数
  据清洗的日志文件。
->把HDFS中的清洗后的数据，给导入到Hive的某个表中。
  1.这里可以使用动态分区，Hive使用分区表，每个分区放一天的数据。
  2.Hive，底层也是基于HDFS，作为一个大数据的数据仓库
  3.数据仓库内部，再往后，其实就是一些数据仓库建模的ETL
  4.ETL会将原始日志所在的一个表，给转换成几十张，甚至上百张表。这些表，就是我们的数据仓库。
  5.公司的统计分析人员，就会针对数据仓库中的表，执行临时的，或者每天定时调度的Hive SQL ETL作业。来进行大数据的统计和分析。
->Spark/Hdoop/Storm，大数据平台/系统，可能都会使用Hive中的数据仓库内部的表
  1.我们的Spark大数据系统，数据来源都是Hive中的某些表
  2.开发特殊的，符合业务需求的大数据平台
  3.通过大数据平台来给公司里的用户进行使用，来提供大数据的支持，推动公司的发展



### 实时数据采集流程介绍

- 我们的数据从哪里来?
->1.Nginx，后台Web服务器（Tomcat、Jetty），后台系统（J2EE、PHP）。
  2.到这一步为止，其实还是可以跟我们之前的离线日志收集流程一样。
->flume，监控指定的文件夹
	->可以每天收集一份，放到flume，转移到HDFS里面，清洗后放入Hive，建立离线的数据仓库。
	->也可以每收集1分钟的数据，或者每收集一点数据，就放入文件，然后转移到flume中去,可以配置flume，将数据写入Kafka
->实时数据，通常都是从分布式消息队列集群中读取的，比如Kafka
->，再由我们后端的实时数据处理程序（Storm、Spark Streaming），实时从Kafka中读取数据，log日志。然后进行实时的计算和处理。
->1.大数据实时计算系统，比如说用Storm、Spark Streaming开发的，
  2.可以实时的从Kafka中拉取数据，然后对实时的数据进行处理和计算，
  3.这里可以封装大量复杂的业务逻辑，甚至调用复杂的机器学习、数据挖掘、智能推荐的算法，然后实现实时的车辆调度、实时推荐。(广告流量的实时统计)



## 三、用户访问session分析

### 介绍
#### 1.模块介绍

  - 1、对用户访问session进行分析
  - 2、JDBC辅助类封装
  - 3、用户访问session聚合统计
  - 4、按时间比例随机抽取session
  - 5、获取点击、下单和支付次数排名前10的品类
  - 6、获取top10品类的点击次数最多的10个session
  - 7、复杂性能调优全套解决方案
  - 8、十亿级数据troubleshooting经验总结
  - 9、数据倾斜全套完美解决方案
  - 10、模块功能演示


- 模块的目标：对用户访问session进行分析

1、可以根据使用者指定的某些条件，筛选出指定的一些用户（有特定年龄、职业、城市）；
2、对这些用户在指定日期范围内发起的session，进行聚合统计，比如，统计出访问时长在0~
3s的session占总session数量的比例；


1、可以根据使用者指定的某些条件，筛选出指定的一些用户（有特定年龄、职业、城市）；

2、对这些用户在指定日期范围内发起的session，进行聚合统计，比如，统计出访问时长在0~
3s的session占总session数量的比例；

3、按时间比例，比如一天有24个小时，其中12:00~
13:00的session数量占当天总session数量的50%，当天总session数
量是10000个，那么当天总共要抽取1000个session，ok，12:00-13:00的用户，就得抽取1000*
50%=500。而且这500个需要随机抽取。

4、获取点击量、下单量和支付量都排名10的商品种类

5、获取top10的商品种类的点击数量排名前10的session

6、开发完毕了以上功能之后，需要进行大量、复杂、高端、全套的性能调优

7、十亿级数据量的troubleshooting（故障解决）的经验总结

8、数据倾斜的完美解决方案

9、使用mock（模拟）的数据，对模块进行调试、运行和演示效果



- 用户访问session介绍

用户的每一次操作，其实可以理解为一个action，比如点击、搜索、下单、支付
简单理解，session就是某一天某一个时间段内，某个用户对网站从打开、进入做了大量操作，到最后关闭浏览器的过程就叫做session。


- 在实际企业项目中的使用架构


1、J2EE的平台（美观的前端页面），其中就包括一个模块，就是用户访问session分析模块；可以指定各种各样的筛选条件，比如年龄范围、职业、城市等等。

2、J2EE平台接收到了执行统计分析任务的请求之后，会调用底层的封装了spark-submit的shell脚本（Runtime、Process），shell脚本进而提交我们编写的Spark作业。

3、Spark作业获取使用者指定的筛选参数，然后运行复杂的作业逻辑，进行该模块的统计和分析。

4、Spark作业统计和分析的结果，会写入MySQL中，指定的表

5、最后，J2EE平台，使用者可以通过前端页面（美观），以表格、图表的形式展示和查看MySQL中存储的该统计分析任务的结果数据。

模块->调用shell脚本->spark工作->写入MYSQL->展现








#### 2.基础数据结构以及大数据平台架构介绍


企业中会有专门的大数据ETL开发工程师，对原始的日志数据，开发大量的ETL，对数据进行各种转换和抽取。然后可能会为了各种业务的需要，形成大量的各种各样的结构的表，可能已经进行了处理或者是某些聚合的操作。

这里我们只会做Spark相关的东西，就是说编写Spark作业程序；spark-submit脚本；数据表的设计；我们只会做，spark从MySQL表中读取任务参数，执行作业逻辑，持久化作业结果数据。


-数据库

表名：user_visit_action（Hive表）

user_visit_action表，其实就是放，比如说网站，或者是app，每天的点击流的数据。可以理解为，用户对网站/app每点击一下，就会代表在这个表里面的一条数据。


表名：user_info（Hive表）

user_info表，实际上，就是一张最普通的用户基础信息表


表名：task（MySQL表）

task_param：用来使用JSON的格式，来封装用户提交的任务对应的特殊的筛选参数

task表，其实是用来保存平台的使用者，通过J2EE系统，提交的基于特定筛选参数的分析任务的信息，就会通过J2EE系统保存到task表中来。之所以使用MySQL表，是因为J2EE系统是要实现快速的实时插入和查询的。


使用者
->提交请求
->J2EE平台展示
  ->提交的任务信息插入到MySQL中的task表中去（Spark作业在运行时的第一件事情，就是从MySQL的task表中，读取本任务需要使用的一些筛选参数）
  ->所在的部署的linux机器，在一起的封装了spark-submit命令的shell和Spark作业的jar包
->Spark Standalone集群上去运行；YARN集群上去运行（Spark作业）(在spark作业运行过程中，或者运行完之后，会将统计分析的结果数据，插入到MySQL中)
->J2EE平台从MySQL业务表中读取结果数据，封装为JSON数据格式，返回前端页面展示。
->任务运行结束后，点击对应的链接，查看结果数据的展示图表和报表





#### 3.需求分析

- 1、按条件筛选session

这个功能，就最大的作用就是灵活。也就是说，可以让使用者，对感兴趣的和关系的用户群体，进行后续各种复杂业务逻辑的统计和分析



- 2、统计出符合条件的session中，访问时长在1s~3s、4s~6s、7s~9s、10s~30s、30s~60s、1m~3m、3m~10m、10m~
30m、30m以上各个范围内的session占比；访问步长在1~3、4~6、7~9、10~30、30~
60、60以上各个范围内的session占比

访问时长、访问步长

这个功能的作用，其实就是，可以让人从全局的角度看到，符合某些条件的用户群体，使用我们的产品的一些习惯。比如大多数人，到底是会在产品中停留多长时间，大多数人，会在一次使用产品的过程中，访问多少个页面。



- 3、在符合条件的session中，按照时间比例随机抽取1000个session



之所以要做到按时间比例随机采用抽取，就是要做到，观察样本的公平性。


- 4、在符合条件的session中，获取点击、下单和支付数量排名前10的品类

要计算出所有这些session对各个品类的点击、下单和支付的次数，然后按照这三个属性进行排序，获取前10个品类。

这个功能，很重要，就可以让我们明白，就是符合条件的用户，他最感兴趣的商品是什么种类。



- 5、对于排名前10的品类，分别获取其点击次数排名前10的session


这个就是说，对于top10的品类，每一个都要获取对它点击次数排名前10的session。


这个功能，可以让我们看到，对某个用户群体最感兴趣的品类，各个品类最感兴趣最典型的用户的session的行为。


#### 4.技术方案设计

- 1、按条件筛选session

筛选的粒度是不同的，比如说搜索词、访问时间，那么这个都是session粒度的，甚至是action粒度的

针对用户的基础信息进行筛选，年龄、性别、职业。所以说筛选粒度是不统一的。

session粒度的聚合

1. 用一些最基本的筛选条件，比如时间范围，从hive表中提取数据
2.按照session_
id这个字段进行聚合，那么聚合后的一条记录，就是一个用户的某个session在指定时间内的访问的记录
3. 聚合过后，针对session粒度的数据，按照使用者指定的筛选条件，进行数据的筛选。

- 2、聚合统计

在spark中，要实现分布式安全的累加操作，基本上只有一个最好的选择，就是Accumulator变量

如果是基础的Accumulator变量，那么可能需要将近20个Accumulator变量，1s~3s、4s~6s。


所以，对于这个情况，那么我们就可以使用自定义Accumulator的技术，来实现复杂的分布式计算。也就是说，就用一个Accumulator，来计算所有的指标。

- 3、在符合条件的session中，按照时间比例随机抽取1000个session

综合运用Spark的countByKey、groupByKey、mapToPair等算子，来开发一个复杂的按时间比例随机均匀采样抽取的算法。（大数据算法）

- 4、在符合条件的session中，获取点击、下单和支付数量排名前10的品类

1. 对每个品类的点击、下单和支付的数量都进行计算
2. 使用Spark的自定义Key二次排序算法的技术，来实现所有品类，按照三个字段，点击数量、下单数量、支付数量依次进行排序

- 5、对于排名前10的品类，分别获取其点击次数排名前10的session

使用Spark的分组取TopN的算法来进行实现，也就是说对排名前10的品类对应的数据，按照品类id进行分组，然后求出每组点击数量排名前10的session。




#### 5.数据表设计


数据设计，包含两个环节，
第一个：我们的上游数据，**项目基于的基础数据**，是否要针对其开发一些Hive ETL，对数
据进行进一步的处理和转换，从而让我们能够更加方便的和快速的去计算和执行spark作业；
第二个：就是要设计spark作业要保存**结果数据的业务表**
的结构，从而让J2EE平台可以使用业务表中的数据，来为使用者展示任务执行结果。

设计MySQL中的业务表的结构：

第一个表：session_aggr_stat表，存储第一个功能，session聚合统计的结果

第二个表：session_random_extract表，存储我们的按时间比例随机抽取功能抽取出来的1000个session

第三个表：top10_category表，存储按点击、下单和支付排序出来的top10品类数据

第四个表：top10_category_session表，存储top10每个品类的点击top10的session

最后一张表：session_detail，用来存储随机抽取出来的session的明细数据、top10品类的session的明细数据

额外的一张表：task表，用来存储J2EE平台插入其中的任务的信息

接下来，就是在完成了数据调研、需求分析、技术方案设计、数据设计以后，正式进入编码实现和功能测试阶段。最后才是性能调优阶段。


---

### Spark上下文构建以及模拟数据生成

- MockData.java （模拟数据程序）

1. 生成数据

2. 将DataFrame中封装的数据注册为一张临时表
  "user_visit_action"
  "user_info"
  "product_info"


- UserVisitSessionAnalyzeSpark.java

1. 获取SQLContext

  如果是在本地测试环境的话，那么就生成SQLContext对象
  如果是在生产环境运行的话，那么就生成HiveContext对象



2. 生成模拟数据

  生成模拟数据（只有本地模式，才会去生成模拟数据）

### 按session粒度进行数据聚合\代码

- UserVisitSessionAnalyzeSpark.java


1. 获取指定日期范围内的用户访问行为数据

  @param sqlContext SQLContext
  @param taskParam 任务参数
  SQLContext调用HQL


2. 对行为数据按session粒度进行聚合

  @param actionRDD 行为数据RDD
  @return session粒度聚合数据

  1.对行为数据按session粒度进行分组

    到此为止，获取的数据格式，<userid,partAggrInfo(sessionid,searchKeywords,clickCategoryIds)>

  2.对每一个session分组进行聚合，将session中所有的搜索词和点击品类都聚合起来，输出一个JavaPairRDD map
    遍历session所有的访问行为
      提取每个访问行为的搜索词字段和点击品类字段
      计算session开始和结束时间
      计算session访问步长
      计算session访问时长（秒）

  3.查询所有用户数据，并映射成<userid,Row>的格式
  4.将session粒度聚合数据，与用户信息进行join
  5.对join起来的数据进行拼接，并且返回<sessionid,fullAggrInfo>格式的数据

### 按筛选参数对session粒度聚合数据进行过滤




- UserVisitSessionAnalyzeSpark.java

1. 过滤session数据

  @param sessionid2AggrInfoRDD
  1.为了使用我们后面的ValieUtils，所以，首先将所有的筛选参数拼接成一个连接串
  2.根据筛选参数进行过滤

---

### session聚合统计之自定义Accumulator

不打算采用传统的方式，用十几个，甚至二十个Accumulator，因为维护成本太高
这里的实现思路是，我们自己自定义一个Accumulator，实现较为复杂的计算逻辑，一个Accumulator维护了所有范
围区间的数量的统计逻辑

使用自定义Accumulator，大家就可以任意的实现自己的复杂分布式计算的逻辑

使用自定义Accumulator，可以更方便进行中间状态的维护，而且不用担心并发和锁的问题



- SessionAggrStatAccumulator.java

1. 数据的初始化
2. 在v1中，找到v2对应的value，累加1，然后再更新回连接串里面去
  v1可能就是我们初始化的那个连接串
  v2，就是我们在遍历session的时候，判断出某个session对应的区间 
  session统计计算逻辑 add()


###　session聚合统计之计算统计结果并写入MySQL

- ISessionAggrStatDAO

  session聚合统计模块DAO接口

- SessionAggrStatDAOImpl

  session聚合统计DAO实现类


- UserVisitSessionAnalyzeSpark

1. 计算各session范围占比，并写入MySQL
  1.从Accumulator统计串中获取值
  2.计算各个访问时长和访问步长的范围
  3.将统计结果封装为Domain对象
  4.调用对应的DAO插入统计结果


### session聚合统计之使用Scala实现自定义Accumulator

- SessionAggrStatAccumulatorTest.scala


---

### session随机抽取之实现思路分析


session聚合数据进行映射，将每个session发生的yyyy-MM-dd_HH（start_time）作为key，value就是session_id

对上述数据，使用countByKey算子，就可以获取到每天每小时的session数量




### session随机抽取之计算每天每小时session数量

-UserVisitSessionAnalyzeSpark.java

1. 随机抽取session

  @param sessionid2AggrInfoRDD
  1.计算出每天每小时的session数量
    1.获取< yyyy-MM-dd_HH,aggrInfo>格式的RDD：time2sessionidRDD
    2.得到每天每小时的session数量：countMap

  2.使用按时间比例随机抽取算法，计算出每天每小时要抽取session的索引：hourCountMap
    1.将< yyyy-MM-dd_HH,count>格式的map，转换成< yyyy-MM-dd,<HH,count>>的格式：dateHourCountMap
    2.实现按时间比例随机抽取算法
      1.计算出这一天的session总数:sessionCount
      2.遍历每个小时
        1.计算每个小时的session数量，占据当天总session数量的比例，直接乘以每天要抽取的数量，就可以计算出，当前小时需要抽取的session数量:hourExtractNumber
        2.先获取当前小时的存放随机数的list:extractIndexList
        3.生成上面计算出来的数量的随机数:extractIndexList

  3.遍历每天每小时的session，然后根据随机索引进行抽取:extractSessionidsRDD

  4.获取抽取出来的session的明细数据:xtractSessionDetailRDD



### session随机抽取之根据随机索引进行抽取

- ISessionRandomExtractDAO.java

session随机抽取模块DAO接口

- SessionRandomExtractDAOImpl.java

随机抽取session的DAO实现

- UserVisitSessionAnalyzeSpark.java


### session随机抽取之获取抽取session的明细数据

- ISessionDetailDAO.java

Session明细DAO接口

- SessionDetailDAOImpl.java

session明细DAO实现类

- UserVisitSessionAnalyzeSpark.java


---

### top10热门品类之需求回顾以及实现思路分析


计算出来通过筛选条件的那些session，他们访问过的所有品类（点击、下单、支付），按照各个品类的点击、下单和支付次数，降序排序，获取前10个品类，也就是筛选条件下的那一批session的top10热门品类；

二次排序，顾名思义，就是说，不只是根据一个字段进行一次排序，可能是要根据多个字段，进行多次排序的
点击、下单和支付次数，依次进行排序，就是二次排序



sortByKey算子，默认情况下，它支持根据int、long等类型来进行排序，但是那样的话，key就只能放一个字段了
所以需要自定义key，作为sortByKey算子的key，自定义key中，封装n个字段，并在key中，自己在指定接口方法中，实现自己的根据多字段的排序算法
然后再使用sortByKey算子进行排序，那么就可以按照我们自己的key，使用多个字段进行排序



实现思路分析：

1、拿到通过筛选条件的那批session，访问过的所有品类

2、计算出session访问过的所有品类的点击、下单和支付次数，这里可能要跟第一步计算出来的品类进行join

3、自己开发二次排序的key

4、做映射，将品类的点击、下单和支付次数，封装到二次排序key中，作为PairRDD的key

5、使用sortByKey(false)，按照自定义key，进行降序二次排序

6、使用take(10)获取，排序后的前10个品类，就是top10热门品类

7、将top10热门品类，以及每个品类的点击、下单和支付次数，写入MySQL数据库

8、本地测试

9、使用Scala来开发二次排序key







### top10热门品类之获取session访问过的所有品类

- UserVisitSessionAnalyzeSpark.java


1. 获取符合条件的session访问过的所有品类，并且去重
2. 计算各品类的点击、下单和支付的次数
3. join各品类与它的点击、下单和支付的次数
4. 自定义二次排序key
5. 将数据映射成<CategorySortKey,info>格式的RDD，然后进行二次排序（降序）
6. 用take(10)取出top10热门品类，并写入MySQL



### top10热门品类之join品类与点击下单支付次数：tmpMapRDD

- UserVisitSessionAnalyzeSpark.java

  @param categoryidRDD
  @param clickCategoryId2CountRDD
  @param orderCategoryId2CountRDD
  @param payCategoryId2CountRDD



### top10热门品类之自定义二次排序key

- CategorySortKey.java

  品类二次排序key
  依次使用三个次数进行比较，如果某一个相等，那么就比较下一个


### top10热门品类之进行二次排序

- UserVisitSessionAnalyzeSpark.java

  1. getClickCategoryId2CountRDD:获取各品类点击次数RDD

  filter过滤
  coalesce算子

  2. getOrderCategoryId2CountRDD:获取各品类的下单次数RDD

  3. getPayCategoryId2CountRDD:获取各个品类的支付次数RDD





### top10活跃session之开发准备以及top10品类RDD生成


  top10热门品类，获取每个品类点击次数最多的10个session，以及其对应的访问明细


  1、拿到符合筛选条件的session的明细数据
  2、按照session粒度进行聚合，获取到session对每个品类的点击次数，用flatMap，算子函数返回的是<categoryid,(sessionid,clickCount)>
  3、按照品类id，分组取top10，获取到top10活跃session；groupByKey；自己写算法，获取到点击次数最多的前10个session，直接写入MySQL表；返回的是sessionid
  4、获取各品类top10活跃session的访问明细数据，写入MySQL
  5、本地测试

  1、重构一下之前的代码，将通过筛选条件的session的访问明细数据RDD，提取成公共的RDD；这样就不用重复计算同样的RDD

  2、将之前计算出来的top10热门品类的id，生成一个PairRDD，方便后面进行join





- UserVisitSessionAnalyzeSpark.java

  getTop10Session:获取top10活跃session

1. 将top10热门品类的id，生成一份RDD: top10CategoryIdRDD
2. 计算top10品类被各session点击的次数:top10CategorySessionCountRDD
3. 分组取TopN算法实现，获取每个品类的top10活跃用户:top10SessionRDD
4. 获取top10活跃session的明细数据，并写入MySQL:sessionDetailRDD


---

### 性能调优之在实际项目中分配更多资源

  问题：
  1、分配哪些资源？
  2、在哪里分配这些资源？
  3、为什么多分配了这些资源以后，性能会得到提升？


  1、分配哪些资源？executor、cpu per executor、memory per executor、driver memory

  2、在哪里分配这些资源？在我们在生产环境中，提交spark作业时，用的spark-submit shell脚本，里面调整对应的参数

  /usr/local/spark/bin/spark-submit \
  --class cn.spark.sparktest.core.WordCountCluster \
  --num-executors 3 \  配置executor的数量
  --driver-memory 100m \  配置driver的内存（影响不大）
  --executor-memory 100m \  配置每个executor的内存大小
  --executor-cores 3 \  配置每个executor的cpu core数量
  /usr/local/SparkTest-0.0.1-SNAPSHOT-jar-with-dependencies.jar \

3、调节到多大，算是最大呢？

  1.Spark Standalone
  2.Yarn
  一个原则，你能使用的资源有多大，就尽量去调节到最大的大小（executor的数量，几十个到上百个不等；executor内存；executor cpu core）


  4、为什么调节了资源以后，性能可以提升？

SparkContext，DAGScheduler，TaskScheduler，会将我们的算子，切割成大量的task，提交到Application的executor上面去执行。


1. 增加executor：


2. 增加每个executor的内存量

  RDD进行cache
  shuffle操作，reduce端，会需要内存来存放拉取的数据并进行聚合
  task的执行

3. 增加每个executor的cpu core

  增加了执行的并行能力.原本20个executor，每个才2个cpu core。能够并行执行的task数量，就是40个task。

### 性能调优之在实际项目中调节并行度


Spark并行度指的是什么？

Spark作业，Application，Jobs，action（collect）触发一个job，1个job；每个job拆成多个stage，发生shuffle的时候，会拆分出一个stage，reduceByKey；

并行度：其实就是指的是，Spark作业中，各个stage的task数量，也就代表了Spark作业的在各个阶段（stage）的并行度。

官方推荐，task数量，设置成spark application总cpu core数量的2-3倍

  如何设置一个Spark Application的并行度？
  spark.default.parallelism 
  SparkConf conf = new SparkConf()
    .set("spark.default.parallelism", "500")



### 性能调优之在实际项目中重构RDD架构以及RDD持久化


  一旦出现一个RDD重复计算的情况，就会导致性能急剧降低。

  另外一种情况，从一个RDD到几个不同的RDD，算子和计算逻辑其实是完全一样的，结果因为人为的疏忽，计算了多次，获取到了多个RDD。

第一，RDD架构重构与优化

  尽量去复用RDD，差不多的RDD，可以抽取称为一个共同的RDD，供后面的RDD计算时，反复使用。

第二，公共RDD一定要实现持久化

第三，持久化，是可以进行序列化的

  使用序列化的方式在纯内存中存储

第四，为了数据的高可靠性，而且内存充足，可以使用双副本机制，进行持久化


### 性能调优之在实际项目中广播大变量



广播，Broadcast，将大变量广播出去。而不是直接使用。


如果使用了广播变量，不一定都是从Driver传输到每个节点，还可能是就近从最近的节点的executor的bockmanager上拉取变量副本

广播变量，在driver上会有一份初始的副本


广播变量的好处，不是每个task一份变量副本，而是变成每个节点的executor才一份副本。这样的话，就可以让变量产生的副本大大减少。


1. task在运行的时候，想要使用广播变量中的数据，此时首先会在自己本地的Executor对应的BlockManager中，尝试获取变量副本
2. 如果本地没有，那么就从Driver远程拉取变量副本，并保存在本地的BlockManager中；此后这个executor上的task，都会直接使用本地的BlockManager中的副本。


### 性能调优之在实际项目中使用Kryo序列化


算子函数中用到了外部变量，会序列化，使用Kryo


在进行stage间的task的shuffle操作时，节点与节点之间的task会互相大量通过网络拉取和传输文件，此时，这些数据既然通过网络传输，也是可能要序列化的，就会使用Kryo



Kryo序列化优化以后，可以让网络传输的数据变少；在集群中耗费的内存资源大大减少。

Kryo序列化机制，一旦启用以后，会生效的几个地方：

  1、算子函数中使用到的外部变量
  2、持久化RDD时进行序列化，StorageLevel.MEMORY_ONLY_SER
  3、shuffle



### 性能调优之在实际项目中使用fastutil优化数据格式


fastutil是扩展了Java标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的map、set、list和queue；


Spark中应用fastutil的场景：

1. 如果算子函数使用了外部变量；

  那么第一，你可以使用Broadcast广播变量优化；
  第二，可以使用Kryo序列化类库，提升序列化性能和效率；
  第三，如果外部变量是某种比较大的集合，那么可以考虑使用fastutil改写外部变量，首先从源头上就减少内存的占用，通过广播变量进一步减少内存占用，再通过Kryo序列化类库进一步减少内存占用。


2. 在你的算子函数里，也就是task要执行的计算逻辑里面，如果有逻辑中，出现，要创建比较大的Map、List等集合，可能会占用较大的内存空间，而且可能涉及到消耗性能的遍历、存取等集合操作；那么此时，可以考虑将这些集合类型使用fastutil类库重写，使用了fastutil集合类以后，就可以在一定程度上，减少task创建出来的集合类型的内存占用。避免executor内存频繁占满，频繁唤起GC，导致性能下降。






### 性能调优之在实际项目中调节数据本地化等待时长


  PROCESS_LOCAL：进程本地化，代码和数据在同一个进程中，也就是在同一个executor中；计算数据的task由executor执行，数据在executor的BlockManager中；性能最好
  NODE_LOCAL：节点本地化，代码和数据在同一个节点中；比如说，数据作为一个HDFS block块，就在节点上，而task在节点上某个executor中运行；或者是，数据和task在一个节点上的不同executor中；数据需要在进程间进行传输
  NO_PREF：对于task来说，数据从哪里获取都一样，没有好坏之分
  RACK_LOCAL：机架本地化，数据和task在一个机架的两个节点上；数据需要通过网络在节点之间进行传输
  ANY：数据和task可能在集群中的任何地方，而且不在一个机架中，性能最差

  spark.locality.wait，默认是3s


最佳情况，直接在一个executor进程内，走内存速度最佳

sk和数据在一个节点上，直接从本地executor的BlockManager中获取数据，纯内存，或者带一点磁盘IO；如果要通过网络传输数据的话，那么实在是，性能肯定会下降的，大量网络传输，以及磁盘IO，都是性能的杀手。




### JVM调优之原理概述以及降低cache操作的内存占比





1. 常规性能调优：分配资源、并行度等

2. JVM调优（Java虚拟机）：JVM相关的参数，通常情况下，如果你的硬件配置、基础的JVM的配置，都ok的话，JVM通常不会造成太严重的性能问题；反而更多的是，在troubleshooting中，JVM占了很重要的地位；JVM造成线上的spark作业的运行报错，甚至失败（比如OOM）。

3. shuffle调优（相当重要）：spark在执行groupByKey、reduceByKey等操作时的，shuffle环节的调优。这个很重要。shuffle调优，其实对spark作业的性能的影响，是相当之高！！！经验：在spark作业的运行过程中，只要一牵扯到有shuffle的操作，基本上shuffle操作的性能消耗，要占到整个spark作业的50%-90%。10%用来运行map等操作，90%耗费在两个shuffle操作。groupByKey、countByKey。

4. spark操作调优（spark算子调优，比较重要）：groupByKey，countByKey或aggregateByKey来重构实现。有些算子的性能，是比其他一些算子的性能要高的。foreachPartition替代foreach。如果一旦遇到合适的情况，效果还是不错的。

  1、分配资源、并行度、RDD架构与缓存
  2、shuffle调优
  3、spark算子调优
  4、JVM调优、广播大变量。。。


清理掉了不再使用的对象之后，那么也会将存活下来的对象（还要继续使用的），放入之前空闲的那一个survivor区域中。这里可能会出现一个问题。默认eden、survior1和survivor2的内存占比是8:1:1。问题是，如果存活下来的对象是1.5，一个survivor区域放不下。此时就可能通过JVM的担保机制（不同JVM版本可能对应的行为），将多余的对象，直接放入老年代了。

内存不充足的时候，问题：

  1、频繁minor gc，也会导致频繁spark停止工作
  2、老年代囤积大量活跃对象（短生命周期的对象），导致频繁full gc，full gc时间很长，短则数十秒，长则数分钟，甚至数小时。可能导致spark长时间停止工作。
  3、严重影响咱们的spark的性能和运行的速度。

### JVM调优之调节executor堆外内存与连接等待时长


有时候，如果你的spark作业处理的数据量特别特别大，几亿数据量；然后spark作业一运行，时不时的报错，shuffle file cannot find，executor、task lost，out of memory（内存溢出）；

处于垃圾回收过程中，所有的工作线程全部停止；相当于只要一旦进行垃圾回收，spark / executor停止工作，无法提供响应


  spark.core.connection.ack.wait.timeout（spark core，connection，连接，ack，wait timeout，建立不上连接的时候，超时等待时长）



---

### Shuffle调优之原理概述



什么样的情况下，会发生shuffle？

在spark中，主要是以下几个算子：groupByKey、reduceByKey、countByKey、join，等等。

什么是shuffle？

groupByKey，要把分布在集群各个节点上的数据中的同一个key，对应的values，都给集中到一块儿，集中到集群中同一个节点上，更严密一点说，就是集中到一个节点的一个executor的一个task中。


不是stage决定shuffle，是shuffle决定stage。


### Shuffle调优之合并map端输出文件


  new SparkConf().set("spark.shuffle.consolidateFiles", "true")

开启shuffle map端输出文件合并的机制；默认情况下，是不开启的，就是会发生如上所述的大量map端输出文件的操作，严重影响性能。

开启了map端输出文件的合并机制之后：

第一个stage，同时就运行cpu core个task，比如cpu core是2个，并行运行2个task；每个task都创建下一个stage的task数量个文件；

第一个stage，并行运行的2个task执行完以后；就会执行另外两个task；另外2个task不会再重新创建输出文件；而是复用之前的task创建的map端输出文件，将数据写入上一批task的输出文件中。

第二个stage，task在拉取数据的时候，就不会去拉取上一个stage每一个task为自己创建的那份输出文件了；而是拉取少量的输出文件，每个输出文件中，可能包含了多个task给自己的map端输出。


1. map task写入磁盘文件的IO，减少：100万文件 -> 20万文件

2. 第二个stage，原本要拉取第一个stage的task数量份文件，1000个task，第二个stage的每个task，都要拉取1000份文件，走网络传输；合并以后，100个节点，每个节点2个cpu core，第二个stage的每个task，主要拉取100 * 2 = 200个文件即可；网络传输的性能消耗是不是也大大减少


实际生产环境的条件：
  100个节点（每个节点一个executor）：100个executor
  每个executor：2个cpu core
  总共1000个task：每个executor平均10个task

  每个节点，2个cpu core，有多少份输出文件呢？2 * 1000 = 2000个
  总共100个节点，总共创建多少份输出文件呢？100 * 2000 = 20万个文件

  相比较开启合并机制之前的情况，100万个

### Shuffle调优之调节map端内存缓冲与reduce端内存占比

1. 默认情况下，shuffle的map task，输出到磁盘文件的时候，统一都会先写入每个task自己关联的一个内存缓冲区。
2. 每一次，当内存缓冲区满溢之后，才会进行spill操作，溢写操作，溢写到磁盘文件中去
3. reduce端task，在拉取到数据之后，会用hashmap的数据格式，来对各个key对应的values进行汇聚。
4. 很有可能会出现，拉取过来的数据很多，那么在内存中，放不下；这个时候，默认的行为，就是说，将在内存放不下的数据，都spill（溢写）到磁盘文件中去。

调优：
  调节reduce端聚合内存占比：spark.shuffle.memoryFraction，0.2

如果发现shuffle 磁盘的write和read，很大。这个时候，就意味着最好调节一些shuffle的参数。进行调优。首先当然是考虑开启map端输出文件合并机制。

reduce task，在进行汇聚、聚合等操作的时候，实际上，使用的就是自己对应的executor的内存，executor（jvm进程，堆），默认executor内存中划分给reduce task进行聚合的比例，是0.2。

调节上面说的那两个参数。调节的时候的原则。spark.shuffle.file.buffer，每次扩大一倍，然后看看效果，64，128；spark.shuffle.memoryFraction，每次提高0.1，看看效果。

调节了以后，效果？map task内存缓冲变大了，减少spill到磁盘文件的次数；reduce端聚合内存变大了，减少spill到磁盘的次数，而且减少了后面聚合读取磁盘文件的数量。









---

### 算子调优之MapPartitions提升Map类操作性能

  1.task、job、partition之间的关系
    1.1一个task处理一个partition的数据
    1.2partition的数量是根据一次任务需fs上的block的数量决定的
    1.3一个action类算子对应一个job要处理的hd
    1.4一个job处理一个或多个partition的数据，所以一个job对应多个partition



spark中，最基本的原则，就是每个task处理一个RDD的partition。


MapPartitions操作的优点：

  如果是普通的map，比如一个partition中有1万条数据；ok，那么你的function要执行和计算1万次。

  但是，使用MapPartitions操作之后，一个task仅仅会执行一次function，function一次接收所有的partition数据。只要执行一次就可以了，性能比较高。


MapPartitions的缺点：一定是有的。

如果是普通的map操作，一次function的执行就处理一条数据；那么如果内存不够用的情况下，比如处理了1千条数据了，那么这个时候内存不够了，那么就可以将已经处理完的1千条数据从内存里面垃圾回收掉，或者用其他方法，腾出空间来吧。

所以说普通的map操作通常不会导致内存的OOM异常。

但是MapPartitions操作，对于大量数据来说，比如甚至一个partition，100万数据，一次传入一个function以后，那么可能一下子内存不够，但是又没有办法去腾出内存空间来，可能就OOM，内存溢出。


什么时候比较适合用MapPartitions系列操作，就是说，数据量不是特别大的时候，都可以用这种MapPartitions系列操作，性能还是非常不错的，



在项目中，自己先去估算一下RDD的数据量，以及每个partition的量，还有自己分配给每个executor的内存资源。看看一下子内存容纳所有的partition数据，行不行。如果行，可以试一下，能跑通就好。性能肯定是有提升的。





### 算子调优之filter过后使用coalesce减少分区数量




问题：

1、每个partition数据量变少了，但是在后面进行处理的时候，还是要跟partition数量一样数量的task，来进行处理；有点浪费task计算资源

2、每个partition的数据量不一样，会导致后面的每个task处理每个partition的时候，每个task要处理的数据量就不同，这个时候很容易发生数据倾斜

1、针对第一个问题，我们希望可以进行partition的压缩吧，因为数据量变少了，那么partition其实也完全可以对应的变少。比如原来是4个partition，现在完全可以变成2个partition。那么就只要用后面的2个task来处理即可。就不会造成task计算资源的浪费。（不必要，针对只有一点点数据的partition，还去启动一个task来计算）


2、针对第二个问题，其实解决方案跟第一个问题是一样的；也是去压缩partition，尽量让每个partition的数据量差不多。那么这样的话，后面的task分配到的partition的数据量也就差不多。不会造成有的task运行速度特别慢，有的task运行速度特别快。避免了数据倾斜的问题。

实现


  coalesce算子

主要就是用于在filter操作之后，针对每个partition的数据量各不相同的情况，来压缩partition的数量。减少partition的数量，而且让每个partition的数据量都尽量均匀紧凑。

从而便于后面的task进行计算操作，在某种程度上，能够一定程度的提升性能。






### 算子调优之使用foreachPartition优化写数据库性能

默认的foreach的性能缺陷在哪里？

首先，对于每条数据，都要单独去调用一次function，task为每个数据，都要去执行一次function函数。

如果100万条数据，（一个partition），调用100万次。性能比较差。


  foreachPartition，在生产环境中，通常来说，都使用foreachPartition来写数据库的



用了foreachPartition算子之后，好处在哪里？

  1、对于我们写的function函数，就调用一次，一次传入一个partition所有的数据

  2、主要创建或者获取一个数据库连接就可以

  3、只要向数据库发送一次SQL语句和多组参数即可


一个partition大概是1千条左右
用foreach，跟用foreachPartition，性能的提升达到了2-3分钟。



### 算子调优之使用repartition解决Spark SQL低并行度的性能问题

并行度：之前说过，并行度是自己可以调节，或者说是设置的。


实际上，在生产环境中，是最好自己设置一下的。官网有推荐的设置方式，

  你的spark-submit脚本中，会指定你的application总共要启动多少个executor，100个；
  每个executor多少个cpu core，2-3个；
  总共application，有cpu core，200个。


官方推荐，根据你的application的总cpu core数量（在spark-submit中可以指定，200个），自己手动设置spark.default.parallelism参数，指定为cpu core总数的2~3倍。400~600个并行度。600。


问题来了，Spark SQL，用了。用Spark SQL的那个stage的并行度，你没法自己指定。Spark SQL自己会默认根据hive表对应的hdfs文件的block，自动设置Spark SQL查询所在的那个stage的并行度。你自己通过spark.default.parallelism参数指定的并行度，只会在没有Spark SQL的stage中生效。



解决上述Spark SQL无法设置并行度和task数量的办法，是什么呢？


  repartition算子

你用Spark SQL这一步的并行度和task数量，肯定是没有办法去改变了。但是呢，可以将你用Spark SQL查询出来的RDD，使用repartition算子，去重新进行分区，此时可以分区成多个partition，比如从20个partition，分区成100个。






### 算子调优之reduceByKey本地聚合介绍

reduceByKey，相较于普通的shuffle操作（比如groupByKey），它的一个特点，就是说，会进行map端的本地聚合。




用reduceByKey对性能的提升：

  1、在本地进行聚合以后，在map端的数据量就变少了，减少磁盘IO。而且可以减少磁盘空间的占用。

  2、下一个stage，拉取数据的量，也就变少了。减少网络的数据传输的性能消耗。

  3、在reduce端进行数据缓存的内存占用变少了。

  4、reduce端，要进行聚合的数据量也变少了。

总结：

reduceByKey在什么情况下使用呢？

1、非常普通的，比如说，就是要实现类似于wordcount程序一样的，对每个key对应的值，进行某种数据公式或者算法的计算（累加、类乘）

2、对于一些类似于要对每个key进行一些字符串拼接的这种较为复杂的操作，可以自己衡量一下，其实有时，也是可以使用reduceByKey来实现的。但是不太好实现。如果真能够实现出来，对性能绝对是有帮助的。（shuffle基本上就占了整个spark作业的90%以上的性能消耗，主要能对shuffle进行一定的调优，都是有价值的）






---

### troubleshooting之控制shuffle reduce端缓冲大小以避免OOM

其实reduce端的task，并不是等到map端task将属于自己的那份数据全部写入磁盘文件之后，再去拉取的。map端写一点数据，reduce端task就会拉取一小部分数据，立即进行后面的聚合、算子函数的应用。

reduce端缓冲大小的另外一面，关于性能调优的一面：

咱们假如说，你的Map端输出的数据量也不是特别大，然后你的整个application的资源也特别充足。200个executor、5个cpu core、10G内存。

其实可以尝试去增加这个reduce端缓冲大小的，比如从48M，变成96M。那么这样的话，每次reduce task能够拉取的数据量就很大。需要拉取的次数也就变少了。比如原先需要拉取100次，现在只要拉取50次就可以执行完了。



reduce端缓冲（buffer），可能会出什么问题？


但是有的时候，map端的数据量特别大，然后写出的速度特别快。reduce端所有task，拉取的时候，全部达到自己的缓冲的最大极限值，缓冲，48M，全部填满。

这个时候，再加上你的reduce端执行的聚合函数的代码，可能会创建大量的对象。也许，一下子，内存就撑不住了，就会OOM。reduce端的内存中，就会发生内存溢出的问题。


这个时候，就应该减少reduce端task缓冲的大小。我宁愿多拉取几次，但是每次同时能够拉取到reduce端每个task的数量，比较少，就不容易发生OOM内存溢出的问题。（比如，可以调节成12M）



在实际生产环境中，我们都是碰到过这种问题的。这是典型的以性能换执行的原理。reduce端缓冲小了，不容易OOM了，但是，性能一定是有所下降的，你要拉取的次数就多了。就走更多的网络传输开销。

这种时候，只能采取牺牲性能的方式了,spark作业，首先，第一要义，就是一定要让它可以跑起来。然后才去考虑性能的调优。


  spark.reducer.maxSizeInFlight，48
  spark.reducer.maxSizeInFlight，24



### troubleshooting之解决JVM GC导致的shuffle文件拉取失败

  spark.shuffle.io.maxRetries 3

第一个参数，意思就是说，shuffle文件拉取的时候，如果没有拉取到（拉取失败），最多或重试几次（会重新拉取几次文件），默认是3次。

  spark.shuffle.io.retryWait 5s

第二个参数，意思就是说，每一次重试拉取文件的时间间隔，默认是5s钟。

  spark.shuffle.io.maxRetries 60
  spark.shuffle.io.retryWait 60s

最多可以忍受1个小时没有拉取到shuffle file。只是去设置一个最大的可能的值。full gc不可能1个小时都没结束吧。

这样呢，就可以尽量避免因为gc导致的shuffle file not found，无法拉取到的问题。



### troubleshooting之解决YARN队列资源不足导致的application直接失败


生产环境中的，给spark用的yarn资源队列的情况：500G内存，200个cpu core。


你的spark作业实际运行起来以后，耗费掉的资源量，可能是比你在spark-submit里面配置的，以及你预期的，是要大一些的。400G内存，190个cpu core。



第二个spark作业，又要申请320G内存+160个cpu core。结果，发现队列资源不足。。。。


此时，可能会出现两种情况：（备注，具体出现哪种情况，跟你的YARN、Hadoop的版本，你们公司的一些运维参数，以及配置、硬件、资源肯能都有关系）

  1、YARN，发现资源不足时，你的spark作业，并没有hang在那里，等待资源的分配，而是直接打印一行fail的log，直接就fail掉了。
  2、YARN，发现资源不足，你的spark作业，就hang在那里。一直等待之前的spark作业执行完，等待有资源分配给自己来执行。

采用如下方案：

1. 在你的J2EE（我们这个项目里面，spark作业的运行，之前说过了，J2EE平台触发的，执行spark-submit脚本），限制，同时只能提交一个spark作业到yarn上去执行，确保一个spark作业的资源肯定是有的。

2. 你应该采用一些简单的调度区分的方式，比如说，你有的spark作业可能是要长时间运行的，比如运行30分钟；有的spark作业，可能是短时间运行的，可能就运行2分钟。此时，都提交到一个队列上去，肯定不合适。很可能出现30分钟的作业卡住后面一大堆2分钟的作业。分队列，可以申请（跟你们的YARN、Hadoop运维的同学申请）。你自己给自己搞两个调度队列。每个队列的根据你要执行的作业的情况来设置。在你的J2EE程序里面，要判断，如果是长时间运行的作业，就干脆都提交到某一个固定的队列里面去把；如果是短时间运行的作业，就统一提交到另外一个队列里面去。这样，避免了长时间运行的作业，阻塞了短时间运行的作业。
3. 你的队列里面，无论何时，只会有一个作业在里面运行。那么此时，就应该用我们之前讲过的性能调优的手段，去将每个队列能承载的最大的资源，分配给你的每一个spark作业，比如80个executor；6G的内存；3个cpu core。尽量让你的spark作业每一次运行，都达到最满的资源使用率，最快的速度，最好的性能；并行度，240个cpu core，720个task。
4. 4、在J2EE中，通过线程池的方式（一个线程池对应一个资源队列），来实现上述我们说的方案。



### troubleshooting之解决各种序列化导致的报错

序列化报错要注意的三个点：

1. 你的算子函数里面，如果使用到了外部的自定义类型的变量，那么此时，就要求你的自定义类型，必须是可序列化的。


  final Teacher teacher = new Teacher("leo");

  studentsRDD.foreach(new VoidFunction() {
   
  public void call(Row row) throws Exception {
    String teacherName = teacher.getName();
    ....  
  }

  });

  public class Teacher implements Serializable {
    
  }

2. 如果要将自定义的类型，作为RDD的元素类型，那么自定义的类型也必须是可以序列化的


  JavaPairRDD<Integer, Teacher> teacherRDD
  JavaPairRDD<Integer, Student> studentRDD
  studentRDD.join(teacherRDD)

  public class Teacher implements Serializable {
    
  }

  public class Student implements Serializable {
    



3. 不能在上述两种情况下，去使用一些第三方的，不支持序列化的类型

  Connection conn = 

  studentsRDD.foreach(new VoidFunction() {
   
  public void call(Row row) throws Exception {
    conn.....
  }

  });

  Connection是不支持序列化的




### troubleshooting之解决算子函数返回NULL导致的问题


大家可以看到，在有些算子函数里面，是需要我们有一个返回值的。但是，有时候，我们可能对某些值，就是不想有什么返回值。我们如果直接返回NULL的话，那么可以不幸的告诉大家，是不行的，会报错的。

有一个解决的办法：

  1、在返回的时候，返回一些特殊的值，不要返回null，比如“-999”
  2、在通过算子获取到了一个RDD之后，可以对这个RDD执行filter操作，进行数据过滤。filter内，可以对数据进行判定，如果是-999，那么就返回false，给过滤掉就可以了。
  3、算子调优里面的coalesce算子，在filter之后，可以使用coalesce算子压缩一下RDD的partition的数量，让各个partition的数据比较紧凑一些。也能提升一些性能。




### troubleshooting之解决yarn-client模式导致的网卡流量激增问题

Application-Master？

  yarn中的核心概念，任何要在yarn上启动的作业类型（mr、spark），都必须有一个。

Driver到底是什么？

  我们写的spark程序，打成jar包，用spark-submit来提交。jar包中的一个main类，通过jvm的命令启动起来。
  JVM进程，这个进程，其实就是咱们的Driver进程。
  Driver进程启动起来以后，执行我们自己写的main函数，从new SparkContext()


  每种计算框架（mr、spark），如果想要在yarn上执行自己的计算应用，那么就必须自己实现和提供一个ApplicationMaster

  相当于是实现了yarn提供的接口，spark自己开发的一个类


  spark在yarn-client模式下，application的注册（executor的申请）和计算task的调度，是分离开来的。

  standalone模式下，这两个操作都是driver负责的。

  ApplicationMaster(ExecutorLauncher)负责executor的申请；

  driver负责job和stage的划分，以及task的创建、分配和调度。

解决的方法：

yarn-client模式是什么情况下，可以使用的？yarn-client模式，通常咱们就只会使用在测试环境中，你写好了某个spark作业，打了一个jar包，在某台测试机器上，用yarn-client模式去提交一下。

yarn-client模式提交，可以在本地机器观察到详细全面的log。通过查看log，可以去解决线上报错的故障（troubleshooting）、对性能进行观察并进行性能调优。

实际上线了以后，在生产环境中，都得用yarn-cluster模式，去提交你的spark作业。

yarn-cluster模式，就跟你的本地机器引起的网卡流量激增的问题，就没有关系了。也就是说，就算有问题，也应该是yarn运维团队和基础运维团队之间的事情了。使用了yarn-cluster模式以后，就不是你的本地机器运行Driver，进行task调度了。是yarn集群中，某个节点会运行driver进程，负责task调度。


### troubleshooting之解决yarn-cluster模式的JVM栈内存溢出问题

  yarn-client模式，driver运行在本地机器上的；
  yarn-cluster模式，driver是运行在yarn集群上某个nodemanager节点上面的。

yarn-cluster的问题：



有的时候，运行一些包含了spark sql的spark作业，可能会碰到yarn-client模式下，可以正常提交运行；yarn-cluster模式下，可能是无法提交运行的，会报出JVM的PermGen（永久代）的内存溢出，OOM。




yarn-client模式下，driver是运行在本地机器上的，spark使用的JVM的PermGen的配置，是本地的spark-class文件（spark客户端是默认有配置的），JVM的永久代的大小是128M，这个是没有问题的；

但是呢，在yarn-cluster模式下，driver是运行在yarn集群的某个节点上的，使用的是没有经过配置的默认设置（PermGen永久代大小），82M。

spark-sql，它的内部是要进行很复杂的SQL的语义解析、语法树的转换等等，特别复杂，在这种复杂的情况下，如果说你的sql本身特别复杂的话，很可能会比较导致性能的消耗，内存的消耗。可能对PermGen永久代的占用会比较大。

所以，此时，如果对永久代的占用需求，超过了82M的话，但是呢又在128M以内；

就会出现如上所述的问题，yarn-client模式下，默认是128M，这个还能运行；

如果在yarn-cluster模式下，默认是82M，就有问题了。会报出PermGen Out of Memory error log。



如何解决这种问题？



既然是JVM的PermGen永久代内存溢出，那么就是内存不够用。咱们呢，就给yarn-cluster模式下的，driver的PermGen多设置一些。

spark-submit脚本中，加入以下配置即可：
--conf spark.driver.extraJavaOptions="-XX:PermSize=128M -XX:MaxPermSize=256M"

这个就设置了driver永久代的大小，默认是128M，最大是256M。那么，这样的话，就可以基本保证你的spark作业不会出现上述的yarn-cluster模式导致的永久代内存溢出的问题。


sql，有大量的or语句。比如where keywords='' or keywords='' or keywords=''
当达到or语句，有成百上千的时候，此时可能就会出现一个driver端的jvm stack overflow，JVM栈内存溢出的问题


JVM栈内存溢出，基本上就是由于调用的方法层级过多，因为产生了大量的，非常深的，超出了JVM栈深度限制的，递归。递归方法。

JVM Stack Memory Overflow，栈内存溢出。


这种时候，建议不要搞那么复杂的spark sql语句。采用替代方案：将一条sql语句，拆解成多条sql语句来执行。每条sql语句，就只有100个or子句以内；一条一条SQL语句来执行。根据生产环境经验的测试，一条sql语句，100个or子句以内，是还可以的。通常情况下，不会报那个栈内存溢出。




### troubleshooting之错误的持久化方式以及checkpoint的使用

正确的持久化使用方式：

  usersRDD
  usersRDD = usersRDD.cache()
  val cachedUsersRDD = usersRDD.cache()



进行checkpoint，就是说，会将RDD的数据，持久化一份到容错的文件系统上（比如hdfs）。

checkpoint，其实就是可以作为是cache的一个备胎。如果cache失效了，checkpoint就可以上来使用了。

checkpoint有利有弊，利在于，提高了spark作业的可靠性，一旦发生问题，还是很可靠的，不用重新计算大量的rdd；但是弊在于，进行checkpoint操作的时候，也就是将rdd数据写入hdfs中的时候，还是会消耗性能的。

checkpoint，用性能换可靠性。

checkpoint原理：

1、在代码中，用SparkContext，设置一个checkpoint目录，可以是一个容错文件系统的目录，比如hdfs；

2、在代码中，对需要进行checkpoint的rdd，执行RDD.checkpoint()；

3、RDDCheckpointData（spark内部的API），接管你的RDD，会标记为marked for checkpoint，准备进行checkpoint

4、你的job运行完之后，会调用一个finalRDD.doCheckpoint()方法，会顺着rdd lineage，回溯扫描，发现有标记为待checkpoint的rdd，就会进行二次标记，inProgressCheckpoint，正在接受checkpoint操作

5、job执行完之后，就会启动一个内部的新job，去将标记为inProgressCheckpoint的rdd的数据，都写入hdfs文件中。（备注，如果rdd之前cache过，会直接从缓存中获取数据，写入hdfs中；如果没有cache过，那么就会重新计算一遍这个rdd，再checkpoint）

6、将checkpoint过的rdd之前的依赖rdd，改成一个CheckpointRDD\*，强制改变你的rdd的lineage。后面如果rdd的cache数据获取失败，直接会通过它的上游CheckpointRDD，去容错的文件系统，比如hdfs，中，获取checkpoint的数据。


---


### 数据倾斜解决方案之原理以及现象分析

  1、数据倾斜的原理
  2、数据倾斜的现象
  3、数据倾斜的产生原因与定位






### 数据倾斜解决方案之聚合源数据以及过滤导致倾斜的key


性能调优，调了半天，最有效，最直接，最简单的方式，就是加资源，加并行度，注意RDD架构（复用同一个RDD，加上cache缓存）；shuffle、jvm等，次要的。

数据倾斜，解决方案，第一个方案和第二个方案，一起来讲。最朴素、最简谱、最直接、最有效、最简单的，解决数据倾斜问题的方案。

  第一个方案：聚合源数据
  第二个方案：过滤导致倾斜的key


- 第一个方案：聚合源数据



  groupByKey、reduceByKey；groupByKey，就是拿到每个key对应的values；
  reduceByKey，说白了，就是对每个key对应的values执行一定的计算。

hive就是适合做离线的，晚上凌晨跑的，ETL（extract transform load，数据的采集、清洗、导入），hive sql，去做这些事情，从而去形成一个完整的hive中的数据仓库；说白了，数据仓库，就是一堆表。

对每个key在hive etl中进行聚合，对所有values聚合一下，不一定是拼接起来，可能是直接进行计算。reduceByKey，计算函数，应用在hive etl中，每个key的values。



聚合源数据方案，第二种做法


你可能没有办法对每个key，就聚合出来一条数据；

那么也可以做一个妥协；对每个key对应的数据，10万条；有好几个粒度，比如10万条里面包含了几个城市、几天、几个地区的数据，现在放粗粒度；


尽量去聚合，减少每个key对应的数量，也许聚合到比较粗的粒度之后，原先有10万数据量的key，现在只有1万数据量。减轻数据倾斜的现象和问题。


对于我们的程序来说，完全可以将aggregateBySession()这一步操作，放在一个hive etl中来做，形成一个新的表。对每天的用户访问行为数据，都按session粒度进行聚合，写一个hive sql。


在spark程序中，就不要去做groupByKey+mapToPair这种算子了。直接从当天的session聚合表中，用Spark SQL查询出来对应的数据，即可。这个RDD在后面就可以使用了。


- 第二个方案：过滤导致倾斜的key





### 数据倾斜解决方案之提高shuffle操作reduce并行度



将reduce task的数量，变多，就可以让每个reduce task分配到更少的数据量，这样的话，也许就可以缓解，或者甚至是基本解决掉数据倾斜的问题。


- 提升shuffle reduce端并行度，怎么来操作？

  很简单，主要给我们所有的shuffle算子，比如groupByKey、countByKey、reduceByKey。
  在调用的时候，传入进去一个参数。
  一个数字。那个数字，就代表了那个shuffle操作的reduce端的并行度。
  那么在进行shuffle操作的时候，就会对应着创建指定数量的reduce task。

这样的话，就可以让每个reduce task分配到更少的数据。基本可以缓解数据倾斜的问题。


比如说，原本某个task分配数据特别多，直接OOM，内存溢出了，程序没法运行，直接挂掉。按照log，找到发生数据倾斜的shuffle操作，给它传入一个并行度数字，这样的话，原先那个task分配到的数据，肯定会变少。就至少可以避免OOM的情况，程序至少是可以跑的。
   

- 提升shuffle reduce并行度的缺陷


治标不治本的意思，因为，它没有从根本上改变数据倾斜的本质和问题。不像第一个和第二个方案（直接避免了数据倾斜的发生）。

  原理没有改变，只是说，尽可能地去缓解和减轻shuffle reduce task的数据压力，以及数据倾斜的问题。

实际生产环境中的经验。

1. 如果最理想的情况下，提升并行度以后，减轻了数据倾斜的问题，或者甚至可以让数据倾斜的现象忽略不计，那么就最好。就不用做其他的数据倾斜解决方案了。

2. 不太理想的情况下，就是比如之前某个task运行特别慢，要5个小时，现在稍微快了一点，变成了4个小时；
或者是原先运行到某个task，直接OOM，现在至少不会OOM了，但是那个task运行特别慢，要5个小时才能跑完。

那么，如果出现第二种情况的话，各位，就立即放弃第三种方案，开始去尝试和选择后面的四种方案。



### 数据倾斜解决方案之使用随机key实现双重聚合

  1、原理

  2、使用场景
  （1）groupByKey
  （2）reduceByKey


比较适合使用这种方式；join，咱们通常不会这样来做，后面会讲三种，针对不同的join造成的数据倾斜的问题的解决方案。


  第一轮聚合的时候，对key进行打散，将原先一样的key，变成不一样的key，相当于是将每个key分为多组；

  先针对多个组，进行key的局部聚合；接着，再去除掉每个key的前缀，然后对所有的key，进行全局的聚合。

  对groupByKey、reduceByKey造成的数据倾斜，有比较好的效果。

如果说，之前的第一、第二、第三种方案，都没法解决数据倾斜的问题，那么就只能依靠这一种方式了。




### 数据倾斜解决方案之将reduce join转换为map join


普通的join，那么肯定是要走shuffle；那么，所以既然是走shuffle，那么普通的join，就肯定是走的是reduce join。

  先将所有相同的key，对应的values，汇聚到一个task中，然后再进行join。



reduce join转换为map join，适合在什么样的情况下，可以来使用？

  如果两个RDD要进行join，其中一个RDD是比较小的。
  一个RDD是100万数据，一个RDD是1万数据。（一个RDD是1亿数据，一个RDD是100万数据）

  其中一个RDD必须是比较小的，broadcast出去那个小RDD的数据以后，就会在每个executor的
  block manager中都驻留一份。要确保你的内存足够存放那个小RDD中的数据

这种方式下，根本不会发生shuffle操作，肯定也不会发生数据倾斜；从根本上杜绝了join操作可能导致的数据倾斜的问题；

- 对于join中有数据倾斜的情况，大家尽量第一时间先考虑这种方式，效果非常好；如果某个RDD比较小的情况下。


不适合的情况：

  两个RDD都比较大，那么这个时候，你去将其中一个RDD做成broadcast，就很笨拙了。很可能导致内存不足。最终导致内存溢出，程序挂掉。

而且其中某些key（或者是某个key），还发生了数据倾斜；此时可以采用最后两种方式。



对于join这种操作，不光是考虑数据倾斜的问题；即使是没有数据倾斜问题，也完全可以优先考虑，用我们讲的这种高级的reduce join转map join的技术，不要用普通的join，去通过shuffle，进行数据的join；

完全可以通过简单的map，使用map join的方式，牺牲一点内存资源；

在可行的情况下，优先这么使用。

不走shuffle，直接走map，是不是性能也会高很多？这是肯定的。








### 数据倾斜解决方案之sample采样倾斜key单独进行join




- 这个方案的实现思路：

其实关键之处在于，将发生数据倾斜的key，单独拉出来，放到一个RDD中去；


就用这个原本会倾斜的keyRDD跟其他RDD，单独去join一下，这个时候，key对应的数据，可能就会分散到多个task中去进行join操作。

就不至于说是，这个key跟之前其他的key混合在一个RDD中时，肯定是会导致一个key对应的所有数据，都到一个task中去，就会导致数据倾斜。





- 这种方案什么时候适合使用？

优先对于join，肯定是希望能够采用上一讲讲的，reducejoin转换mapjoin。

两个RDD数据都比较大，那么就不要那么搞了。

针对你的RDD的数据，你可以自己把它转换成一个中间表，或者是直接用countByKey()的方式，你可以看一下这个RDD各个key对应的数据量；此时如果你发现整个RDD就一个，或者少数几个key，是对应的数据量特别多；尽量建议，比如就是一个key对应的数据量特别多。

此时可以采用咱们的这种方案，单拉出来那个最多的key；单独进行join，尽可能地将key分散到各个task上去进行join操作。

- 什么时候不适用呢？

如果一个RDD中，导致数据倾斜的key，特别多；那么此时，最好还是不要这样了；还是使用我们最后一个方案，终极的join数据倾斜的解决方案。





就是说，咱们单拉出来了，一个或者少数几个可能会产生数据倾斜的key，然后还可以进行更加优化的一个操作；

对于那个key，从另外一个要join的表中，也过滤出来一份数据，比如可能就只有一条数据。userid2infoRDD，一个userid key，就对应一条数据。

然后呢，采取对那个只有一条数据的RDD，进行flatMap操作，打上100个随机数，作为前缀，返回100条数据。

单独拉出来的可能产生数据倾斜的RDD，给每一条数据，都打上一个100以内的随机数，作为前缀。

再去进行join，是不是性能就更好了。肯定可以将数据进行打散，去进行join。join完以后，可以执行map操作，去将之前打上的随机数，给去掉，然后再和另外一个普通RDD join以后的结果，进行union操作。







### 数据倾斜解决方案之使用随机数以及扩容表进行join


当采用随机数和扩容表进行join解决数据倾斜的时候，就代表着，你的之前的数据倾斜的解决方案，都没法使用。

这个方案是没办法彻底解决数据倾斜的，更多的，是一种对数据倾斜的缓解。



步骤：

  1、选择一个RDD，要用flatMap，进行扩容，将每条数据，映射为多条数据，
  每个映射出来的数据，都带了一个n以内的随机数，通常来说，会选择10。

  2、将另外一个RDD，做普通的map映射操作，每条数据，都打上一个10以内的随机数。

  3、最后，将两个处理后的RDD，进行join操作。



局限性：

  1、因为你的两个RDD都很大，所以你没有办法去将某一个RDD扩的特别大，一般咱们就是10倍。

  2、如果就是10倍的话，那么数据倾斜问题，的确是只能说是缓解和减轻，不能说彻底解决。


- sample采样倾斜key并单独进行join

将key，从另外一个RDD中过滤出的数据，可能只有一条，或者几条，此时，可以任意进行扩容，扩成1000倍。

将从第一个RDD中拆分出来的那个倾斜key RDD，打上1000以内的一个随机数。

这种情况下，还可以配合上，提升shuffle reduce并行度，join(rdd, 1000)。通常情况下，效果还是非常不错的。

打散成100份，甚至1000份，2000份，去进行join，那么就肯定没有数据倾斜的问题了吧。




---

### 页面单跳转化率-模块介绍

用户行为分析大数据平台

页面单跳转化率，非常经典的功能；而且也非常有用


### 需求分析、技术方案设计、数据表设计


  参数：
  1、日期范围
  2、多个页面的id

  java执行spark-submit
  脚本，执行spark程序


  大数据开发人员（RD）
  编写spark代码


基本的需求：

1. 接收J2EE系统传入进来的taskid，从mysql查询任务的参数，日期范围、页面流id
2. 针对指定范围日期内的用户访问行为数据，去判断和计算，页面流id中，每两个页面组成的页面切片，它的访问量是多少
3. 根据指定页面流中各个页面切片的访问量，计算出来各个页面切片的转化率
4. 计算出来的转化率，写入mysql数据库中


  用户指定的页面流id：
  3,5,7,9,10,21

  页面3->页面5的转化率是多少；
  页面5->页面7的转化率是多少；
  页面7->页面9的转化率是多少；
  页面3->页面5的访问量是多少；
  页面5到页面7的访问量是多少；
  两两相除，就可以计算出来


  1、获取任务的日期范围参数
  2、查询指定日期范围内的用户访问行为数据
  3、获取用户访问行为中，每个session，计算出各个在指定页面流中的页面切片的访问量；
  实现，页面单跳切片生成以及页面流匹配的算法；session，3->8->7，3->5->7，是不匹配的；
  4、计算出符合页面流的各个切片的pv（访问量）
  5、针对用户指定的页面流，去计算各个页面单跳切片的转化率
  6、将计算结果持久化到数据库中


  数据表，其实是比较简单的

  taskid：唯一标识一个任务
  convert_rate：页面流中，各个页面切片的转化率，以特定的格式拼接起来，作为这个字段的值


  1、业务：页面单跳转化率业务，实现思路

  2、页面单跳切片生成以及页面流匹配的算法


### 编写基础代码




  基础数据是什么？
  还是用户访问session分析模块基于的基础数据；用户购买支付统计模块；

  基础数据是通用的；
  它里面就包含了咱们网站 / app，每天所有用户在网站中，每一步的访问行为；origin_log


  实际生产环境中，其实一般不会这样；
  通常来说，都会为某个，或者某几个业务模块，通过hive etl，开发出一个源表。


### 页面单跳转化率



- PageOneStepConvertRateSpark.java

  页面单跳转化率模块spark作业



1. 查询指定日期范围内的用户访问行为数据:getActionRDDByDateRange()
2. 对用户访问行为数据做一个映射，将其映射为<sessionid,访问行为>的格式:getSessionid2actionRDD()
3. 对<sessionid,访问行为> RDD，做一次groupByKey操作:groupByKey()
4. 最核心的一步，每个session的单跳页面切片的生成，以及页面流的匹配算法:generateAndMatchPageSplit()、countByKey()
5. 计算目标页面流的各个页面切片的转化率:computePageSplitConvertRate()
6. 持久化页面切片转化率:persistConvertRate()


---


### 各区域热门商品统计-模块介绍


- 需求：根据用户指定的日期范围，统计各个区域下的最热门的top3商品

1. 区域信息在哪里，各个城市的信息，城市是不怎么变化的，没有必要存储在hive里？MySQL，Hive和MySQL异构数据源使用，技术点
2. hive用户行为数据，和mysql城市信息，join，关联之后是RDD？RDD转换DataFrame，注册临时表，技术点
3. 各个区域下各个商品的点击量，保留每个区域的城市列表数据？自定义UDAF函数，group_concat_distinct()
4. product_id，join hive表中的商品信息，商品信息在哪里？Hive。商品的经营类型是什么？自定义UDF函数，get_json_object()，if()
5. 获取每个区域的点击量top3商品？开窗函数；给每个区域打上级别的标识，西北大区，经济落后，区域上的划分，C类区域；北京、上海，发达，标记A类
6. Spark SQL的数据倾斜解决方案？双重group by、随机key以及扩容表（自定义UDF函数，random_key()）、内置reduce join转换为map join、shuffle并行度





### 需求分析、技术方案设计以及数据设计


- 需求：根据用户指定的日期范围，统计各个区域下的最热门的top3商品


Spark作业接收taskid，查询对应的MySQL中的task，获取用户指定的筛选参数；

统计出指定日期范围内的，各个区域的top3热门商品；最后将结果写入MySQL表中。


- 技术方案设计：

1. 查询task，获取日期范围，通过Spark SQL，查询user_visit_action表中的指定日期范围内的数据，过滤出，商品点击行为，click_product_id is not null；click_product_id != 'NULL'；click_product_id != 'null'；city_id，click_product_id
2. 使用Spark SQL从MySQL中查询出来城市信息（city_id、city_name、area），用户访问行为数据要跟城市信息进行join，city_id、city_name、area、product_id，RDD，转换成DataFrame，注册成一个临时表
3. Spark SQL内置函数（case when），对area打标记（华东大区，A级，华中大区，B级，东北大区，C级，西北大区，D级），area_level
4. 计算出来每个区域下每个商品的点击次数，group by area, product_id；保留每个区域的城市名称列表；自定义UDAF，group_concat_distinct()函数，聚合出来一个city_names字段，area、product_id、city_names、click_count
5. join商品明细表，hive（product_id、product_name、extend_info），extend_info是json类型，自定义UDF，get_json_object()函数，取出其中的product_status字段，if()函数（Spark SQL内置函数），判断，0 自营，1 第三方；（area、product_id、city_names、click_count、product_name、product_status）
6. 开窗函数，根据area来聚合，获取每个area下，click_count排名前3的product信息；area、area_level、product_id、city_names、click_count、product_name、product_status
7. 结果写入MySQL表中
8. Spark SQL的数据倾斜解决方案？双重group by、随机key以及扩容表（自定义UDF函数，random_key()）、Spark SQL内置的reduce join转换为map join、提高shuffle并行度
9. 本地测试和生产环境的测试





- 基础数据的准备和设计

  1、MySQL表中，要有city_info，city_id、city_name、area
  2、Hive表中，要有一个product_info表，product_id、product_name、extend_info
  3、MySQL中，设计结果表，task_id、area、area_level、product_id、city_names、click_count、product_name、product_status



### 各区域热门商品统计


- AreaTop3ProductSpark.java


1. 注册自定义函数
2. 获取命令行传入的taskid，查询对应的任务参数:getTaskDAO()
3. 查询用户指定日期范围内的点击行为数据（city_id，在哪个城市发生的点击行为）:
  技术点1：Hive数据源的使用
  getcityid2ClickActionRDDByDate()
4. 从MySQL中查询城市信息
  技术点2：异构数据源之MySQL的使用
  getcityid2CityInfoRDD()
5. 生成点击商品基础信息临时表
  技术点3：将RDD转换为DataFrame，并注册临时表
  generateTempClickProductBasicTable()
6. 生成各区域各商品点击次数的临时表:generateTempAreaPrdocutClickCountTable()
7. 生成包含完整商品信息的各区域各商品点击次数的临时表:generateTempAreaFullProductClickCountTable()
8. 使用开窗函数获取各个区域内点击次数排名前3的热门商品:getAreaTop3ProductRDD()




---

### 广告点击流量实时统计-需求分析、技术方案设计以及数据设计



1. 用户访问session分析模块：会话（session），用户的基础访问行为
2. 页面单跳转化率模块：页面（page），用户的页面访问和页面跳转行为
3. 各区域热门商品统计模块：商品（product），用户的商品点击行为
4. 广告点击流量实时统计模块：广告（ad，advertisement），用户的广告点击行为


### 广告点击流量实时统计


- ad.sql

- AdClickRealTimeStatSpark.java




1. 构建Spark Streaming上下文
2. 构建kafka参数map:kafkaParams
3. 构建topic set:topics
4. 构建出针对kafka集群中指定topic的输入DStream:createDirectStream()
5. 根据动态黑名单进行数据过滤:filterByBlacklist()
6. 生成动态黑名单:generateDynamicBlacklist()
7. 业务功能一：计算广告点击流量实时统计结果（yyyyMMdd_province_city_adid,clickCount）
    calculateRealTimeStat()
8. 业务功能二：实时统计每天每个省份top3热门广告:calculateProvinceTop3Ad()
9. 业务功能三：实时统计每天每个广告在最近1小时的滑动窗口内的点击趋势（每分钟的点击量）
    calculateAdClickCountByWindow()


### 实现实时计算程序的HA高可用性


通过一整套方案（3个步骤），开启和实现实时计算程序的HA高可用性，保证一些关键数据都有其冗余副本，不至于因为节点挂掉或者其他原因导致数据丢失。


1. updateStateByKey、window等有状态的操作，自动进行checkpoint，必须设置checkpoint目录
checkpoint目录：容错的文件系统的目录，比如说，常用的是HDFS

  SparkStreaming.checkpoint("hdfs://192.168.1.105:9090/checkpoint")

2. Driver高可用性

driver在启动的时候，不会重新创建一个streaming context，而是从容错文件系统（比如hdfs）中读取之前的元数据信息，包括job的执行进度，继续接着之前的进度，继续执行。


使用这种机制，就必须使用cluster模式提交，确保driver运行在某个worker上面


3. 实现RDD高可用性：启动WAL预写日志机制

  spark streaming，从原理上来说，是通过receiver来进行数据接收的；
  接收到的数据，会被划分成一个一个的block；block会被组合成一个batch；
  针对一个batch，会创建一个rdd；启动一个job来执行我们定义的算子操作。

  receiver主要接收到数据，那么就会立即将数据写入一份到容错文件系统（比如hdfs）上的checkpoint目录中的，一份磁盘文件中去；作为数据的冗余副本。



### 对实时计算程序进行性能调优


1. 并行化数据接收：处理多个topic的数据时比较有效
2. spark.streaming.blockInterval：增加block数量，增加每个batch rdd的partition数量，增加处理并行度
3. inputStream.repartition(<number of partitions>)：重分区，增加每个batch rdd的partition数量
4. 调节并行度
5. 使用Kryo序列化机制：
6. batch interval：每个的处理时间必须小于batch interval




## Spark 2.0-新特性介绍

### 新特性介绍

1. 统一Dataframe和Dataset API
2. SparkSession是新的Spark上下文以及入口，用于合并SQLContext和HiveContext，并替代它们
3. 新版本Accumulator API
4. SparkR中的分布式机器学习算法以及UDF函数
5. 让Spark作为编译器来运行
6. Spark Streaming应该说是将离线计算操作和流式计算操作统一起来的大数据计算框架之一
7. Whole-stage code generation动态生成代码
8. Vectorization

  向量化的意思就是避免每次仅仅处理一条数据，相反，将多条数据通过面向列的方式来组织成一个一个的batch，然后对一个batch中的数据来迭代处理。每次next()函数调用都返回一个batch的数据，这样可以减少virtual function dispatch的开销。



### Spark 2.x各组件分析

1. Spark Core（RDD）

RDD，简单来说，就是一个不可变的分布式数据集，被分为多个partition从而在一个集群上分布式地存储。我们可以使用RDD提供的各种transformation和action算子，对RDD执行分布式的计算操作。


2. Spark SQL（ANSI-SQL+Subquery）

Spark 2.x中的Spark SQL，提供了标准化SQL的支持，以及子查询的支持，大幅度提升了Spark在SQL领域的应用场景。


3. Spark SQL（Dataframe/Dataset）

Dataframe也代表一个不可变的分布式数据集。与RDD不同的一点是，Dataframe引入了schema的概念，支持以复杂的类型作为元素类型，同时指定schema，比如Row。因此Dataframe更像是传统关系型数据库中的表的概念。

但是在Spark 2.0中，Dataframe和Dataset合并了，Dataframe已经不是一个单独的概念了，目前仅仅只是Dataset[Row]的一个类型别名而已，你可以理解为Dataframe就是Dataset。


4. Spark Streaming&Structured Streaming

Spark Streaming是老牌的Spark流式计算引擎，底层基于RDD计算引擎。

Spark 2.x中也推出了全新的基于Dataframe/Dataset的Structured Streaming流式计算引擎。相较于Spark Streaming来说，其最大的不同之处在于，采用了全新的逻辑模型，提出了real-time incremental table的概念，更加统一了流式计算和离线计算的概念，减轻了用户开发的负担。同时还提供了（可能在未来提供）高度封装的特性。


5. Spark MLlib&GraphX


Spark MLlib未来将主要基于Dataframe/Dataset API来开发。


Spark GraphX，目前发展较为缓慢，如果有图计算相关的应用，可以考虑使用。














































































































