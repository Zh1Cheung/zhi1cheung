---
title: Spark章节一览
categories:
- Spark
- Big Data
tags:
- Spark



---


## Spark是什么

Spark，是一种通用的大数据计算框架，正如传统大数据技术Hadoop的MapReduce、Hive引擎，以及Storm流式实时计算引擎等。

Spark包含了大数据领域常见的各种计算框架：比如Spark Core用于离线计算，Spark SQL用于交互式查询，Spark Streaming用于实时流式计算，Spark MLlib用于机器学习，Spark GraphX用于图计算。

Spark主要用于大数据的计算，而Hadoop以后主要用于大数据的存储（比如HDFS、Hive、HBase等），以及资源调度（Yarn）。


 Spark除了一站式的特点之外，另外一个最重要的特点，就是基于内存进行计算，从而让它的速度可以达到MapReduce、Hive的数倍甚至数十倍。



大数据体系概览（Spark的地位）


![](https://s1.51cto.com/images/blog/201902/26/80fa6769232f362b079bbd067d34b075.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)


Spark vs MapReduce的计算模型（内存）

![](https://s1.51cto.com/images/blog/201902/26/9a03f1aabbc8a27253f16781864aaaf4.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)

Spark Streaming和Storm的计算模型对比

![](https://s1.51cto.com/images/blog/201902/26/3788bba2da52abff9ef2d76e94474bd0.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)


Spark SQL和Hive的关系

![](https://s1.51cto.com/images/blog/201902/26/5bb34437ac960c2d1a28f214d49aa41d.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)






## Spark内容介绍

### Scala编程详解
### Spark核心编程

	·RDD介绍
	·Spark基本工作原理
	·Spark开发入门
	    ·编写WordCount程序
	    ·使用本地模式进行测试
	    ·使用spark-submit提交到集群运行（spark-submit常用参数说明）
	    ·Spark程序开发流程总结
	    ·spark-shell的使用（编写wordcount程序）
	·创建RDD：并行化集合、基于文件创建RDD
	·操作RDD：transformation和action，java 8和旧版本的区别，操作key-value对
	·RDD常用操作全程案例实战
	·RDD持久化：cache()和persist()，几种持久化策略
	·共享变量：broadcast variable、accumulator
	·RDD高级编程：基于排序算法的WordCount、二次排序、topn、combineByKey



### 结合源码深度剖析Spark内核

	Spark内核概览
	    ·Spark核心概念
	    ·Spark工作流程
	    ·Spark运行模式
	·SparkContext原理剖析与源码分析
	·job触发流程原理剖析与源码分析
	·Master原理剖析（资源调度算法）
	    ·高可用机制原理剖析
	    ·注册机制原理剖析
	    ·executor失败容错机制原理剖析
	    ·资源调度算法剖析
	·Worker原理剖析
	DAGScheduler原理剖析
	    ·stage划分算法
	·TaskScheduler原理剖析
	    ·task分配算法
	·Executor原理剖析
	·ShuffleMapTask和ResultTask原理剖析
	·Shuffle原理剖析
	·Storage模块原理剖析
	    ·BlockManager原理剖析
	    ·Cache原理剖析
	    ·Checkpoint原理剖析



### Spark性能优化

	使用Kryo进行序列化
	·优化数据结构
	·对多次执行action operation的RDD进行持久化
	·对RDD持久化进行序列化
	·垃圾回收调优
	·提高并行度
	·广播大数据集
	·数据本地化
	·reduceByKey和groupByKey
	·shuffle性能调优




### Spark SQL

	DataFrame的使用
	·将RDD转化为DataFrame
	·支持的数据源（parquet、json、hive、jdbc）
	·工作原理
	·性能调优







### Spark Streaming


	基本工作原理
	·WordCount与开发流程
	·输入DStream（hdfs、socket、kafka）
	·DStream的transformation操作（updateStateByKey、transform、slide window）
	·DStream的output操作（性能优化与最佳实践）
	·Spark Streaming与Spark SQL整合
	·Cache、Checkpoint、Ahead Write Log
	·容错机制 
	·源码剖析
	·性能调优

































