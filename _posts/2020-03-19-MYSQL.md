---
title: MYSQL（2）
categories:
- MYSQL
tags:
- MYSQL
---


## 字符串字段加索引

- 前缀索引

  - 使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。

    - 我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少

    - > 首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：
      >
      > mysql> select count(distinct email) as L from SUser;
      >
      > 
      >
      > 依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：
      > 1 mysql> select 
      > 2 count(distinct left(email,4)）as L4,
      > 3 count(distinct left(email,5)）as L5,
      > 4 count(distinct left(email,6)）as L6,
      > 5 count(distinct left(email,7)）as L7,
      > 6 from SUser;

  - 使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。

- 遇到前缀的区分度不够好的情况时，我们要怎么办呢？

  - 第一种方式是使用倒序存储。如果你存储身份证号的时候把它倒过来存
  - 第二种方式是使用 hash 字段。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。

  



## MySQL会“抖”一下

- MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。
  - 什么情况会引发数据库的 flush 过程呢？
    - redo log满了
    - 系统内存不足
      - InnoDB 用缓冲池（buffer pool）管理内存，InnoDB 需要有控制脏页比例的机制，来尽量避免这种情况。
    - MySQL 认为系统“空闲”的时候
    -  MySQL 正常关闭的情况
- InnoDB 刷脏页的控制策略
  -  innodb_io_capacity 
    - 告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试
  - InnoDB 的刷盘速度就是要参考两个因素：一个是脏页比例，一个是 redo log 写盘速度。
    - 平时要多关注脏页比例，不要让它经常接近 75%。





## 为什么表数据删掉一半，表文件大小不变

- 一个 InnoDB 表包含两部分，即：表结构定义和数据。

- innodb_file_per_table参数 

  - 表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数innodb_file_per_table 控制的
    - 这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
    - 这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。
      从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。
  - 一个表单独存储为一个文件更容易管理，在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。

- 数据删除流程

  - 如果我们用 delete 命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。
    - delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。
  - 更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。经过大量增删改的表，都是可能是存在空洞的。
    - 所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。重建表，就可以达到这样的目的

-  Online DDL

  - 在重建表中使用

  - > 1. 建立一个临时文件，扫描表 A 主键的所有数据页；
    > 2. 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；
    > 3. 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；
    > 4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；
    > 5. 用临时文件替换表 A 的数据文件。

  - 由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。

  - alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。为什么要退化呢？为了实现 Online，MDL 读锁不会阻塞增删改操作。

    - 对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。







## count(*)

- 为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？

  - 由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的
    - 这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制
    - 每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。
  - 在执行 count(*) 操作的时候还是做了优化的。
    - InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。
    - 对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。

- 不同的 count 用法

  - count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。
    - 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。
    - 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。
  - 对于 count(字段) 来说
    - 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；
    - 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。
  - 按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(\*)，所以我建议你，尽量使用 count(*)。

- 从并发系统性能的角度考虑，在一个事务中应该先插入操作记录，再更新计数表。

  - 因为更新计数表涉及到行锁的竞争，先插入再更新能最大程度地减少了事务之间的锁等待，提升了并发度。

  





## order by

- 全字段排序

  - select city,name,age from t where city='杭州' order by name limit 1000 ;

  - > 1. 初始化 sort_buffer，确定放入 name、city、age 这三个字段；
    > 2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id；
    > 3. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；
    > 4. 从索引 city 取下一个记录的主键 id；
    > 5. 重复步骤 3、4 直到 city 的值不满足查询条件为止，；
    > 6. 对 sort_buffer 中的数据按照字段 name 做快速排序；
    > 7. 按照排序结果取前 1000 行返回给客户端。

  - 按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。

  - sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。

- rowid 排序

  - SET max_length_for_sort_data=16;

    - max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。

  - 新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。

    - > 1. 初始化 sort_buffer，确定放入两个字段，即 name 和 id；
      > 2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id；
      > 3. 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；
      > 4. 从索引 city 取下一个记录的主键 id；
      > 5. 重复步骤 3、4 直到不满足 city='杭州’条件为止；
      > 6. 对 sort_buffer 中的数据按照字段 name 进行排序；
      > 7. 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。

  - rowid 排序多访问了一次表 t 的主键索引，就是步骤 7。

- 全字段排序 VS rowid 排序

  - 体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。

  - 对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择

  - MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。

    - > 我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：
      > 	alter table t add index city_user(city, name);
      >
      > 
      >
      > 1. 从索引 (city,name) 找到第一个满足 city='杭州’条件的主键 id；
      > 2. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；
      > 3. 从索引 (city,name) 取下一个记录主键 id；
      > 4. 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。

  - 这个语句的执行流程有没有可能进一步简化呢

    - > 按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程
      >
      > 针对这个查询，我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是：
      > 	alter table t add index city_user_age(city, name, age)
      >
      > 
      >
      > 1. 从索引 (city,name,age) 找到第一个满足 city='杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；
      > 2. 从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；
      > 3. 重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束

- mysql> select * from t where city in ('杭州'," 苏州 ") order by name limit 100;这个语句执行的时候会有排序过程吗，为什么？

  - 虽然有 (city,name) 联合索引，对于单个 city 内部，name 是递增的
  - 由于这条 SQL语句不是要单独地查一个 city 的值，而是同时查了"杭州"和" 苏州 "两个城市，因此所有满足条件的 name 就不是递增的了。也就是说，这条 SQL 语句需要排序。
  - 要用到 (city,name) 联合索引的特性，把这一条语句拆成两条语句







## SQL语句逻辑相同，性能却差异巨大

- 条件字段函数操作

  - > mysql> select count(*) from tradelog where month(t_modified)=7;
    >
    > 如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定。
    >
    > key="t_modified"表示的是，使用了 t_modified 这个索引
    > rows=100335，说明这条语句扫描了整个索引的所有值；
    > Extra 字段的 Using index，表示的是使用了覆盖索引
    > 也就是说，由于在 t_modified 字段加了 month() 函数操作，导致了全索引扫描
    >
    > 
    >
    > 如果你的 SQL 语句条件用的是 where t_modified='2018-7-1’的话，引擎就会快速定位到 t_modified='2018-7-1’需要的结果。
    > 	实际上，B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性。
    > 	也就是说，对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。
    >
    > 
    >
    > 对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1 操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 -1 才可以。

- 隐式类型转换

  - > mysql> select * from tradelog where tradeid=110717;
    > tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换。
    >
    > 
    >
    > 在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。

- 隐式字符编码转换

  - 两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引。这个回答，也是通常你搜索这个问题时会得到的答案。
  - 为什么字符集不同就用不上索引呢？
    - 字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。
      - CONVERT() 函数，在这里的意思是把输入的字符串转成 utf8mb4 字符集。
      - 这就再次触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。
  - 字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。







## 只查一行的语句，也执行这么慢

- 第一类：查询长时间不返回

  - 等 MDL 锁

    - MySQL 5.7版本修改了 MDL 的加锁策略，所以就不能复现这个场景了。

    - >  mysql> select * from t where id=1;
      > 	一般碰到这种情况的话，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。

    - 通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的process id，把这个连接用 kill 命令断开即可。

  - 等 flush

    - > MySQL 里面对表做 flush操作的用法，一般有以下两个：
      > 	flush tables t with read lock;
      > flush tables with read lock;
      > 	这两个 flush 语句，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。

  - 等行锁

    - > mysql> select * from t where id=1 lock in share mode;
      > 由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。

    - 如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。

    - > mysql> select * from t sys.innodb_lock_waits where locked_table=`'test'.'t'`\G

    - 4 号线程是造成堵塞的罪魁祸首

      - 不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。
      - 实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。

- 第二类：查询慢

  - 字段上没有索引

    - 这里为了把所有语句记录到 slow log 里，我在连接后先执行了 set long_query_time=0，将慢查询日志的时间阈值设置为 0。

  - >  mysql> select * from t where id=1；
    >
    > 虽然扫描行数是 1，但执行时间却长达 800 毫秒。
    >
    > 
    >
    > select * from t where id=1 lock in share mode，执行时扫描行数也是 1 行，执行时间是 0.2 毫秒。
    > 第一个语句的查询结果里 c=1，带 lock in share mode 的语句返回的是 c=1000001

    - session A 先用 start transaction with consistent snapshot 命令启动了一个事务，之后 session B 才开始执行 update 语句。
      - session B 更新完 100 万次，生成了 100 万个回滚日志 (undo log)
      - 带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；
      - 而 select * from t where id=1 这个语句，是一致性读，因此需要从1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回
      - undo log 里记录的其实是“把 2 改成 1”，“把 3 改成 2”这样的操作逻辑

- 这个语句序列是怎么加锁的呢？加的锁又是什么时候释放呢？
  - > 1 begin;
    > 2 select * from t where c=5 for update;
    > 3 commit;

  - RR隔离级别下

    - 为保证binlog记录顺序，非索引更新会锁住全表记录，且事务结束前不会对不符合条件记录有逐步释放的过程。

  - RC隔离级别下

    - 对非索引字段更新，有个锁全表记录的过程，不符合条件的会及时释放行锁，不必等事务结束时释放；
    - 而直接用索引列更新，只会锁索引查找值和行。c=5 这一行的行锁，还是会等到 commit 的时候才释放的。

- 一般说全表扫描默认是指“扫瞄主键索引”

