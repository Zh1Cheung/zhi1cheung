---
title: 高并发架构思路
categories:
- 高并发
tags:
- 高并发

---



# 数据库高并发解决方法

- 概述
  - 关键是如何解决慢和等，核心一个是短，一个是少，一个是分流,最后一个是集群/横向扩张/读写分离/建立主从。
    - 短是指路径（请求）要短
      - 页面静态化
      - 缓存
      - 储存过程
      - 批量读取
      - 延迟修改
      - 索引
    - 少是指查询的数据要少
      - 分表
      - 分离活跃数据
      - 分块
    - 分流
      - 集群
        - 并发请求分配到不同的服务器上
      - 分布式
        - 把单次请求的多项业务逻辑分配到多个服务器上
      - CDN
        - 例如将华南地区的用户请求分配到华南的服务器，华中地区的用户请求分配到华中的服务器
- 解决数据库高并发访问瓶颈问题
  - 缓存式的Web应用程序架构
    - 在Web层和db层之间加一层cache层
  - 业务拆分
    - 每一个模块都使用单独的数据库来进行存储，不同的业务访问不同的数据库
  - MySQL主从复制，读写分离
    - 主从复制技术（master-slave模式）来达到读写分离，以提高读写性能和读库的可扩展性
    - 主从复制
      - 数据复制的实际就是Slave从Master获取Binary log文件，然后在本地镜像的执行日志中记录的操作
    - 读写分离
      - 只在主服务器上写，只在从服务器上读
      - 让主数据库处理事务性查询，而从数据库处理select查询
      - 数据库复制被用于把事务性查询（增删改）导致的改变更新同步到集群中的从数据库
    - 实现主从分离可以使用MySQL中间件如：Atlas
  - 分表分库
    - 采用Master-Slave复制模式的MySQL架构，只能对数据库的读进行扩展，而对数据的写操作还是集中在Master上
    - 分表
      - 对于访问极为频繁且数据量巨大的单表来说，首先要做的是减少单表的记录条数
    - 分表能够解决单表数据量过大带来的查询效率下降的问题，但是却无法给数据库的并发处理能力带来质的提升
      - 分表的实质还是在一个数据库上进行的操作，很容易受数据库IO性能的限制
    - 分库
      - 当数据库master服务器无法承载写操作压力时，不管如何扩展Slave服务器都是没有意义的
    - 数据库分表可以解决单表海量数据的查询性能问题，分库可以解决单台数据库的并发访问压力问题
    - 经过业务拆分及分库分表，虽然查询性能和并发处理能力提高了。但是原本跨表的事务上升为分布式事务
    - 分库分表后需要进一步对系统进行扩容（路由策略变更）将变得非常不方便，需要重新进行数据迁移
    - 分库分表的策略
      - １、中间变量　＝ user_id%（库数量*每个库的表数量）; 　　

　　２、库序号　＝　取整（中间变量／每个库的表数量）; 　　

　　３、表序号　＝　中间变量％每个库的表数量;





# 如何应对大流量、高并发思路

所谓高并发指的是：在同时或极短时间内，有大量的请求到达服务端，每个请求都需要服务端耗费资源进行处理，并做出相应的反馈。

**常用的高并发处理的思路与手段**

从服务端视角看高并发
服务端处理请求需要耗费服务端的资源，比如能同时开启的进程数、能同时运行的线程数、网络连接数、cpu、I/O、内存等等，由于服务端资源是有限的，那么服务端能同时处理的请求也是有限的。高并发问题的本质就是：资源的有限性

高并发带来的问题
服务端的处理和响应会越来越慢，甚至会丢弃部分请求不予处理，更严重的会导致服务端崩溃。



**高并发处理的基本思路**
1）从客户端看
尽量减少请求数量，比如：依靠客户端自身的缓存或处理能力

尽量减少对服务端资源的不必要耗费，比如：重复使用某些资源，如连接池客户端处理的基本原则就是：能不访问服务端就不要访问

2）从服务端看
增加资源供给，比如：更大的网络带宽，使用更高配置的服务器，使用高性能的Web服务器，使用高性能的数据库

请求分流，比如：使用集群,分布式的系统架构

应用优化，比如：使用更高效的编程语言,优化处理业务逻辑的算法,优化访问数据库的SQL

基本原则：分而治之，并提高单个请求的处理速度



**高并发处理的基本手段**
1）客户端发出请求层面，常见的手段有：
尽量利用浏览器的缓存功能，减少访问服务端，比如：js、css、图片等

可以考虑使用压缩传输的功能，减少网络流量，也会提高传输速度

考虑使用异步请求，分批获取数据

**2）前端接收客户端请求层面，常见的手段有：**
动静分离，部分静态资源可以直接从Nginx返回

按请求的不同，分发到不同的后端进行处理，比如：负载均衡、业务拆分访问等

前面再加上一层来做多个Nginx的负载均衡，比如：LVS、F5等

还可以在更前面使用CDN服务

还可以对动态内容进行缓存，尽量减少访问后端服务

**3）Web服务器层面，常见的手段有：**
使用最新的JVM，并进行配置优化

对Web服务器进行配置优化，比如：调整内存数量、线程数量等

提供多个能提供相同服务的Web服务器，以实现负载均衡

仔细规划Web服务器上部署的应用规模

对Web服务器进行集群

**4）Web应用层面，常见的手段有：**
动态内容静态化

Java开发优化

优化处理业务逻辑的算法

合理高效的利用缓存

优化访问数据库的Sql，可以考虑利用存储过程等数据库的能力

合理使用多线程，加快业务处理

部分业务可以考虑内存数据库，或者是进行纯内存处理

尽量避免远程调用、大量I/O等耗时的操作

合理规划事务等较为耗资源的操作

合理使用异步处理

对部分业务考虑采用预处理或者预计算的方式，减少实时计算量

内部系统间的业务尽量直接调用、直接处理，减少WebService、工作流等

**5）数据库层面，常见的手段有：**
合理选择数据库的引擎，比如Mysql的InnoDB与MyISAM引擎

进行配置优化

可以考虑使用存储过程来处理复杂的数据逻辑

数据库集群，进行读写分离

合理设计数据库的表结构、索引等

分库、分表，降低单库、单表的数据量

# 请求量突增（限流降级）

一般的业务服务系统大体上就是通过**网络远程对DB进行读写**。如果流量突然飙大，总有一个资源会遇到瓶颈。按照经验大概出问题地方是DB磁盘io、CPU、带宽、连接数、内存其中的一个或几个。不同的业务，不同的系统设计，出问题的地方会有所不同。如果流量增大数倍，势必某个资源会在瞬间被榨干，然后所有的服务都会“开小差”，引起用户的抱怨。而解决问题的关键，是在问题发生时，尽量减少出问题的资源被访问。

对于这个问题，我这里给出两个回答，一个是应付面试的，一个面向实际的。大家各取所需。

## 面试中怎么回答

面试官其实就想听到几个术语的解释而已——**缓存、服务降级、限流**。

**缓存**，就是用内存来顶替一部分DB的查询+数据的处理。这应该是所有业务开发人员的必修课。业务上大致可以把缓存分为三类：浏览器缓存（HTTP Cache-Control Header)，[CDN](https://cloud.tencent.com/product/cdn?from=10680)和服务器业务缓存。而业务缓存根据实现的结构可以分多个层级，可以用in-memory cache (如Guava Cache），或者是分布式共享Cache（如[Redis](https://cloud.tencent.com/product/crs?from=10680)）。在设计缓存一致性更新模式时，无非就是*Cache Aside*、*Read/Write Through*和*Write Behind*这三大种模式。有些超级NB的缓存系统自带Cluster加持（比如Ehcache即可单机用，也可以组集群）。限于本文主题，具体的缓存设计不赘述。

留意下这里说的缓存仅仅是利用了内存访问比磁盘访问快得多的特性（大概可以理解为2～3个数量级），并不会让用户感知到数据一致性哪里不对劲（与下面的降级不同）。

**服务降级**，是指通过降低服务质量的方法，达到节省资源的目的。简单来说就是**弃车保帅**。比如你的服务有ABC，平时消耗差不多的资源。突发事件时，A的请求量极大的增高了，B和C没有变化。那么可以比如减少或者暂停B和C的服务，省出资源给A用。

再比如，一个热点新闻的业务，有新闻内容，有评论，有点赞数等等。一旦新闻热点了，就可以把所有这些内容“静态化”，不必再查DB。这时虽然评论，点赞的数暂时就不准了，但是主要的服务——内容，还是让用户可以看到。这就足够了。

可以看到，降级的具体的方案，要结合业务和系统实现来综合设计，并没有定法。

降级很多时候也会用到缓存。只不过这时候使用缓存的方法就可能会以牺牲数据一致性为代价——内存里的数据和DB不一样，就不一样吧，业务上可接受，并且这段热点时间段过去了，能够恢复为一致就可以。

**限流**，即限制用户的请求流量。具体的做法有*计数器*、*滑动窗口*、*滴漏*、*服务token*、*请求队列化*等办法。这些方法的详细解释，在[这里](https://www.jianshu.com/p/d9504fc0af4d)都说得比较清楚，所以我就不重复了。只是值得注意的是，现在很多生产级别的服务都是多节点分布式架构。很多单机上容易做的算法和控制逻辑到了分布式下就会带来一些实现上的麻烦。这又涉及到了分布式一致性、CAP的权衡等等问题。

怎么样，这些足够你在10分钟内和面试官白话一番了吧。下面我们说说真的。

**总是预先准备**

当设计一个业务时，产品设计和研发团队应该找个时间，除了讨论产品本身怎么实现之外，还应该关心一下如下几点的实施：

**流量估算**。到底大概有多少人可能会用呢？对于大公司，都有长时间运营的经验，可以参照之前的产品/活动给出一个量化的估算结果。但是小公司往往就只能拍脑袋。但即便是拍脑袋也比没有强，可以作为设计容量的依据。这下你明白为啥有些公司面试时会出“你觉得本城市有多少个辆汽车”这样的题目了吧。

作为一个经验，可以把设计流量*3作为系统压力的下限——即，实现完了要压测，压测得到的结果要达到设计流量 * 3。当然如果是你的话，要 * 4， * 5都可以，关键是要给系统留些缓冲。一旦发生了什么，不至于挂的太惨。此时，一般会得到一个带缓存的业务服务系统。考虑到缓存高于后台服务2～3个数量级的性能优势，多撑几倍流量一般不成问题。

**降级方案**。降级总得是用户可以买账的方式才行，不能瞎降。能降级成什么样，显示成什么样子，都得预先设计好。UI上有的要配图，有的要出警告语提示。而作为后台服务器，需要有对应的实时开关，一旦设置，立刻进入降级方案。

但是，如果核心服务就是热点本身，就没得降级，那就尴尬了…… 比如下单就是下单，不能下一半，不能砍掉支付，不能随机性有的能买有的不能买。这时就得靠限流。

**限流方案**。上面提到了种种限流算法——*计数器*、*滑动窗口*、*滴漏*、*服务token*、*请求队列化*，等办法技术在更加传统的模版式页面的网站更容易做——整个界面是由一个GET请求在后台通过模版产生的。所以只要在这个请求处理过程中做限流控制即可。

但是在SPA或者移动端App时，一个界面可能是由数个或者数十个Ajax接口分批获得。每个请求都做限流可能会得到随机的半残的界面——有几个接口没限制，有几个被限制了。此时做限流还得考虑前后端架构设计。一般来讲，每个主要界面都应该有个主控接口来实现限流（比如产品详情接口）——即，一旦该接口说限流了，后续的前端代码就得配合按照预先的设计显示限流后的界面。同时会影响关键资源的接口在后端要再做一道限流——毕竟你不知道有没有人绕开前端直接压接口使坏不是。嗯，抢票就是这么来的。

**提前安排开发和演练排期**。如果一切安排妥当，就可以做作演习了。你可以找个没人用你服务的时间点（大半夜？）使用流量replay压一下你的真实生产环境，看看真的发生了流量增高的问题，系统是否足够健壮能够应对，之前设计的种种方案是不是可以达到设计的需要。根据**墨菲定律**，可能会发生的事情一定会发生，不经演练的系统上线到了出问题的时候100%会让你大开眼界。

**相关问题**

这里稍微说一下高流量问题带来的一些相关的问题。这里仅仅是简单列举，具体内容之后找时间细细说。

-  **雪崩效应**——如果用户看到“服务开小差”，他的第一反应一定是再刷一次；如果是微服务架构，服务与服务之间可能会有自动重试机制。而这些，会让已经半死的系统死的更透彻。对此类问题，一般使用**断路器**的方案，简单来说就是，如果一个服务已经证明快挂了，就别再调用了，直接fallback。等一会再试。nginx里的upstream控制有`max_fails`和`fail_timeout`处理这个问题。Hystrix也实现了该机制。但断路了不等于让用户看到404页面骂娘，一定要结合业务+产品设计来实现断路方案。
-  **无效的服务响应**——在高压下，可以简单将等待处理的服务看作是在排队，队首的请求被处理。但被最终“见”到处理逻辑的请求从队尾排到队首时可能已经过了比较长的时间，而客户端那边可能早就超时了。所以业务服务处理了也是白处理。这时如果队列系统做得好，比如要处理前先猜一次是不是处理完了会超时，如果是就忽略扔掉。可以减少这种问题的发生几率。这也算是一种服务降级。
-  **大量的TIME_WAIT**——如果业务服务器的压力造成服务端大量主动关闭连接，就会产生大量的TIME_WAIT状态的TCP链接。这些链接会在数分钟内像僵尸一样堆在那里，榨干所有的连接数。这种问题尤其以自研业务服务框架容易出现。
-  **一致性**——为了服务降级，可能会把用户请求放内存里缓一缓，再批量进DB。那么一旦系统出现故障，就意味着比如下单数据不一致，支付状态不一致等问题。有时，这些问题在业务上极大的影响用户的使用体验。当系统降级时，尽量保证，要不就告诉用户现在不能给你服务，要服务了结果就明确。对于交易这种业务，事前打脸还是比事后扯皮要好一些。两害取其轻。
-  **系统可能会临时stop the world**——对于java这样的系统，会因为GC而暂时卡那么一下；对于mongoDB，可能因为要底层flush数据到磁盘，也会卡那么一下；平时写的什么正则表达式处理一类的逻辑，在高峰期也可能会卡那么一下…… 平时一般没事，但是赶上高峰时，这些问题一旦出现就有可能成为压垮骆驼的最后一根稻草。因此平时还是多多压测和演习，心里踏实。



# 双十一抢购性能瓶颈调优

首先，由于没有限流，超过预期的请求量导致了系统卡顿；其次，基于 Redis 实现的分布式锁分发抢购名额的功能抛出了大量异常；再次，就是我们误判了横向扩容服务可以起到的作用，其实第一波抢购的性能瓶颈是在数据库，横向扩容服务反而又增加了数据库的压力，起到了反作用；最后，就是在服务挂掉的情况下，丢失了异步处理的业务请求。

## 抢购业务流程

在进行具体的性能问题讨论之前，我们不妨先来了解下一个常规的抢购业务流程，这样方便我们更好地理解一个抢购系统的性能瓶颈以及调优过程。

- 用户登录后会进入到商品详情页面，此时商品购买处于倒计时状态，购买按钮处于置灰状态。
- 当购买倒计时间结束后，用户点击购买商品，此时用户需要排队等待获取购买资格，如果没有获取到购买资格，抢购活动结束，反之，则进入提交页面。
- 用户完善订单信息，点击提交订单，此时校验库存，并创建订单，进入锁定库存状态，之后，用户支付订单款。
- 当用户支付成功后，第三方支付平台将产生支付回调，系统通过回调更新订单状态，并扣除数据库的实际库存，通知用户购买成功。

## 抢购系统中的性能瓶颈

熟悉了一个常规的抢购业务流程之后，我们再来看看抢购中都有哪些业务会出现性能瓶颈。

1. **商品详情页面**

如果你有过抢购商品的经验，相信你遇到过这样一种情况，在抢购马上到来的时候，商品详情页面几乎是无法打开的。

这是因为大部分用户在抢购开始之前，会一直疯狂刷新抢购商品页面，尤其是倒计时一分钟内，查看商品详情页面的请求量会猛增。此时如果商品详情页面没有做好，就很容易成为整个抢购系统中的第一个性能瓶颈。

类似这种问题，我们通常的做法是提前将整个抢购商品页面生成为一个静态页面，并 push 到 CDN 节点，并且在浏览器端缓存该页面的静态资源文件，通过 CDN 和浏览器本地缓存这两种缓存静态页面的方式来实现商品详情页面的优化。

2. **抢购倒计时**

在商品详情页面中，存在一个抢购倒计时，这个倒计时是服务端时间的，初始化时间需要从服务端获取，并且在用户点击购买时，还需要服务端判断抢购时间是否已经到了。

如果商品详情每次刷新都去后端请求最新的时间，这无疑将会把整个后端服务拖垮。我们可以改成初始化时间从客户端获取，每隔一段时间主动去服务端刷新同步一次倒计时，这个时间段是随机时间，避免集中请求服务端。这种方式可以避免用户主动刷新服务端的同步时间接口。

**3. 获取购买资格**

可能你会好奇，在抢购中我们已经通过库存数量限制用户了，那为什么会出现一个获取购买资格的环节呢？

我们知道，进入订单详情页面后，需要填写相关的订单信息，例如收货地址、联系方式等，在这样一个过程中，很多用户可能还会犹豫，甚至放弃购买。如果把这个环节设定为一定能购买成功，那我们就只能让同等库存的用户进来，一旦用户放弃购买，这些商品可能无法再次被其他用户抢购，会大大降低商品的抢购销量。

增加购买资格的环节，选择让超过库存的用户量进来提交订单页面，这样就可以保证有足够提交订单的用户量，确保抢购活动中商品的销量最大化。

获取购买资格这步的并发量会非常大，还是基于分布式的，通常我们可以通过 Redis 分布式锁来控制购买资格的发放。

**4. 提交订单**

由于抢购入口的请求量会非常大，可能会占用大量带宽，为了不影响提交订单的请求，我建议将提交订单的子域名与抢购子域名区分开，分别绑定不同网络的服务器。

用户点击提交订单，需要先校验库存，库存足够时，用户先扣除缓存中的库存，再生成订单。如果校验库存和扣除库存都是基于数据库实现的，那么每次都去操作数据库，瞬时的并发量就会非常大，对数据库来说会存在一定的压力，从而会产生性能瓶颈。与获取购买资格一样，我们同样可以通过分布式锁来优化扣除消耗库存的设计。

由于我们已经缓存了库存，所以在提交订单时，库存的查询和冻结并不会给数据库带来性能瓶颈。但在这之后，还有一个订单的幂等校验，为了提高系统性能，我们同样可以使用分布式锁来优化。

而保存订单信息一般都是基于数据库表来实现的，在单表单库的情况下，碰到大量请求，特别是在瞬时高并发的情况下，磁盘 I/O、数据库请求连接数以及带宽等资源都可能会出现性能瓶颈。此时我们可以考虑对订单表进行分库分表，通常我们可以基于 userid 字段来进行 hash 取模，实现分库分表，从而提高系统的并发能力。

**5. 支付回调业务操作**

在用户支付订单完成之后，一般会有第三方支付平台回调我们的接口，更新订单状态。

除此之外，还可能存在扣减数据库库存的需求。如果我们的库存是基于缓存来实现查询和扣减，那提交订单时的扣除库存就只是扣除缓存中的库存，为了减少数据库的并发量，我们会在用户付款之后，在支付回调的时候去选择扣除数据库中的库存。

此外，还有订单购买成功的短信通知服务，一些商城还提供了累计积分的服务。

在支付回调之后，我们可以通过异步提交的方式，实现订单更新之外的其它业务处理，例如库存扣减、积分累计以及短信通知等。通常我们可以基于 MQ 实现业务的异步提交。

## 性能瓶颈调优

了解了各个业务流程中可能存在的性能瓶颈，我们再来讨论下商城基于常规优化设计之后，还可能出现的一些性能问题，我们又该如何做进一步调优。

**1. 限流实现优化**

限流是我们常用的兜底策略，无论是倒计时请求接口，还是抢购入口，系统都应该对它们设置最大并发访问数量，防止超出预期的请求集中进入系统，导致系统异常。

通常我们是在网关层实现高并发请求接口的限流，如果我们使用了 Nginx 做反向代理的话，就可以在 Nginx 配置限流算法。Nginx 是基于漏桶算法实现的限流，这样做的好处是能够保证请求的实时处理速度。

Nginx 中包含了两个限流模块：[ngx_http_limit_conn_module](http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html) 和 [ngx_http_limit_req_module](http://nginx.org/en/docs/http/ngx_http_limit_req_module.html)，前者是用于限制单个 IP 单位时间内的请求数量，后者是用来限制单位时间内所有 IP 的请求数量。以下分别是两个限流的配置：

```
limit_conn_zone $binary_remote_addr zone=addr:10m;
 
server {
    location / {
        limit_conn addr 1;
    }
http {
    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;
    server {
        location / {
            limit_req zone=one burst=5 nodelay;
        }
} 
```

在网关层，我们还可以通过 lua 编写 OpenResty 来实现一套限流功能，也可以通过现成的 Kong 安装插件来实现。除了网关层的限流之外，我们还可以基于服务层实现接口的限流，通过 Zuul RateLimit 或 Guava RateLimiter 实现。

**2. 流量削峰**

瞬间有大量请求进入到系统后台服务之后，首先是要通过 Redis 分布式锁获取购买资格，这个时候我们看到了大量的“JedisConnectionException Could not get connection from pool”异常。

这个异常是一个 Redis 连接异常，由于我们当时的 Redis 集群是基于哨兵模式部署的，哨兵模式部署的 Redis 也是一种主从模式，我们在写 Redis 的时候都是基于主库来实现的，在高并发操作一个 Redis 实例就很容易出现性能瓶颈。

你可能会想到使用集群分片的方式来实现，但对于分布式锁来说，集群分片的实现只会增加性能消耗，这是因为我们需要基于 Redission 的红锁算法实现，需要对集群的每个实例进行加锁。

后来我们使用 Redission 插件替换 Jedis 插件，由于 Jedis 的读写 I/O 操作还是阻塞式的，方法调用都是基于同步实现，而 Redission 底层是基于 Netty 框架实现的，读写 I/O 是非阻塞 I/O 操作，且方法调用是基于异步实现。

但在瞬时并发非常大的情况下，依然会出现类似问题，此时，我们可以考虑在分布式锁前面新增一个等待队列，减缓抢购出现的集中式请求，相当于一个流量削峰。当请求的 key 值放入到队列中，请求线程进入阻塞状态，当线程从队列中获取到请求线程的 key 值时，就会唤醒请求线程获取购买资格。

**3. 数据丢失问题**

无论是服务宕机，还是异步发送给 MQ，都存在请求数据丢失的可能。例如，当第三方支付回调系统时，写入订单成功了，此时通过异步来扣减库存和累计积分，如果应用服务刚好挂掉了，MQ 还没有存储到该消息，那即使我们重启服务，这条请求数据也将无法还原。

重试机制是还原丢失消息的一种解决方案。在以上的回调案例中，我们可以在写入订单时，同时在数据库写入一条异步消息状态，之后再返回第三方支付操作成功结果。在异步业务处理请求成功之后，更新该数据库表中的异步消息状态。

假设我们重启服务，那么系统就会在重启时去数据库中查询是否有未更新的异步消息，如果有，则重新生成 MQ 业务处理消息，供各个业务方消费处理丢失的请求数据。

**总结**

减少抢购中操作数据库的次数，缩短抢购流程，是抢购系统设计和优化的核心点。

抢购系统的性能瓶颈主要是在数据库，即使我们对服务进行了横向扩容，当流量瞬间进来，数据库依然无法同时响应处理这么多的请求操作。我们可以对抢购业务表进行分库分表，通过提高数据库的处理能力，来提升系统的并发处理能力。

除此之外，我们还可以分散瞬时的高并发请求，流量削峰是最常用的方式，用一个队列，让请求排队等待，然后有序且有限地进入到后端服务，最终进行数据库操作。当我们的队列满了之后，可以将溢出的请求放弃，这就是限流了。通过限流和削峰，可以有效地保证系统不宕机，确保系统的稳定性。

# 高并发对服务器的需求有哪些？

1）从客户端看
尽量减少请求数量，比如：依靠客户端自身的缓存或处理能力。
尽量减少对服务端资源的不必要耗费，比如：重复使用某些资源，如连接池客户端处理的基本原则就是：能不访问服务端就不要访问。
2）从服务端看
增加资源供给，比如：更大的网络带宽，使用更高配置的服务器，使用高性能的Web服务器，使用高性能的数据库。
请求分流，比如：使用集群,分布式的系统架构。
应用优化，比如：使用更高效的编程语言,优化处理业务逻辑的算法,优化访问数据库的SQL。
基本原则：分而治之，并提高单个请求的处理速度。

怎么提高服务器的并发处理能力

1. **提高CPU并发计算能力**
   服务器之所以可以同时处理多个请求，在于操作系统通过多执行流体系设计使得多个任务可以轮流使用系统资源。

**这些资源包括CPU，内存以及I/O. 这里的I/O主要指磁盘I/O, 和网络I/O。**

**多进程 & 多线程**
多执行流的一般实现便是进程，多进程的好处可以对CPU时间的轮流使用，对CPU计算和IO操作重叠利用。这里的IO主要是指磁盘IO和网络IO，相对CPU而言，它们慢的可怜。

而实际上，大多数进程的时间主要消耗在I/O操作上。

现代计算机的DMA技术可以让CPU不参与I/O操作的全过程，比如进程通过系统调用，使得CPU向网卡或者磁盘等I/O设备发出指令，然后进程被挂起，释放出CPU资源，等待I/O设备完成工作后通过中断来通知进程重新就绪。

对于单任务而言，CPU大部分时间空闲，这时候多进程的作用尤为重要。CPU 是怎么认识代码的？推荐大家看下。

多进程不仅能够提高CPU的并发度。其优越性还体现在独立的内存地址空间和生命周期所带来的稳定性和健壮性，其中一个进程崩溃不会影响到另一个进程。

但是进程也有如下缺点：

fork()系统调用开销很大: prefork

进程间调度和上下文切换成本: 减少进程数量

庞大的内存重复：共享内存

IPC编程相对比较麻烦

**减少进程切换**
当硬件上下文频繁装入和移出时，所消耗的时间是非常可观的。可用Nmon工具监视服务器每秒的上下文切换次数。

为了尽量减少上下文切换次数，最简单的做法就是减少进程数，尽量使用线程并配合其它I/O模型来设计并发策略。

还可以考虑使用进程绑定CPU技术，增加CPU缓存的命中率。若进程不断在各CPU上切换，这样旧的CPU缓存就会失效。

**减少使用不必要的锁**
服务器处理大量并发请求时，多个请求处理任务时存在一些资源抢占竞争，这时一般采用“锁”机制来控制资源的占用。到底什么是重入锁，推荐大家看下。

当一个任务占用资源时，我们锁住资源，这时其它任务都在等待锁的释放，这个现象称为锁竞争。

通过锁竞争的本质，我们要意识到尽量减少并发请求对于共享资源的竞争。

比如在允许情况下关闭服务器访问日志，这可以大大减少在锁等待时的延迟时间。要最大程度减少无辜的等待时间。

这里说下无锁编程，就是由内核完成这个锁机制，主要是使用原子操作替代锁来实现对共享资源的访问保护。

使用原子操作时，在进行实际的写操作时，使用了lock指令，这样就可以阻止其他任务写这块内存，避免出现数据竞争现象。原子操作速度比锁快，一般要快一倍以上。

例如fwrite(), fopen()，其是使用append方式写文件，其原理就是使用了无锁编程，无锁编程的复杂度高，但是效率快，而且发生死锁概率低。

**考虑进程优先级**
进程调度器会动态调整运行队列中进程的优先级，通过top观察进程的PR值

**考虑系统负载**
可在任何时刻查看/proc/loadavg, top中的load average也可看出

**考虑CPU使用率**
除了用户空间和内核空间的CPU使用率以外，还要关注I/O wait,它是指CPU空闲并且等待I/O操作完成的时间比例（top中查看wa的值）。

2. **考虑减少内存分配和释放**
   服务器的工作过程中，需要大量的内存，使得内存的分配和释放工作尤为重要。

可以通过改善数据结构和算法复制度来适当减少中间临时变量的内存分配及数据复制时间，而服务器本身也使用了各自的策略来提高效率。

例如Apache,在运行开始时一次申请大片的内存作为内存池，若随后需要时就在内存池中直接获取，不需要再次分配，避免了频繁的内存分配和释放引起的内存整理时间。

再如Nginx使用多线程来处理请求，使得多个线程之间可以共享内存资源，从而令它的内存总体使用量大大减少。

另外，Nginx分阶段的内存分配策略，按需分配，及时释放，使得内存使用量保持在很小的数量范围。

另外，还可以考虑**共享内存**。

共享内存指在多处理器的计算机系统中，可以被不同中央处理器（CPU）访问的大容量内存，也可以由不同进程共享，是非常快的进程通信方式。

但是使用共享内存也有不好的地方，就是对于多机器时数据不好统一。

shell命令ipcs可用来显示系统下共享内存的状态，函数shmget可以创建或打开一块共享内存区，函数shmat将一个存在的共享内存段连接到本进程空间, 函数shmctl可以对共享内存段进行多种操作，函数shmdt函数分离该共享内存。

3. **考虑使用持久连接**
   持久连接也为长连接，它本身是TCP通信的一种普通方式，即在一次TCP连接中持续发送多分数据而不断开连接。

与它相反的方式称为短连接，也就是建立连接后发送一份数据就断开，然后再次建立连接发送下一份数据， 周而复始。

是否采用持久连接，完全取决于应用特点。

从性能角度看，建立TCP连接的操作本身是一项不小的开销，在允许的情况下，连接次数越少，越有利于性能的提升; 尤其对于密集型的图片或网页等小数据请求处理有明显的加速所用。

HTTP长连接需要浏览器和web服务器的共同协作，目前浏览器普遍支持长连接，表现在其发出的HTTP请求数据头中包含关于长连接的声明，如下：Connection: Keep-Alive

主流的web服务器都支持长连接，比如apache中，可以用KeepAlive off关闭长连接。

对于长连接的有效使用，还有关键一点在于长连接超时时间的设置，即长连接在什么时候关闭吗？

Apache的默认设置为5s, 若这个时间设置过长，则可能导致资源无效占有，维持大量空闲进程，影响服务器性能。

4. **改进I/O 模型**
   I/O操作根据设备的不同分为很多类型，比如内存I/O, 网络I/O, 磁盘I/O。详解 Java 中 4 种 I/O 模型，推荐大家看下。

对于网络I/O和磁盘I/O, 它们的速度要慢很多，尽管使用RAID磁盘阵列可通过并行磁盘磁盘来加快磁盘I/O速度，购买大连独享网络带宽以及使用高带宽网络适配器可以提高网络I/O的速度。

但这些I/O操作需要内核系统调用来完成，这些需要CPU来调度，这使得CPU不得不浪费宝贵的时间来等待慢速I/O操作。

我们希望让CPU足够少的时间在i/O操作的调度上，如何让高速的CPU和慢速的I/O设备更好地协调工作，是现代计算机一直探讨的话题。各种I/O模型的本质区别在于CPU的参与方式。

DMA技术
I/O设备和内存之间的数据传输方式由DMA控制器完成。在DMA模式下，CPU只需向DMA下达命令，让DMA控制器来处理数据的传送，这样可以大大节省系统资源。

异步I/O
异步I/O指主动请求数据后便可以继续处理其它任务，随后等待I/O操作的通知，这样进程在数据读写时不发生阻塞。

异步I/O是非阻塞的，当函数返回时，真正的I/O传输已经完成，这让CPU处理和I/O操作达到很好的重叠。

**I/O多路复用**
epoll服务器同时处理大量的文件描述符是必不可少的，若采用同步非阻塞I/O模型，若同时接收TCP连接的数据，就必须轮流对每个socket调用接收数据的方法，不管这些socket有没有可接收的数据，都要询问一次。

假如大部分socket并没有数据可以接收，那么进程便会浪费很多CPU时间用于检查这些socket有没有可以接收的数据。

多路I/O就绪通知的出现，提供了对大量文件描述符就绪检查的高性能方案，它允许进程通过一种方法同时监视所有文件描述符，并可以快速获得所有就绪的文件描述符，然后只针对这些文件描述符进行数据访问。

epoll可以同时支持水平触发和边缘触发，理论上边缘触发性能更高，但是代码实现复杂，因为任何意外的丢失事件都会造成请求处理错误。

**epoll**主要有2大改进：

epoll只告知就绪的文件描述符，而且当调用epoll_wait()获得文件描述符时，返回并不是实际的描述符，而是一个代表就绪描述符数量的值，然后只需去epoll指定的一个数组中依次取得相应数量的文件描述符即可。

这里使用了内存映射(mmap)技术，这样彻底省掉了这些文件描述符在系统调用时复制的开销。

epoll采用基于事件的就绪通知方式。其事先通过epoll_ctrl()注册每一个文件描述符，一旦某个文件描述符就绪时，内核会采用类似callback的回调机制，当进程调用epoll_wait()时得到通知

关于IO模型，可以参考笔者前面写的相关文章Java NIO.2；关于epoll，可以参考笔者前面写的文章select、poll和epoll简介。

**Sendfile**
大多数时候，我们都向服务器请求静态文件，比如图片，样式表等。

在处理这些请求时，磁盘文件的数据先经过内核缓冲区，然后到用户内存空间，不需经过任何处理，其又被送到网卡对应的内核缓冲区，接着再被送入网卡进行发送。

Linux提供sendfile()系统调用，可以讲磁盘文件的特定部分直接传送到代表客户端的socket描述符，加快了静态文件的请求速度，同时减少CPU和内存的开销。

适用场景：对于请求较小的静态文件，sendfile发挥的作用不那么明显，因发送数据的环节在整个过程中所占时间的比例相比于大文件请求时小很多。

**内存映射**
Linux内核提供一种访问磁盘文件的特殊方式，它可以将内存中某块地址空间和我们指定的磁盘文件相关联，从而对这块内存的访问转换为对磁盘文件的访问。这种技术称为内存映射。

多数情况下，内存映射可以提高磁盘I/O的性能，无须使用read()或write()等系统调用来访问文件，而是通过mmap()系统调用来建立内存和磁盘文件的关联，然后像访问内存一样自由访问文件。

缺点：在处理较大文件时，内存映射会导致较大的内存开销，得不偿失。

直接I/O
在linux 2.6中，内存映射和直接访问文件没有本质差异，因为数据需要经过2次复制，即在磁盘与内核缓冲区之间以及在内核缓冲区与用户态内存空间。

引入内核缓冲区的目的在于提高磁盘文件的访问性能，然而对于一些复杂的应用，比如数据库服务器，它们为了进一步提高性能，希望绕过内核缓冲区，由自己在用户态空间实现并管理I/O缓冲区，比如数据库可根据更加合理的策略来提高查询缓存命中率。

另一方面，绕过内核缓冲区也可以减少系统内存的开销，因内核缓冲区本身就在使用系统内存。

Linux在open()系统调用中增加参数选项O_DIRECT,即可绕过内核缓冲区直接访问文件,实现直接I/O。

在Mysql中，对于Innodb存储引擎，自身进行数据和索引的缓存管理，可在my.cnf配置中分配raw分区跳过内核缓冲区，实现直接I/O。

5. **改进服务器并发策略**
   服务器并发策略的目的，是让I/O操作和CPU计算尽量重叠进行，一方面让CPU在I/O等待时不要空闲，另一方面让CPU在I/O调度上尽量花最少的时间。

一个进程处理一个连接，非阻塞I/O
这样会存在多个并发请求同时到达时，服务器必然要准备多个进程来处理请求。其进程的开销限制了它的并发连接数。

但从稳定性和兼容性的角度，则其相对安全，任何一个子进程的崩溃不会影响服务器本身，父进程可以创建新的子进程；这种策略典型的例子就是Apache的fork和prefork模式。

对于并发数不高（如150以内）的站点同时依赖Apache其它功能时的应用选择Apache还是可以的。

一个线程处理一个连接，**非阻塞IO**
这种方式允许在一个进程中通过多个线程来处理多个连接，一个线程处理一个连接。Apache的worker模式就是这种典型例子，使其可支持更多的并发连接。不过这种模式的总体性能还不如prefork，所以一般不选用worker模式。推荐阅读：14个Java并发容器。

一个进程处理多个连接，**异步I/O**
一个线程同时处理多个连接，潜在的前提条件就是使用IO多路复用就绪通知。

这种情况下，将处理多个连接的进程叫做worker进程或服务进程。worker的数量可以配置，如Nginx中的worker_processes 4。

一个线程处理多个连接，异步IO
即使有高性能的IO多路复用就绪通知，但磁盘IO的等待还是无法避免的。更加高效的方法是对磁盘文件使用异步IO，目前很少有Web服务器真正意义上支持这种异步IO。

6. **改进硬件环境**
   还有一点要提及的是硬件环境，服务器的硬件配置对应用程序的性能提升往往是最直接，也是最简单的方式，这就是所谓的scale up。这里不做论述



一个系统的并发能力是多少呢？怎么衡量？

衡量指标常用的有响应时间，吞吐量，每秒查询率QPS，并发用户数

响应时间：系统对请求做出响应的时间。你简单理解为一个http请求返回所用的时间

吞吐量：单位时间内处理的请求数量。

QPS：每秒可以处理的请求数

并发用户数：同时承载正常使用系统功能的用户数量。也就是多少个人同时使用这个系统，这个系统还能正常运行。这个用户数量就是并发用户数啦。

**1. 吞吐率**

吞吐率，单位时间里服务器处理的最大请求数，单位req/s

从服务器角度，实际并发用户数的可以理解为服务器当前维护的代表不同用户的文件描述符总数，也就是并发连接数。

服务器一般会限制同时服务的最多用户数，比如apache的MaxClents参数。

这里再深入一下，对于服务器来说，服务器希望支持高吞吐率，对于用户来说，用户只希望等待最少的时间，显然，双方不能满足，所以双方利益的平衡点，就是我们希望的最大并发用户数。

**2. 压力测试**

有一个原理一定要先搞清楚，假如100个用户同时向服务器分别进行10个请求，与1个用户向服务器连续进行1000次请求，对服务器的压力是一样吗？

实际上是不一样的，因对每一个用户，连续发送请求实际上是指发送一个请求并接收到响应数据后再发送下一个请求。

这样对于1个用户向服务器连续进行1000次请求, 任何时刻服务器的网卡接收缓冲区中只有1个请求，而对于100个用户同时向服务器分别进行10个请求，服务器的网卡接收缓冲区最多有100个等待处理的请求，显然这时的服务器压力更大。

压力测试前提考虑的条件

- 并发用户数: 指在某一时刻同时向服务器发送请求的用户总数(HttpWatch)
- 总请求数
- 请求资源描述
- 请求等待时间(用户等待时间)
- 用户平均请求的等待时间
- 服务器平均请求处理的时间
- 硬件环境

压力测试中关心的时间又细分以下2种:

1. 用户平均请求等待时间（这里暂不把数据在网络的传输时间，还有用户PC本地的计算时间计算入内）
2. 服务器平均请求处理时间

用户平均请求等待时间主要用于衡量服务器在一定并发用户数下，单个用户的服务质量；而服务器平均请求处理时间就是吞吐率的倒数。

一般来说，用户平均请求等待时间 = 服务器平均请求处理时间 * 并发用户数

# 高并发服务器的设计--架构与瓶颈的设计



不同人的处理方法不同，据我经验，可以将瓶颈子分成两类：

1.阻塞串行处理

2.异步并行处理

mysql,中间件的处理属于第一类，异步网关查询属于第二类。

对于第一类，一种通用的解决方法是增加处理进程，其实是横向扩容的思想，打个比方，一个进程的并发是600，10个进程就可以达到6000了，如何才能将请求均匀地分配到这10个进程是关键。

多个进程同时监听一个端口，[负载均衡](https://cloud.tencent.com/product/clb?from=10680)的方法很多，这里介绍nginx的做法

nginx用一个全局变量ngx_accept_disabled 来控制单个进程的负载，当负载达到一定值的时候，不再接受新的负载。

对于第二类情况，解决的方法就像名字一样，异步并行解决。

拿跨网查询为例：

创建一个查询的请求，将请求放进事件模型中，等待服务端的返回，异步处理。

熟悉nginx的就知道nginx的upstream反向代理，这个解决方案跟反向代理很像，只不过在与上游服务器交互的前后分别还有其他的业务处理，而且可能还会有多次交互。

相应的流水图是这样的：

![img](https://img-blog.csdn.net/20130527204452023)

当客户端请求量大时，事件模型的容量会成为瓶颈，这样仍然需要横向扩容的方式来解决，增加处理进程。

这两种情况的处理方法大致如此，有时候特殊问题特殊对待，比哪数据库的瓶颈可以借助缓存解决，有些高配服务器的内存128G，甚至几台高配服务器只为一个业务，这样的情况下，不吃点内存难免对不起老板的money.





# 1秒1000并发 高并发需要什么样的服务器

- 我这边一分钟产生40万条数据，大概是400MB，期间要有其它程序处理这些数据。最初采用了Redis和MySQL，因为有读有写，发现写库根本来不及。最后采用的方式是：先缓存数据在内存，将每10万条数据进行序列化，写文件（7200转的硬盘，每秒写100MB），另外一程序解析文件，处理数据（处理完数据没那么多了），之后存库。

  - 所有数据先存队列里（比如beanstalkd），然后异步写入数据库
  - 网络环境是局域网

- 不需要有特殊服务器，一般云上主流主机都可以，主要还是软件架构要符合业务场景。

  - 阿里云10台2核4g

- 宽带肯定是要万兆的，硬件这块其实还好，现在可以用很廉价的pc来做分布式的架构，至于内存和硬盘的大小主要是根据数据量的大小和存储多少来决定的。

- 先普及一下基础知识：

  一、硬件条件。确认服务器硬件是否足够支持当前的流量，一台普通的P4服务器一般最多能支持每天10万独立IP，如果访问量比这个还要大， 那么必须首先配置一台更高性能的专用服务器才能解决问题 ，另外就是增加服务器数量，否则怎么优化都不可能彻底解决性能问题。

  

  二、数据库。优化数据库访问前台实现完全的静态化当然最好，可以完全不用访问数据库，不过对于频繁更新的网站， 静态化往往不能满足某些功能。缓存技术就是另一个解决方案，就是将动态数据存储到缓存文件中，动态网页直接调用 这些文件，而不必再访问数据库，WordPress和Z-Blog都大量使用这种缓存技术。如果确实无法避免对数据库的访问，那么可以尝试优化数据库的查询SQL，避免使用 Select * from这样的语句，每次查询只返回自己需要的结果，避免短时间内的大,尽量做到"所查即所得" ,遵循以小表为主,附表为辅,查询条件先索引,先小后大的原则,提高查询效率.量SQL查询。

  三、禁止盗链。外部网站的图片或者文件盗链往往会带来大量的负载压力，因此应该严格限制外部对于自身的图片或者文件盗链，好在目前可以简单地通过refer来控制盗链，Apache自 己就可以通过配置来禁止盗链，IIS也有一些第三方的ISAPI可以实现同样的功能。当然，伪造refer也可以通过代码来实现盗链，不过目前蓄意伪造refer盗链的还不多， 可以先不去考虑，或者使用非技术手段来解决，比如在图片上增加水印。

  

  四、控制大文件的下载。大文件的下载会占用很大的流量，并且对于非SCSI硬盘来说，大量文件下载会消耗 CPU，使得网站响应能力下降。因此，尽量不要提供超过2M的大文件下载，如果需要提供，建议将大文件放在另外一台服务器上。

  

  五、镜像分流。将文件放在不同的主机上，提供不同的镜像供用户下载。比如如果觉得RSS文件占用流量大，那么使用FeedBurner或者FeedSky等服务将RSS输出放在其他主机上，这样别人访问的流量压力就大多集中在FeedBurner的主机上，RSS就不占用太多资源了。

  

  六、做好流量监控。在网站上安装一个流量分析统计软件，可以即时知道哪些地方耗费了大量流量，哪些页面需要再进行优化，因此，解决流量问题还需要进行精确的统计分析才可以。推荐使用的流量分析统计软件是Google Analytics（Google分析）。

  

  接下来我们来说说服务器架构，前段时间我们请到了国内服务器顶级攻城狮，他把服务器那点事讲得非常通透简单。对于一个刚起步的创业公司，不需要考虑太多复杂的服务器架构，能把业务跑起来就行了。但是在早期业务逻辑设计时，懂一些稍微复杂的服务器架构的逻辑，后面可以少走很多弯路。

  

  下面这个图估计大家都明白，这就是最基础的服务器架构。傻瓜式的方法是把应用服务器、文件服务器、数据库服务器全部混合在一起，呵呵呵！但这并不是最科学的。

  ![img](https://pic3.zhimg.com/80/v2-8e496f310fc643f9c12934395fa7c445_1440w.png)

  

  

  当业务量持续增加到一定量以后，执行应用程序、读写文件、访问数据库应该有所区分，保证各自的需求都能得到满足，这时候你需要考虑把应用服务器、文件服务器、数据库服务器分离，这个时候的服务器架构应该是下面这样的，它是由三个独立的服务器组成，各司其职。

  ![img](https://pic1.zhimg.com/80/v2-3c7d638f12854bfff9defe7448a2648a_1440w.png)

  

  

  随着业务量持续增加，应用程序访问缓存数据会成为瓶颈，这个时候需要增加本地缓存，有的也需要分布式缓存。分布式缓存是指缓存部署在多个服务器组成的服务器集群中，以集群的方式提供缓存服务，其架构方式主要有两种，一种是以JBoss Cache为代表的需要同步更新的分布式缓存，一种是以Memchached为代表的互不通信的分布式缓存。如下图：

  ![img](https://pic1.zhimg.com/80/v2-2fe94a063184df2ba0ef279145e728c6_1440w.png)

  

  

  接下来，需要更多台应用服务器以应对复杂的业务逻辑，同时需要负载均衡调度服务器来调度和分配应用服务器的工作任务。

  ![img](https://pic1.zhimg.com/80/v2-073ccab95e5175268865591de2353804_1440w.png)

  

  

  再往后，需要考虑数据库服务器的承压能力，通常可以采用主从式数据库服务器架构，把读、写两部分分开，既可以提高数据访问的安全性，也能提高数据读写的效率。

  ![img](https://pic4.zhimg.com/80/v2-44bee1d539b9b6e8ce96a15a231c7c5c_1440w.png)

  

  

  随着业务量暴增，单一区域的服务器带宽将不能承载全国的业务需求，这时候需要增加反向代理和CDN服务器。CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。其目的是使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。

  ![img](https://picb.zhimg.com/80/v2-cfbd61431a0b08b140184deb0c77d063_1440w.png)

  

  

  同样，服务器架构师应该分析文件服务器和数据库服务器的网络读写速度，进一步部署分布式文件和分布式数据库的架构。

  ![img](https://pic3.zhimg.com/80/v2-019478359e8a916b405b724000922e4f_1440w.png)

  

  

  对于有搜索和大量查询的网络业务，还需要增加独立的搜索引擎和NoSQL服务器。

  ![img](https://picb.zhimg.com/80/v2-967cc701131edeffd524857d84660d0a_1440w.png)

  

  

  对于更复杂的系统，还需要进一步拆分应用服务器，增加消息队列服务器。增加消息队列服务器有以下几点好处：

  1，由于消息队列服务器的速度远远高于数据库服务器，所以能够快递处理并返回数据；

  2，消息队列服务器具有更好的扩展性；

  3，在高并发的情况下，延迟写入数据库，可以有效降低数据库的压力。

  ![img](https://picb.zhimg.com/80/v2-1ebdedfc6cb79c4cbeab8203f5926a15_1440w.png)

  

  

  对于一些超大型综合互联网业务，应用服务器也需要分布式的架构，这个时候在不同业务的应用服务器之间做好消息协同会有较大的挑战。

  

  

  ![img](https://pic2.zhimg.com/80/v2-ea826176a298de845a07acb7318f35e9_1440w.png)

  

  读完后，是不是感觉很简单，**基本上就是围绕着应用服务器、文件服务器、数据库服务器，以及不断提升其性能需要增加的服务器**。好在如今腾讯云、阿里云、金山云都提供了完整的解决方案

# 设计一个高并发、高可用秒杀系统



## **秒杀系统的难点**

- 友好的用户体验

  - 用户不能接受破窗的体验，例如：系统超时、系统错误的提示，或者直接 404 页面

- 瞬时高并发流量的挑战

  - 木桶短板理论，整个系统的瓶颈往往都在 DB，如何设计出高并发、高可用系统？

## **如何设计**

![img](https://pic1.zhimg.com/v2-e3a128f561bb4739c156ed6e392cb426_b.jpg)

上图是一个典型的互联网业务，用户完成一个写操作，一般会通过接入层和逻辑层，这里的服务都是无状态，可以通过平行拓展去解决高并发的问题；到了 db 层，必须要落到介质中，可以是磁盘/ssd/内存，如果出现 key 的冲突，会有一些并发控制技术，例如 cas/加锁/串行排队等。

**直筒型**

直筒型业务，指的是用户请求 1:1 的洞穿到 db 层，如下图所示。在比较简单的业务中，才会采用这个模型。随着业务规模复杂度上来，一定会有 db 和逻辑层分离、逻辑层和接入层分离。

![img](https://pic2.zhimg.com/v2-15f4981679385991797c2c435160d2dd_b.jpg)

**漏斗型**

漏斗型业务，指的是，用户的请求，从客户端到 db 层，层层递减，递减的程度视业务而定。例如当 10w 人去抢 1 个物品时，db 层的请求在个位数量级，这就是比较理想的模型。如下图所示

![img](https://picb.zhimg.com/v2-243232ef478e347dd4d594af21a03d8a_b.jpg)

这个模型，是高并发的基础，翻译一下就是下面这些：

- 及早发现，及早拒绝
- Fast Fail
- 前端保护后端

**如何实现漏斗型系统**

漏斗型系统需要从产品策略/客户端/接入层/逻辑层/DB 层全方位立体的设计。

![img](https://pic4.zhimg.com/v2-e0a777b9cacabc2e32df83f4e7d6d829_b.jpg)

**产品策略**

- 轻重逻辑分离，以秒杀为例，将抢到和到账分开；

- - 抢到，是比较轻的操作，库存扣成功后，就可以成功了
  - 到账，是比较重的操作，需要涉及到到事务操作

- 用户分流，以整点秒杀活动为例，在 1 分钟内，陆续对用户放开入口，将所有用户请求打散在 60s 内，请求就可以降一个数量级

- 页面简化，在秒杀开始的时候，需要简化页面展示，该时刻只保留和秒杀相关的功能。例如，秒杀开始的时候，页面可以不展示推荐的商品。

**客户端**

- 重试策略非常关键，如果用户秒杀失败了，频繁重试，会加剧后端的雪崩。如何重试呢？根据后端返回码的约定，有两种方法：

- - 不允许重试错误，此时 ui 和文案都需要有一个提示。同时不允许重试
  - 可重试错误，需要策略重试，例如二进制退避法。同时文案和 ui 需要提示。

- ui 和文案，秒杀开始前后，用户的所有异常都需要有精心设计的 ui 和文案提示。例如：【当前活动太火爆，请稍后再重试】【你的货物堵在路上，请稍后查看】等

- 前端随机丢弃请求可以作为降级方案，当用户流量远远大于系统容量时，人工下发随机丢弃标记，用户本地客户端开始随机丢弃请求。

**接入层**

- 所有请求需要鉴权，校验合法身份

- - 如果是长链接的服务，鉴权粒度可以在 session 级别；如果是短链接业务，需要应对这种高并发流量，例如 cache 等

- 根据后端系统容量，需要一个全局的限流功能，通常有两种做法：

- - 设置好 N 后，动态获取机器部署情况 M，然后下发单机限流值 N/M。要求请求均匀访问，部署机器统一。
  - 维护全局 key，以时间戳建 key。有热 key 问题，可以通过增加更细粒度的 key 或者定时更新 key 的方法。

- 对于单用户/单 ip 需要频控，主要是防黑产和恶意用户。如果秒杀是有条件的，例如需要完成 xxx 任务，解锁资格，对于获得资格的步骤，可以进行安全扫描，识别出黑产和恶意用户。

**逻辑层**

- 逻辑层首先应该进入校验逻辑，例如参数的合法性，是否有资格，如果失败的用户，快速返回，避免请求洞穿到 db。

- 异步补单，对于已经扣除秒杀资格的用户，如果发货失败后，通常的两种做法是：

- - 事务回滚，回滚本次行为，提示用户重试。这个代价特别大，而且用户重试和前面的重试策略结合的话，用户体验也不大流畅。
  - 异步重做，记录本次用户的 log，提示用户【稍后查看，正在发货中】，后台在峰值过后，启动异步补单。需要服务支持幂等

- 对于发货的库存，需要处理热 key。通常的做法是，维护多个 key，每个用户固定去某个查询库存。对于大量人抢红包的场景，可以提前分配。

**存储层**

对于业务模型而言，对于 db 的要求需要保证几个原则：

- 可靠性

- - 主备：主备能互相切换，一般要求在同城跨机房

  - 异地容灾：当一地异常，数据能恢复，异地能选主

  - 数据需要持久化到磁盘，或者更冷的设备

- 一致性

- - 对于秒杀而言，需要严格的一致性，一般要求主备严格的一致。

## **实践——微视集卡瓜分系统**

微视集卡瓜分项目属于微视春节项目之一。用户的体验流程如下：

![img](https://pic2.zhimg.com/v2-9bde162bee150dc33d61df71ffb71724_b.jpg)

**架构图**

![img](https://pic2.zhimg.com/v2-60b7f118b41855263cd1e4d434285b4d_b.jpg)

- 客户端主要是微视主 app 和 h5 页面，主 app 是入口，h5 页面是集卡活动页面和瓜分页面。

- 逻辑部分为分：发卡来源、集卡模块、奖品模块，发卡来源主要是任务模块；集卡模块主要由活动模块和集卡模块组成。瓜分部分主要在活动控制层。

- 奖品模块主要是发钱和其他奖品。

**瓜分降级预案**

为了做好瓜分时刻的高并发，对整个系统需要保证两个重要的事情：

- 全链路梳理，包括调用链的合理性和时延设置

- 降级服务预案分析，提升系统的鲁棒性

如下图所示，是针对瓜分全链路调用分析如下图，需要特别说明的几点：

![img](https://picb.zhimg.com/v2-2357aac83e60101d1b143f634725b5b2_b.jpg)

- 时延很重要，需要全链路分析。不但可以提高吞吐量，而且可以快速暴露系统的瓶颈。

- 峰值时刻，补单逻辑需要关闭，避免加剧雪崩。

我们的降级预案大概如下：

- 一级预案，瓜分时刻前后 5 分钟自动进入：

- - 入口处 1 分钟内陆续放开入口倒计时，未登录用户不弹入口

  - 主会场排队，以进入主会场 100wqps 为例，超过了进入排队，由接入层频控控制

  - 拉取资格接口排队，拉取资格接口 100wqps，超过了进入排队，由接入层频控控制

  - 抢红包排队，抢红包 100wqps，超过了进入排队，由接入层频控控制

  - 红包到账排队，如果资格扣除成功，现金发放失败，进入排队，24 小时内到账。异步补单

  - 入口处调用后端非关键 rpc:ParticipateStatus，手动关闭

  - 异步补单逻辑关闭。

- 二级预案，后端随机丢请求，接入层频控失效或者下游服务过载，手动开启进入

- 三级预案，前端随机丢请求，后端服务过载或者宕机进入。手动开启

综上，整个瓜分时刻体验如下所示：

![img](https://pic4.zhimg.com/v2-4551c7d39e776fe0d494c4cc6005fa17_b.jpg)

回顾下漏斗模型，总结下整个实践：

![img](https://picb.zhimg.com/v2-db80d36c4a81173ec75db7fe88b25a75_b.jpg)





降级开关设计，过载感知，分流策略设计

