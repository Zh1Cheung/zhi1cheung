---
title: MYSQL（5）
categories:
- MYSQL
tags:
- MYSQL
---



## InnoDB、Memory

- InnoDB 和 Memory 引擎的数据组织方式是不同的

  - InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。
  - 而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。

- 这两个引擎的一些典型不同

  -  InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；
  -  当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；
  - 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；
  -  InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。
  - InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。
  - 由于内存表的这些特性，每个数据行被删除以后，空出的这个位置都可以被接下来要插入的数据复用

- 为什么我不建议你在生产环境上使用内存表。这里的原因主要包括两个方面：

  - 锁粒度问题
    - 内存表不支持行锁，只支持表锁
  - 数据持久化问题
    - 数据库重启的时候，所有的内存表都会被清空。
    - 在高可用架构下，内存表的这个特点简直可以当做 bug 来看待了。

  





## 自增主键

- 概述

  - 自增主键可以让主键索引尽量地保持递增顺序插入，避免了页分裂，因此索引更紧凑。
  - 自增主键不能保证连续递增。

- 自增值保存在哪

  - show create table +表
    - 表定义里面出现了一个 AUTO_INCREMENT=2，表示下一次插入数据时，如果需要自动生成自增值，会生成 id=2。
    - 表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。
  - 不同的引擎对于自增值的保存策略不同。
    - MyISAM 引擎的自增值保存在数据文件中。
    - InnoDB 引擎的自增值，其实是保存在了内存里，并且到了 MySQL 8.0 版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为MySQL 重启前的值”
    - 在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。

- 自增值修改机制

  - 在 MySQL 里面，如果字段 id 被定义为 AUTO_INCREMENT
    - 某次要插入的值是 X，当前的自增值是 Y。
    - 如果 X<Y，那么这个表的自增值不变；
    - 如果 X≥Y，就需要把当前自增值修改为新的自增值。
  - auto_increment_offset 和 auto_increment_increment 是两个系统参数，分别用来表示自增的初始值和步长，默认值都是 1。
    - 新的自增值生成算法是：从auto_increment_offset 开始，以auto_increment_increment 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。
    - 在一些场景下，使用的就不全是默认值。比如，双 M 的主备结构里要求双写的时候，我们就可能会设置成 auto_increment_increment=2，让一个库的自增 id 都是奇数，另一个库的自增 id 都是偶数，避免两个库生成的主键发生冲突

- 在这两个参数都设置为 1 的时候，自增主键 id 却不能保证是连续的

  - 唯一键冲突是导致自增主键 id 不连续的第一种原因。

    - 假设，表 t 里面已经有了 (1,1,1) 这条记录，这时我再执行一条插入数据命令（insert into t values(null, 1, 1)）：

      - > 这个语句的执行流程就是：
        > 	传入的这一行的值是 (0,1,1)
        > 	 InnoDB 发现用户没有指定自增 id 的值，获取表 t 当前的自增值 2
        > 	将传入的行的值改成 (2,1,1);
        > 	将表的自增值改成 3；
        > 	 继续执行插入数据操作，由于已经存在 c=1 （c 是唯一索引）的记录，所以报 Duplicate key error，语句返回。

    - 这个表的自增值改成 3，是在真正执行插入数据的操作之前。这个语句真正执行的时候，因为碰到唯一键 c 冲突，所以 id=2 这一行并没有插入成功，但也没有将自增值再改回去。

    - 在这之后，再插入新的数据行时，拿到的自增 id 就是 3。也就是说，出现了自增主键不连续的情况

  - 事务回滚也会产生类似的现象，这就是第二种原因

    - 语句执行失败也不回退自增 id。也正是因为这样，所以才只保证了自增 id 是递增的，但不保证是连续的。

  - 主键 id 出现自增 id 不连续的第三种原因。

    - > 对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略：
      > 	语句执行过程中，第一次申请自增 id，会分配 1 个；
      > 	1 个用完以后，这个语句第二次申请自增 id，会分配 2 个；
      > 	 2 个用完以后，还是这个语句，第三次申请自增 id，会分配 4 个；
      > 	依此类推，同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍。
      >
      > 
      >
      > insert…select，实际上往表 t2 中插入了 4 行数据。但是，这四行数据是分三次申请的自增id，第一次申请到了 id=1，第二次被分配了 id=2 和 id=3， 第三次被分配到 id=4 到id=7。
      >
      > 
      >
      > 由于这条语句实际只用上了 4 个 id，所以 id=5 到 id=7 就被浪费掉了。之后，再执行insert into t2 values(null, 5,5)，实际上插入的数据就是（8,5,5)。

- 自增锁的优化

  - 自增 id 锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请。

  - 在 binlog 里面把插入数据的操作都如实记录进来，到备库执行的时候，不再依赖于自增主键去生成。

    - innodb_autoinc_lock_mode 设置为2（设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁），同时 binlog_format 设置为 row。

    - 因为insert … select中insert 生成的 id 不连续。这个不连续的 id，用statement 格式的 binlog 来串行执行，是执行不出来的。

      

  





## insert语句

- 主键索引，唯一索引这两类索引冲突加的都是 next-key lock。
- insert … select 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下，这个语句会给 select 的表里扫描到的记录和间隙加读锁
- 如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。
  - 这类一边遍历数据，一边更新数据的情况，如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录，新插入的记录如果参与计算逻辑，就跟语义不符。
- insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的读锁。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。
  - insert into … on duplicate key update 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。
- 关于数据拷贝大表我建议采用pt-archiver,这个工具能自动控制频率和速度









## 日志和索引相关问题

- 在两阶段提交的不同瞬间，MySQL 如果发生异常重启，是怎么保证数据完整性的？
  - 由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。
  -  如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；
    - 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：
      - a. 如果是，则提交事务；
      - b. 否则，回滚事务。
- MySQL 怎么知道 binlog 是完整的
  - 一个事务的 binlog 是有完整格式的：
    - statement 格式的 binlog，最后会有 COMMIT；
    - row 格式的 binlog，最后会有一个 XID event。
  - 在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog内容的正确性。
- redo log 和 binlog 是怎么关联起来的
  - 它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log
    - 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
    - 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。
- 处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计
  - 数据与备份的一致性有关
    - 在时刻 B，binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库
      （或者用这个 binlog 恢复出来的库）使用
    - 所以，在主库上也要提交这个事务
    - 采用这个策略，主库和备库的数据就保证了一致性。
  - 如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？
    - 如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。
    - 对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。
  - InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。
-  binlog 有着 redo log 无法替代的功能。
  - 一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，
    - 一个就是 MySQL 系统依赖于 binlog
      - MySQL 系统高可用的基础，就是 binlog 复制。
      - 还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。
- 正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢
  - 这里涉及到了，“redo log 里面到底是什么”的问题。
  - redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。
  - 如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页
    - 最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。
      在崩溃恢复场景中
  - InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。







## join 的写法

- 构造两个表 a 和 b：

  - > 1 create table a(f1 int, f2 int, index(f1))engine=innodb;
    > 2 create table b(f1 int, f2 int)engine=innodb;
    > 3 insert into a values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6);
    > 4 insert into b values(3,3),(4,4),(5,5),(6,6),(7,7),(8,8);
    >
    > 
    >
    > 1 select * from a left join b on(a.f1=b.f1) and (a.f2=b.f2); /*Q1*/
    > 2 select * from a left join b on(a.f1=b.f1) where (a.f2=b.f2);/*Q2*/
    >
    > 
    >
    > 语句 Q1 返回的数据集是 6 行，表 a 中即使没有满足匹配条件的记录，查询结果中也会返回一行，并将表 b 的各个字段值填成 NULL。
    >
    > 语句 Q2 返回的是 4 行。从逻辑上可以这么理解，最后的两行，由于表 b 中没有匹配的字段，结果集里面 b.f2 的值是空，不满足 where 部分的条件判断，因此不能作为结果集的一部分。

  - Q1 的 explain 结果
    - 驱动表是表 a，被驱动表是表 b；
    - 由于表 b 的 f1 字段上没有索引，所以使用的是 Block Nexted Loop Join（简称 BNL）算法。

  - Q2 的 expain 结果

    - 以表 b 为驱动表的。而如果一条 join 语句的 Extra 字段什么都没写的话，就表示使用的是 Index Nested-Loop Join（简称 NLJ）算法。
    - 执行流程是这样的：顺序扫描表 b，每一行用 b.f1 到表 a 中去查，匹配到记录后判断 a.f2=b.f2 是否满足，满足条件的话就作为结果集的一部分返回。

  - 在 MySQL 里，NULL 跟任何值执行等值判断和不等值判断的结果，都是 NULL。这里包括， select NULL = NULL 的结果，也是返回 NULL

    - 语句 Q2 里面 where a.f2=b.f2 就表示，查询结果里面不会包含 b.f2 是 NULL 的行，这样这个 left join 的语义就是“找到这两个表里面，f1、f2 对应相同的行。对于表 a中存在，而表 b 中匹配不到的行，就放弃”。这样，这条语句虽然用的是 left join，但是语义跟 join 是一致的。
    - 优化器就把这条语句的 left join 改写成了 join，然后因为表 a 的 f1 上有索引，就把表 b 作为驱动表，这样就可以用上 NLJ 算法。在执行 explain 之后，你再执行 show warnings，就能看到这个改写的结果

  - 如果需要 left join 的语义，就不能把被驱动表的字段放在 where 条件里面做等值判断或不等值判断，必须都写在 on 里面。

  - join 将判断条件是否全部放在 on 部分就没有区别了。







## distinct 和 group by 的性能

- 如果表 t 的字段 a 上没有索引，那么下面这两条语句：

  - > 1 select a from t group by a order by null;
    > 2 select distinct a from t;

  - 没有了 count(*) 以后，也就是不再需要执行“计算总数”的逻辑时，第一条语句的逻辑就变成是：按照字段 a 做分组，相同的 a 的值只返回一行。而这就是 distinct 的语义，所以不需要执行聚合函数时，distinct 和 group by 这两条语句的语义和执行流程是相同的，因此执行性能也相同。

- 这两条语句的执行流程是下面这样的

  -  创建一个临时表，临时表有一个字段 a，并且在这个字段 a 上创建一个唯一索引；
  - 遍历表 t，依次取数据插入临时表中：
    - 如果发现唯一键冲突，就跳过；
    - 否则插入成功
  - 遍历完成后，将临时表作为结果集返回给客户端。

















