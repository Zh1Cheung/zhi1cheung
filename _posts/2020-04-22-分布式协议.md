---
title: 分布式协议
categories:
- 分布式
tags:
- 分布式
---




## CAP理论

- 一致性（Consistency）
  - 一致性说的是客户端的每次读操作，不管访问哪个节点，要么读到的都是同一份最新的数据，要么读取失败。
  - 你可以把一致性看作是分布式系统对访问本系统的客户端的一种承诺：不管你访问哪个节点，要么我给你返回的都是绝对一致的数据，要么你都读取失败。你可以看到，一致性强调的不是数据完整，而是各节点间的数据一致。
- 可用性（Availability）
  - 可用性说的是任何来自客户端的请求，不管访问哪个节点，都能得到响应数据，但不保证是同一份最新数据。你也可以把可用性看作是分布式系统对访问本系统的客户端的另外一种承诺：我尽力给你返回数据，不会不响应你，但是我不保证每个节点给你的数据都是最新的。这个指标强调的是服务可用，但不保证数据的一致
- 分区容错性（Partition Tolerance）
  - 当节点间出现任意数量的消息丢失或高延迟的时候，系统仍然可以继续提供服务。也就是说，分布式系统在告诉访问本系统的客户端：不管我的内部出现什么样的数据同步问题，我会一直运行，提供服务。这个指标，强调的是集群对分区故障的容错能力。
  - 当节点 1 和节点 2 通信出问题的时候，如果系统仍能提供服务，那么，2个节点是满足分区容错性的。
  - 因为分布式系统与单机系统不同，它涉及到多节点间的通讯和交互，节点间的分区故障是必然发生的，所以我要提醒你，在分布式系统中分区容错性是必须要考虑的。







## ACID理论

- ACID 理论是对事务特性的抽象和总结，方便我们实现事务。你可以理解成：如果实现了操作的 ACID 特性，那么就实现了事务。而大多数人觉得比较难，是因为分布式系统涉及多个节点间的操作。加锁、时间序列等机制，只能保证单个节点上操作的 ACID 特性，无法保证节点间操作的 ACID 特性。
- TCC
  - 不管是原始的二阶段提交协议，还是 XA 协议，都存在一些问题
    - 在提交请求阶段，需要预留资源，在资源预留期间，其他人不能操作（比如，XA 在第一阶段会将相关资源锁定）；
    - 在第一个阶段，每个参与者投票表决事务是放弃还是提交。一旦参与者投票要求提交事务，那么就不允许放弃事务。也就是说，在一个参与者投票要求提交事务之前，它必须保证能够执行提交协议中它自己那一部分，即使参与者出现故障或者中途被替换掉。这个特性，是我们需要在代码实现时保障的。
    - 崩溃后协调者会不断的重试，这时候这个事务使用到的相关资源都会被锁住，没办法使用，直到节点恢复。
    - 参与者在阶段二挂掉，重启之后是没办法知道别的节点是否commit还是rollback，事务处于悬挂状态，必须等待协调者的异步重试消息，来执行commit或rollback操作
  - 在TCC中，数据是最终一致。
    - 2PC用在集群间一致性数据同步，所有参与者完成的是同一件事，可以理解为它们在一个start transaction--commit里面，具有强一致性
    - TCC是对业务过程的拆分，一致性弱于2PC

- Paxos、Raft 等强一致性算法，也采用了二阶段提交操作，在“提交请求阶段”，只要大多数节点确认就可以，而具有 ACID 特性的事务，则要求全部节点确认可以。所以可以将具有 ACID 特性的操作，理解为最强的一致性。
- 事务系统缺乏节点故障容错能力，性能也是痛点。
  - 需要将提交相关信息保存到持久存储上，用于故障后恢复，超时，也要不断重试







## BASE理论

- BASE 理论是 CAP 理论中的 AP 的延伸，是对互联网大规模分布式系统的实践总结，强调可用性。
  - 几乎所有的互联网后台分布式系统都有 BASE 的支持，这个理论很重要，地位也很高。一旦掌握它，你就能掌握绝大部分场景的分布式系统的架构技巧，设计出适合业务场景特点的、高可用性的分布式系统。
  - 而它的核心就是基本可用（Basically Available）和最终一致性（Eventually consistent）。也有人会提到软状态（Soft state），在我看来，软状态描述的是实现服务可用性的时候系统数据的一种过渡状态，也就是说不同节点间，数据副本存在短暂的不一致。你只需要知道软状态是一种过渡状态就可以了，我们不多说。
- 实现基本可用的 4 板斧
  - 基本可用是说，当分布式系统在出现不可预知的故障时，允许损失部分功能的可用性，保障核心功能的可用性。
  - 在春运期间，深圳出发的火车票在 8 点开售，北京出发的火车票在 9 点开售。这就是我们常说的**流量削峰**。
  - 在春运期间，自己提交的购票请求，往往会在队列中排队等待处理，可能几分钟或十几分钟后，系统才开始处理，然后响应处理结果，这就是你熟悉的**延迟响应**。
  - **体验降级**， 比如用小图片来替代原始图片，通过降低图片的清晰度和大小，提升系统的处理能力。
  - 然后你还能想到**过载保护**， 比如把接收到的请求放在指定的队列中排队处理，如果请求等待时间超时了（假设是 100ms），这个时候直接拒绝超时请求；再比如队列满了之后，就清除队列中一定数量的排队请求，保护系统不过载，实现系统的基本可用。

- 最终的一致
  - 在数据一致性上，存在一个短暂的延迟
  - 一般来说，在实际工程实践中有这样几种方式：
    - 以最新写入的数据为准，比如 AP 模型的 KV 存储采用的就是这种方式；
    - 以第一次写入的数据为准，如果你不希望存储的数据被更改，可以以它为准。
  - 在这里，我想强调的是因为写时修复（在写入数据，检测数据的不一致时，进行修复）不需要做数据一致性对比，性能消耗比较低，对系统运行影响也不大，所以我推荐你在实现最终一致性时优先实现这种方式。而读时修复（在读取数据时，检测数据的不一致，进行修复）和异步修复（这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复）因为需要做数据的一致性对比，性能消耗比较多，在开发实际系统时，你要尽量优化一致性对比的算法，降低性能消耗，避免对系统运行造成影响。
  - 在实现最终一致性的时候，我推荐同时实现自定义写一致性级别（All、Quorum、One、Any）， 让用户可以自主选择相应的一致性级别，比如可以通过设置一致性级别为 All，来实现强一致性。
- 从微服务的角度来考虑, 有这些方式能够尽可能地保证系统的基本可用:
  - 使用消息队列, 对偶然的高并发写操作进行削峰填谷;
    - MQ能很好的弥补ES写性能差、支持突发流量能力弱的痛点。
  2. 对进程间的服务调用做好熔断保护;
  3. 在系统能力无法支撑高并发访问时, 对非核心业务降级;
  4. 对关键服务做好限流.