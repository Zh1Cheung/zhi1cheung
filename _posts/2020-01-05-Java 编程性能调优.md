---
title: Java 编程性能调优
categories:
- JAVA
tags:
- Java调优
---


## 如何制定性能调优标准

- CPU
  - CPU利用率则代表单位时间内一个线程或进程实时占用CPU的百分比
  - 系统负载代表单位时间内正在运行或等待的进程或线程数
  - CPU密集型
  - I/O密集型
- 内存
  - Java 程序一般通过 JVM 对内存进行分配管理，主要是用 JVM 中的堆内存来存储Java 创建的对象。系统堆内存的读写速度非常快，所以基本不存在读写性能瓶颈。但是由 于内存成本要比磁盘高，相比磁盘，内存的存储空间又非常有限。所以当内存空间被占满，对象无法回收时，就会导致内存溢出、内存泄露等问题。
- 磁盘 I/O
  - 磁盘相比内存来说，存储空间要大很多，但磁盘 I/O 读写的速度要比内存慢
- 网络
  - 网络带宽
- 异常
  - Java 应用中，抛出异常需要构建异常栈，对异常进行捕获和处理，这个过程非常消耗系统性能。
- 数据库
  - 数据库的操作往往是涉及到磁盘 I/O 的读写
- 锁竞争
  - 锁的使用可能会带来上下文切换，从而给系统带来性能开销。
- TPS
  - TPS(transaction per second)是单位时间内处理事务的数量
  - TPS代表一个事务的处理，可以包含了多次请求
  - TPS的一次事务代表一次用户操作到服务器返回结果
- QPS
  - QPS(query per second)是单位时间内请求的数量
  - QPS的一次请求代表一个接口的一次请求到服务器返回结果。当一次用户操作只包含一个请求接口时，TPS和QPS没有区别。当用户的一次操作包含了多个服务请求时，这个时候TPS作为这次用户操作的性能指标就更具有代表性了。
- 端口被CLOSE_WAIT占用
  - 可以通过tcpdump抓包看看连接状态，分析是否是服务端的FIN packet没有发出去。
  -   正常的关闭流程是：服务端在接收到客户端发送的关闭请求FIN后，会进入CLOSE_WAIT状态，同时发送ACK回去。在完成与客户端直接的通信操作之后，再向客户端发送FIN，进入LAST_ACK状态。
  - 如果连接是CLOSE_WAIT状态，而不是LAST_ACK状态，说明还没有发FIN给Client，那么可能是在关闭连接之前还有许多数据要发送或者其他事要做，导致没有发这个FIN packet。  





## 字符串

- String 对象是如何实现的
  -  从 Java9 版本开始，工程师将 char[] 字段改为了 byte[] 字段，又维护了一个新的属性coder，它是一个编码格式的标识
  - 从 Java7 版本开始到 Java8 版本，Java 对 String 类做了一些改变。String 类中不再有offset 和 count 两个变量了。这样的好处是 String 对象占用的内存稍微少了些，同时，String.substring 方法也不再共享 char[]，从而解决了使用该方法可能导致的内存泄漏问题。
    - 在Java6中substring方法会调用new string构造函数，此时会复用原来的char数组
- String 对象的不可变性
  -  String 类被 final 关键字修饰了，char[] 被 final+private 修饰，代表了String 对象不可被更改
  - 保证 String 对象的安全性
  -  可以实现字符串常量池
     - 当代码中使用String str= "abcdef"方式创建字符串对象时，JVM 首先会检查该对象是否在字符串常量池中，如果在，就返回该对象引用，否则新的字符串将在常量池中被创建。这种方式可以减少同一个值的字符串对象的重复创建，节约内存
     -  String str = new String(“abc”) 这种方式，首先在编译类文件时，"abc"常量字符串将会放入到常量结构中，在类加载时，“abc"将会在常量池中创建；其次，在调用 new 时，JVM 命令将会调用 String 的构造函数，同时引用常量池中的"abc” 字符串，在堆内存中创建一个 String 对象；最后，str 将引用 String 对象
        - 具体的复制过程是先将常量池中的字符串压入栈中，在使用string的构造方法时，会拿到栈中的字符串作为构造方法的参数
        - 如果调用 intern 方法，会去查看字符串常量池中是否有等于该对象的字符串，如果没有，就在常量池中新增该对象，并返回该对象引用；如果有，就返回常量池中的字符串引用。堆内存中原有的对象由于没有引用指向它，将会通过垃圾回收器回收。
        - intern方法生成的引用或对象是在运行时常量池中。
  -  对象在内存中是一块内存地址，str 则是一个指向该内存地址的引用
-  静态常量池和运行时常量池，
  - 静态常量池是存放字符串字面量、符号引用以及类和方法的信息，而运行时常量池存放的是运行时一些直接引用。
  - 运行时常量池是在类加载完成之后，将静态常量池中的符号引用值转存到运行时常量池中，类在解析之后，将符号引用替换成直接引用。
  - 这两个常量池在JDK1.7版本之后，就移到堆内存中了，这里指的是物理空间，而逻辑上还是属于方法区（方法区是逻辑分区）。  





## ArrayList还是LinkedList

- ArrayList
  - 数组是一块连续的内存空间，并且实现了RandomAccess 接口标志，意味着 ArrayList 可以实现快速随机访问，所以 for 循环效率非常高。
  - ArrayList 的实现类源码中对象数组 elementData 使用了transient 修饰，防止对象数组被其他外部方法序列化。
    - 由于 ArrayList 的数组是基于动态扩增的，所以并不是所有被分配的内存空间都存储了数据。
    - 如果采用外部序列化法实现数组的序列化，会序列化整个数组。ArrayList 为了避免这些没有存储数据的内存空间被序列化，内部提供了两个私有方法 writeObject 以及 readObject来自我完成序列化与反序列化，从而在序列化与反序列化数组时节省了空间和时间。
  - 如果我们在初始化时就比较清楚存储数据的大小，就可以在 ArrayList 初始化时指定数组容量大小，并且在添加元素时，只在数组末尾添加元素，那么 ArrayList 在大量新增元素的场景下，性能并不会变差
  - 两个方法也有不同之处，添加元素到任意位置，会导致在该位置后的所有元素都需要重新排列，而将元素添加到数组的末尾，在没有发生扩容的前提下，是不会有元素复制排序过程的。
  - ArrayList 在每一次有效的删除元素操作之后，都要进行数组的重组，并且删除的元素位置越前，数组重组的开销就越大。
- LinkedList
  - LinkedList 的两个重要属性 first/last 属性，其实还有一个 size 属性。我们可以看到这三个属性都被 transient 修饰了，原因很简单，我们在序列化的时候不会只对头尾进行序列化，所以 LinkedList 也是自行实现 readObject 和writeObject 进行序列化与反序列化
  - LinkedList 的获取元素操作实现跟 LinkedList 的删除元素操作基本类似，通过分前后半段来循环查找到对应的元素。但是通过这种方式来查询元素是非常低效的，特别是在 for 循环遍历的情况下，每一次循环都会去遍历半个 List。以使用 iterator 方式迭代循环，直接拿到我们的元素，而不需要通过循环查找 List。
- 在添加元素到尾部的操作中，我们发现，在没有扩容的情况下，ArrayList 的效率要高于LinkedList。这是因为 ArrayList 在添加元素到尾部的时候，不需要复制重排数据，效率非常高。而 LinkedList 虽然也不用循环查找元素，但 LinkedList 中多了 new 对象以及变换指针指向对象的过程，所以效率要低于 ArrayList。
- for迭代遍历
  - 当再次遍历时，会先调用内部类iteator中的hasNext(),再调用next(),在调用next()方法时，会对modCount和expectedModCount进行比较（checkForComodification()），此时两者不一致，就抛出了ConcurrentModificationException异常
  - 在foreach循环中调用list中的remove()方法，会走到fastRemove()方法，该方法不是iterator中的方法，而是ArrayList中的方法，在该方法只做了modCount++，而没有同步到expectedModCount。
  - 在iterator中的remove方法中，删除元素实际上调用的就是list.remove()方法，但是它多了一个操作：expectedModCount = modCount;
- 为什么 ArrayList 不像 HashMap 一样在扩容时需要一个负载因子
  - HashMap有负载因子是既要考虑数组太短，因哈希冲突导致链表过长而导致查询性能下降，也考虑了数组过长，新增数据时性能下降。这个负载因子是综合了数组和链表两者的长度，不能太大也不能太小。而ArrayList不需要这种考虑。





## HashMap

- 存储键值对（x，“aa”）时，哈希表会通过哈希函数 f(x) 得到"aa"的实现存储位置。

- 实际上一个链表被放满8个节点的概率非常小，实际上链表转红黑树是非常耗性能的，而链表在8个节点以内的平均查询时间复杂度与红黑树相差无几。

- hash() 方法

  - 如果我们没有使用 hash() 方法计算 hashCode，而是直接使用对象的 hashCode 值，会出现什么问题呢？

    - 假设要添加两个对象 a 和 b，如果数组长度是 16，这时对象 a 和 b 通过公式 (n - 1) &hash 运算，也就是 (16-1)＆a.hashCode 和 (16-1)＆b.hashCode。你会发现上述与运算结果都是 0。

  - 如果我们将 hashCode 值右移 16 位（h >>> 16），也就是取int 类型的一半，刚好可以将该二进制数对半切开，并且使用位异或运算（如果两个数对应的位置相反，则结果为 1，反之为 0），这样的话，就能避免上面的情况发生

    - ```java
      h = key.hashCode()) ^ (h >>> 16)
      ```

  -  (n - 1) & hash 是怎么设计的，这里的 n 代表哈希表的长度，哈希表习惯将长度设置为 2 的 n 次方，这样恰好可以保证 (n - 1) & hash 的计算得到的索引值总是位于table 数组的索引之内。例如：hash=15，n=16 时，结果为 15；hash=17，n=16 时，结果为 1。

- 在获得 Node 的存储位置后，如果判断 Node 不在哈希表中，就新增一个 Node

  - 如果存在tab[i]节点，分三种情况
    - 存在和Key相等的节点
    - 红黑树节点
    - 链表节点
      - 长度是否超过阈值
        - 转红黑树（链表长度大于8而且整个map中的键值对大于等于MIN_TREEIFY_CAPACITY (64)时，才进行链表到红黑树的转换）
      - 链表尾部新增节点

- HashMap 扩容优化

  - JDK1.7 中
    - 分别取出数组元素，一般该元素是最后一个放入链表中的元素，然后遍历以该元素为头的单向链表元素，依据每个被遍历元素的 hash 值计算其在新数组中的下标
  -  JDK 1.8 中
    - HashMap 对扩容操作做了优化。由于扩容数组的长度是 2 倍关系，所以对于假设初始 tableSize = 4 要扩容到 8 来说就是 0100 到 1000 的变化
    - 在扩容中只用判断原来的 hash 值和左移动的一位（newtable 的值）按位与操作是 0 或 1 就行，0 的话索引不变，1 的话索引变成原索引加上扩容前数组。

- 实际应用中，我们设置初始容量，一般得是 2 的整数次幂。

  - 2的幂次方减1后每一位都是1，让数组每一个位置都能添加到元素。
  - 例如十进制8，对应二进制1000，减1是0111，这样在&hash值使数组每个位置都是可以添加到元素的，如果有一个位置为0，那么无论hash值是多少那一位总是0，例如0101，&hash后第二位总是0，也就是说数组中下标为2的位置总是空的。
  - 减少哈希冲突，均匀分布元素





## I/O模型

- 字符到字节必须经过转码，如果我们不知道编码类型就很容易出现乱码问题。所以 I/O 流提供了一个直接操作字符的接口，方便我们平时对字符进行流操作
- 传统 I/O 的性能问题
  - 磁盘 I/O 操作和网络 I/O 操作
  - 多次内存复制，导致不必要的数据拷贝和上下文切换，从而降低 I/O的性能
  - 大量连接请求时，创建大量监听线程，这时如果线程没有数据就绪就会被挂起，然后进入阻塞状态。
    - 阻塞线程在阻塞状态是不会占用CPU资源的，但是会被唤醒争夺CPU资源。操作系统将CPU轮流分配给线程任务，当线程数量越多的时候，当某个线程在规定的时间片运行完之后，会被其他线程抢夺CPU资源，此时会导致上下文切换。抢夺越激烈，上下文切换就越频繁
  - 在传统 I/O 中，InputStream 的 read() 是一个 while 循环操作，它会一直等待数据读取直到数据就绪才会返回。这就意味着如果没有数据就绪，这个读取操作将会一直被挂起，用线程将会处于阻塞状态。
- 如何优化 I/O 操作
  - NIO 的发布优化了内存复制以及阻塞导致的严重性能问题
  - 使用缓冲区优化读写流操作
    - 传统 I/O 和 NIO 的最大区别就是传统 I/O 是面向流，NIO 是面向 Buffer。buffer 可以文件一次性读入内存再做后续处理，而传统的方式是边读文件边处理数据
    - 缓冲区（Buffer）和通道（Channel）
      - Buffer 是一块连续的块，是 NIO 读写数据的中转地。
        - 在没有bytebuff缓存的情况下，一旦读取数据的SO_RCVBUF满了，将会通知对端TCP协议中的窗口关闭（滑动窗口），将影响TCP发送端，这也就影响到了整个TCP通信的速度。而有了bytebuff，我们可以先将读取的数据缓存在bytebuff中，提高TCP的通信能力。
      - Channel 表示缓冲数据的源头或者目的地，它用于读取缓冲或者写入数据，是访问缓冲的接口。
  - 使用 DirectBuffer 减少内存复制
    - NIO 的 Buffer 除了做了缓冲块优化之外，还提供了一个可以直接访问物理内存的类DirectBuffer。普通的 Buffer 分配的是 JVM 堆内存，而 DirectBuffer 是直接分配物理内存。
    - 直接将步骤简化为从内核空间复制到外部设备，减少了数据拷贝
    - 由于 DirectBuffer 申请的是非 JVM 的物理内存，所以创建和销毁的代价很小。DirectBuffer 申请的内存并不是直接由 JVM 负责垃圾回收，但在 DirectBuffer 包类被回收时，会通过 Java Reference 机制来释放该内存块
  - NIO 发布后，通道和多路复用器这两个基本组件实现了 NIO 的非阻塞
    - 通道
      - 外部设备(磁盘)通过DMA控制器（DMAC），向CPU提出接管总线控制权的总线请求
      - CPU对某个设备接口响应DMA请求时，会让出总线控制权。于是在DMA控制器的管理下，磁盘和存储器直接进行数据交换，而不需CPU干预。 
      - 通道则是在DMA的基础上增加了能执行有限通道指令的I/O控制器，代替CPU管理控制外设
    - 多路复用器
      - selector 是 Java NIO 编程的基础。用于检查一个或多个 NIO Channel 的状态是否处于可读、可写。
      - selector 是基于事件驱动实现的，一个线程使用一个 Selector，通过轮询的方式，可以监听多个 Channel 上的事件。
      - 目前操作系统的 I/O 多路复用机制都使用了 epoll，相比传统的 select 机制，epoll 没有最大连接句柄 1024 的限制。所以 Selector 在理论上可以轮询成千上万的客户端。







## 序列化

- 两个服务之间要共享一个数据对象，就需要从对象转换成二进制流，通过网络传输，传送到对方服务，再转换回对象，供服务方法调用。这个编码和解码过程我们称之为序列化与反序列化。
- 在大量并发请求的情况下，如果序列化的速度慢，会导致请求响应时间增加；而序列化后的传输数据体积大，会导致网络吞吐量下降。所以一个优秀的序列化框架可以提高系统的整体性能
- 一个使用单例模式实现的类，如果我们将该类实现 Java 的 Serializable 接口，它还是单例吗？如果要你来写一个实现了 Java 的 Serializable 接口的单例，你会怎么写呢？
  - 序列化会通过反射调用无参构造器返回一个新对象，破坏单例模式。反序列化得到的对象，和序列化之前的对象，不是同一个对象
  - 解决方法是重写readResolve，返回单例对象的方式来避免这个问题
    - Java的序列化机制提供了一个钩子方法，即私有的readresolve方法，允许我们来控制反序列化时得到的对象。
    - 序列化时，先执行了writeReplace方法，后执行了writeObject方法；在反序列化的时候，先执行了readObject方法，最后执行了readResolve方法
-  Protobuf序列化
  - Protobuf 以一个 .proto 后缀的文件为基础，这个文件描述了字段以及字段类型，在序列化该数据对象的时候，Protobuf 通过.proto文件描述来生成 Protocol Buffers 格式的编码。 
  - 它使用 T-L-V（标识 - 长度 - 字段值）的数据格式来存储数据





## 通信协议

- 微服务的核心是远程通信和服务治理

- RPC 通信包括了建立通信、实现报文、传输协议以及传输数据编解码等操作

  - 选择合适的通信协议

    - 网络传输协议有 TCP、UDP 协议，这两个协议都是基于 Socket 编程接口之上
    - TCP：socket()->bind()->listen()->accept()阻塞等待客户端连接—>connect()->read()、write()->close()
      - 当有一个客户端连接到服务端之后，服务端就会调用 fork 创建一个子进程，通过系统调用read 监听客户端发来的消息，再通过 write 向客户端返回信息。
    - UDP：socket()->bind()->recvfrom()、sendto()->close()

  - 使用单一长连接

    - 基于长连接实现，就可以省去大量的 TCP 建立和关闭连接的操作

  - 优化 Socket 通信

    - 传统的Socket 通信主要存在 I/O 阻塞、线程模型缺陷以及内存拷贝等问题。我们可以使用比较成熟的通信框架，比如 Netty
    - 高效的 Reactor 线程模型
      - 服务端接收客户端请求连接是用了一个主线程
      - 监听到事件后会创建一个链路请求。链路请求将会注册到负责 I/O 操作的 I/O 工作线程上，由 I/O 工作线程负责后续的 I/O 操作。
    - 串行设计
      - Netty 采用了串行无锁化完成链路操作，Netty 提供了 Pipeline 实现链路的各个操作在运行期间不进行线程切换。
    - 零拷贝
      - NIO 提供的ByteBuffer 可以使用 Direct Buffers 模式，直接开辟一个非堆物理内存，不需要进行字节缓冲区的二次拷贝，可以直接将数据写入到内核空间。

  - 量身定做报文格式

  - 编码、解码

  - 调整 Linux 的 TCP 参数设置选项

    

    







## NIO

- 网络 I/O 模型优化
  - 阻塞式 I/O
    - connect 阻塞
      - 客户端需要等待服务端发送回来的 ACK 以及 SYN 信号，同样服务端也需要阻塞等待客户端确认连接的 ACK 信号，这就意味着 TCP 的每个 connect都会阻塞等待，直到确认连接。
    - accept 阻塞
    - read、write 阻塞
  - 非阻塞式 I/O
    - 当我们把以上操作设置为了非阻塞状态，我们需要设置一个线程对该操作进行轮询检查，这也是最传统的非阻塞 I/O 模型
  - I/O 复用
    - Linux 提供了 I/O 复用函数 select/poll/epoll，进程将一个或多个读操作通过系统调用函数，阻塞在函数操作上。这样，系统内核就可以帮我们侦测多个读操作是否处于就绪状态。
    -  select() 函数调用后会阻塞，直到有描述符就绪或者超时，函数返回。当 select 函数返回后，可以通过函数 FD_ISSET 遍历 fdset，来找到就绪的描述符
    - select() 函数监视的文件描述符分 3 类，分别是 writefds（写文件描述符）、readfds（读文件描述符）以及 exceptfds（异常事件文件描述符）
    - poll() 和 select() 存在一个相同的缺点，那就是包含大量文件描述符的数组被整体复制到用户态和内核的地址空间之间，而无论这些文件描述符是否就绪，他们的开销都会随着文件描述符数量的增加而线性增大
    - epoll 使用事件驱动的方式代替轮询扫描fd。
    - 一旦某个文件描述符就绪时，内核会采用类似 callback 的回调机制，迅速激活这个文件描述符，当进程调用 epoll_wait() 时便得到通知，之后进程将完成相关 I/O 操作
- 零拷贝
  - 在 I/O 复用模型中，执行读写 I/O 操作依然是阻塞的，在执行读写 I/O 操作时，存在着多次内存拷贝和上下文切换，给系统增加了性能开销。
  - 零拷贝是一种避免多次内存复制的技术，用来优化读写 I/O 操作。
  - 在 NIO 服务端通信编程中，首先会创建一个 Channel，用于监听客户端连接；接着，创多路复用器 Selector，并将 Channel 注册到 Selector，程序会通过 Selector 来轮询在其上的Channel 
  - Linux 内核中的 mmap 函数可以代替 read、write 的 I/O 读写操作，实现用户空间和内核空间共享一个缓存数据(同时映射到相同的一块物理内存地址)，这种方式避免了内核空间与用户空间的数据交换。I/O 复用中的epoll 函数中就是使用了 mmap 减少了内存拷贝。
  - Java 的 NIO 编程中，则是使用到了 Direct Buffer 来实现内存的零拷贝。Java 直接在JVM 内存空间之外开辟了一个物理内存空间，这样内核和用户进程都能共享一份缓存数据。
- 线程模型优化
  - Reactor 模型是同步 I/O 事件处理的一种常见模型，其核心思想是将 I/O 事件注册到多路复用器上，一旦有 I/O 事件触发，多路复用器就会将事件分发到事件处理器中，执行就绪的 I/O 事件操作。
  - 单线程 Reactor 线程模型
    - 最开始 NIO 是基于单线程实现的，所有的 I/O 操作都是在一个 NIO 线程上完成。由于NIO 是非阻塞 I/O，理论上一个线程可以完成所有的 I/O 操作。
  - 多线程 Reactor 线程模型
    -  Acceptor 线程来监听连接请求事件，当连接成功之后，会将建立的连接注册到多路复用器中，一旦监听到事件，将交给 Worker 线程池来负责处理
  - 主从 Reactor 线程模型
    - Acceptor 不再是一个单独的 NIO 线程，而是一个线程池。Acceptor 接收到客户端的 TCP 连接请求，建立连接之后，后续的 I/O 操作将交给 Worker I/O 线程。
- 基于线程模型的 Tomcat 参数调优
  - 在 NIO 中，Tomcat 新增了一个 Poller 线程池，Acceptor 监听到连接后，不是直接使用Worker 中的线程处理请求，而是先将请求发送给了 Poller 缓冲队列。在 Poller 中，维护了一个 Selector 对象，通过遍历 Selector，找出其中就绪的 I/O 操作，并使用 Worker 中的线程处理相应的请求
    - acceptorThreadCount：该参数代表 Acceptor 的线程数量
    - maxThreads：专门处理 I/O 操作的 Worker 线程数量
    - acceptCount ：这里的 acceptCount 指的是 accept 队列的大小。
      - Tomcat 的 Acceptor 线程是负责从 accept 队列中取出该 connection，然后交给工作线程去执行相关操作
      - 当 Http 关闭 keep alive，在并发量比较大时，可以适当地调大这个值。而在 Http 开启keep alive 时，因为 Worker 线程数量有限，Worker 线程就可能因长时间被占用，而连接在 accept 队列中等待超时。如果 accept 队列过大，就容易浪费连接。
    - maxConnections：表示有多少个 socket 连接到 Tomcat 上。























