---
title: 多线程性能调优
categories:
- JAVA
tags:
- Java调优
---




## Synchronized同步锁

- Synchronized 是 JVM 实现的一种内置锁，锁的获取和释放是由 JVM 隐式实现。
- Lock 同步锁是基于 Java 实现的，而 Synchronized 是基于底层操作系统的 Mutex Lock实现的，每次获取和释放锁操作都会带来用户态和内核态的切换，从而增加系统性能开销
-  Synchronized 同步锁对普通方法和静态方法的修饰有什么区别？
  - 加在普通方法锁对象是当前对象，其ObjectMonitor就是对象的，而静态方法上，锁对象就是字节码对象，静态方法是所有对象共享的，锁粒度比较大
- 同步锁实现原理
  - 修饰方法
    - 当 Synchronized 修饰同步方法时，并没有发现 monitorenter 和 monitorexit 指令，而是出现了一个 ACC_SYNCHRONIZED 标志。
    - Monitor 是由 ObjectMonitor 实现，而ObjectMonitor 是由 C++ 的 ObjectMonitor.hpp 文件实现
    - 同步锁在这种实现方式中，因 Monitor 是依赖于底层的操作系统实现，存在用户态与内核态之间的切换，所以增加了性能开销。
  - 修饰代码块
    - Synchronized 在修饰同步代码块时，是由 monitorenter和 monitorexit 指令来实现同步的
    - 进入 monitorenter 指令后，线程将持有 Monitor 对象，退出 monitorenter 指令后，线程将释放该 Monitor 对象
  - Synchronized 同步锁就是从偏向锁开始的，随着竞争越来越激烈，偏向锁升级到轻量级锁，最终升级到重量级锁
- 锁升级优化
  - 新增的 Java 对象头实现了锁升级功能，当 Java 对象被 Synchronized 关键字修饰成为同步锁后，围绕这个锁的一系列升级操作都将和 Java 对象头有关。
  - 在 JDK1.6 JVM 中，对象实例在堆内存中被分为了三个部分：对象头、实例数据和对齐填充。
  - Java 对象头由 Mark Word、指向类的指针以及数组长度三部分组成。
    - 锁升级功能主要依赖于 Mark Word 中的锁标志位和是否偏向锁标志位
    - 无锁01、偏向锁01、轻量级锁00、重量级锁10、gc标记11
- 偏向锁
  - 偏向锁主要用来优化同一线程多次申请同一个锁的竞争,在某些情况下，大部分时间是同一个线程竞争锁资源，例如，在创建一个线程并在线程中执行循环监听的场景下，或单线程操 作一个线程安全集合时，同一线程每次都需要获取和释放锁，每次操作都会发生用户态与内核态的切换
  - 当对象被当做同步锁并有一个线程抢到了锁时，锁标志位还是 01，“是否偏向锁”标志位设置为 1，并且记录抢到锁的线程 ID，表示进入偏向锁状态。
- 轻量级锁
  - 当有另外一个线程竞争获取这个锁时，由于该锁已经是偏向锁，当发现对象头 Mark Word中的线程 ID 不是自己的线程 ID，就会进行 CAS 操作获取锁，如果获取成功，直接替换Mark Word 中的线程 ID 为自己的 ID，该锁会保持偏向锁状态；如果获取锁失败，代表当前锁有一定的竞争，偏向锁将升级为轻量级锁。
  - 轻量级锁适用于线程交替执行同步块的场景，绝大部分的锁在整个同步周期内都不存在长时间的竞争。
- 自旋锁与重量级锁
  - JVM 提供了一种自旋锁，可以通过自旋方式不断尝试获取锁，从而避免线程被挂起阻塞。
  - CAS 重试操作意味着长时间地占用 CPU。
  - 未抢到锁的线程都会进入 Monitor，之后会被阻塞在 _WaitSet 队列中。
  - 在锁竞争不激烈且锁占用时间非常短的场景下，自旋锁可以提高系统性能。
  - 在高负载、高并发的场景下，我们可以通过设置 JVM 参数来关闭自旋锁，优化系统性能

- 流程
  - 访问同步方法
    - 无锁-MarkWord是否存储线程ID，
      - 是就获取偏向锁并执行方法
      - 不是就CAS操作替换线程ID
        - 成功就执行方法
        - 失败就开始撤销偏向锁
          - 原持有偏向锁的线程到达安全点，发生stw
          - 检查持有偏向锁的线程状态
            - 已退出执行方法——返回MarkWord是否存储线程ID
            - 执行方法中——升级为轻量级锁，原持有偏向锁的线程获得轻量级锁
              - CAS操作，若失败，自旋
              - 自选到达一定次数没有成功，升级为重量级锁
                - 挂起当前线程，进入阻塞

- 动态编译实现锁消除 / 锁粗化
  - JIT 编译器在动态编译同步块的时候，借助了一种被称为逃逸分析的技术，来判断同步块使用的锁对象是否只能够被一个线程访问，而没有被发布到其它线程。
  - 如果发现几个相邻的同步块使用的是同一个锁实例，那么 JIT 编译器将会把这几个同步块合并为一个大的同步块，从而避免一个线程“反复申请、释放同一个锁“所带来的性能开销。
- 减小锁粒度
  - 当我们的锁对象是一个数组或队列时，集中竞争一个对象的话会非常激烈，锁也会升级为重量级锁。我们可以考虑将一个数组和队列对象拆成多个小对象，来降低锁竞争，提升并行度。
  - 最经典的减小锁粒度的案例就是 JDK1.8 之前实现的 ConcurrentHashMap 版本
  - 1.8后，可以尽量采用并发包中的无锁或则称乐观锁来实现





## Lock同步锁

- Lock 锁的实现原理
  - 从性能方面上来说，在并发量不高、竞争不激烈的情况下，Synchronized 同步锁由于具有分级锁的优势，性能上与Lock 锁差不多；但在高负载、高并发的情况下，Synchronized 同步锁由于竞争激烈会升级到重量级锁，性能则没有 Lock 锁稳定。
  - Lock 锁是基于 Java 实现的锁，Lock 是一个接口类，常用的实现类有 ReentrantLock、ReentrantReadWriteLock（RRW），它们都是依赖AbstractQueuedSynchronizer（AQS）类实现的。
  - AQS 类结构中包含一个基于链表实现的等待队列（CLH 队列），用于存储所有阻塞的线程，AQS 中还有一个 state变量，该变量对 ReentrantLock 来说表示加锁状态。
- 读写锁 ReentrantReadWriteLock是如何实现锁分离来保证共享资源的原子性的
  - RRW 也是基于 AQS 实现的，它的自定义同步器（继承AQS）需要在同步状态 state 上维护多个读线程和一个写线程的状态，该状态的设计成为实现读写锁的关键
  - 高低位，来实现一个整型控制两种状态的功能，读写锁将变量切分成了两个部分，高 16 位表示读，低 16位表示写。
  - 一个线程尝试获取写锁时
    - 会先判断同步状态 state 是否为0。如果 state 等于 0，说明暂时没有其它线程获取锁；如果 state 不等于 0，则说明有其它线程获取了锁。
      - 再判断同步状态 state 的低 16 位（w）是否为 0，为 0，则说明其它线程获取了读锁，此时进入 CLH 队列进行阻塞等待
      - 如果 w 不为 0，则说明其它线程获取了写锁，此时要判断获取了写锁的是不是当前线程，若不是就进入 CLH 队列进行阻塞等待；若是，就应该判断当前线程获取写锁是否超过了最大次数，若超过，抛异常，反之更新同步状态。
- StampLock不支持重入，不支持条件变量，线程被中断时可能导致CPU暴涨
- StampedLock在写多读少的时候性能会很差
- 进程上下文切换，是指用户态和内核态的来回切换。我们知道，如果一旦Synchronized锁资源竞争激烈，线程将会被阻塞，阻塞的线程将会从用户态调用内核态，尝试获取mutex，这个过程就是进程上下文切换。





## 乐观锁

- 乐观锁相比悲观锁来说，不会带来死锁、饥饿等活性故障问题，线程间的相互影响也远远比悲观锁要小。更为重要的是，乐观锁没有因竞争造成的系统开销，所以在性能上也是更胜一筹。
- 现在的服务器通常是多处理器，并且每个处理器都是多核的。每个处理器维护了一块字节的内存，每个内核维护了一块字节的缓存，这时候多线程并发就会存在缓存不一致的问题，从而导致数据不一致。
- CAS 是调用处理器底层指令来实现原子操作。处理器提供了总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。
  - 当处理器要操作一个共享变量的时候，其在总线上会发出一个 Lock 信号，这时其它处理器就不能操作共享变量了
  - 当某个处理器对缓存中的共享变量进行了操作，就会通知其它处理器放弃存储该共享资源或者重新读取该共享资源。目前最新的处理器都支持缓存锁定机制。
- CAS 乐观锁在平常使用时比较受限，它只能保证单个变量操作的原子性，当涉及到多个变量时，CAS 就无能为力了
- ABA
  - StampdLock获取锁时返回一个时间戳可以解决该问题





## 上下文切换

- 处理器给每个线程分配 CPU 时间片（Time Slice），线程在分配获得的时间片内执行任务。一个线程被暂停剥夺使用权，另外一个线程被选中开始或者继续运行的过程就叫做上下文切换（Context Switch）。

- 在这种切出切入的过程中，操作系统需要保存和恢复相应的进度信息，这个进度信息就是“上下文”了。它包括了寄存器的存储内容以及程序计数器存储的指令内容。

- 一种是程序本身触发的切换，这种我们称为自发性上下文切换，另一种是由系统或者虚拟机诱发的非自发性上下文切换。

  - 自发性上下文切换指线程由 Java 程序调用导致切出
  - 非自发性上下文切换指线程由于调度器的原因被迫切出。常见的有：线程被分配的时间片用完，虚拟机垃圾回收导致或者执行优先级的问题导致
    - 垃圾回收机制的使用有可能会导致 stop-the-world 事件的发生，这其实就是一种线程暂停行为。

- 系统开销具体发生在切换过程中的哪些具体环节

  - 操作系统保存和恢复上下文；

  - 调度器进行线程调度；

  - 处理器高速缓存重新加载

    

- 在多线程中使用 Synchronized 还会发生进程间的上下文切换吗？具体又会发生在哪些环节呢？

  - 如果一旦Synchronized锁资源竞争激烈，线程将会被阻塞，阻塞的线程将会从用户态调用内核态，尝试获取mutex，这个过程就是进程上下文切换。
  -  CAS乐观锁只是一个原子操作，为CPU指令实现，不需要进入内核或者切换线程。而lock竞争锁资源是基于用户态完成，所以竞争锁资源时不会发生进程上下文切换。
  - 使用Synchronized获得锁失败，进入等待队列会发生上下文切换。如果竞争锁时锁是其他线程的偏向锁，需要升级，这时需要stop the world也会发生上下文切换

- 在多线程编程中，锁其实不是性能开销的根源，竞争锁才是。

  - 减少锁的持有时间
  - 降低锁的粒度
  - 非阻塞乐观锁替代竞争锁
  - JVM 内部其实也对Synchronized 同步锁做了优化
  - 如果有多个消费者线程同时被阻塞，notifyAll() 方法，将会唤醒所有阻塞的线程。而某些商品依然没有库存，过早地唤醒这些没有库存的商品的消费线程，可能会导致线程再次进入阻塞状态，从而引起不必要的上下文切换。
    - 为了避免长时间等待，我们常会使用 Object.wait (long）设置等待超时时间
    - 建议使用 Lock 锁结合 Condition 接口替代 Synchronized 内部锁中的 wait notify，实现等待／通知。

- 合理地设置线程池大小，避免创建过多线程

- 减少 Java 虚拟机的垃圾回收

  - 很多 JVM 垃圾回收器（serial 收集器、ParNew 收集器）在回收旧对象时，会产生内存碎片，从而需要进行内存整理，在这个过程中就需要移动存活的对象。
  - 而移动内存对象就意味着这些对象所在的内存地址会发生变化，因此在移动对象前需要暂停线程，在移动完成后需要再次唤醒该线程。因此减少 JVM 垃圾回收的频率可以有效地减少上下文切换。

- 竞争锁、线程间的通信以及过多地创建线程等多线程编程操作，都会给系统带来上下文切换。除此之外，I/O 阻塞以及 JVM 的垃圾回收也会增加上下文切换。

- 本质上java目前都是利用内核线程，所以都会有上下文切换

  - Lock是通过AQS的state以及CAS操作判断是否持有锁，AQS中，阻塞线程再次获取锁时，是通过state以及CAS操作判断，只有没有竞争成功时，才会再次被挂起，这样可以尽量减少上下文切换。
  - AQS挂起是通过LockSupport中的park进入阻塞状态，这个过程也是存在进程上下文切换的。但被阻塞的线程再次获取锁时，不会产生进程上下文切换，而synchronized阻塞的线程每次获取锁资源都要通过系统调用内核来完成，这样就比AQS阻塞的线程更消耗系统资源了。



## 并发容器

- ConcurrentHashMap 

  - 在某些场景中，ConcurrentHashMap 依然不能代替 Hashtable。例如，在强一致的场景中ConcurrentHashMap 就不适用，原因是 ConcurrentHashMap 中的 get、size 等方法没有用到锁，ConcurrentHashMap 是弱一致性的，因此有可能会导致某次读无法马上获取到写入的数据。
    - happens-before规则中，对锁的规则：一个unLock操作先行发生于后面对同一个锁的lock操作；
      - ConcurrentHashMap中的get如果有锁操作，在put操作之后，get操作是一定能拿到put后的数据；而实际上get操作时没有锁的
  - JDK1.8 在添加元素时，在没有哈希冲突的情况下，会使用CAS 进行添加元素操作；如果有冲突，则通过 Synchronized 将链表锁定，再执行接下来的操作。

- ConcurrentSkipListMap

  - 新增节点和链接索引都是基于 CAS 操作实现。

- 如果对数据有强一致要求，则需使用 Hashtable；在大部分场景通常都是弱一致性的情况下，使用 ConcurrentHashMap 即可；如果数据量在千万级别，且存在大量增删改操作，则可以考虑使用ConcurrentSkipListMap

- 抢购场景一般都是写多读少，该队列基于链表实现，所以新增和删除元素性能较高

  - 写数据时通过cas操作，性能较高。
  - 但是ConcurrentLinkedQueue有一个普遍存在的问题，就是该队列是无界的，需要控制容量，否则可能引起内存溢出

- ConcurrentHashMap和HashTable的key和value不能为空，而HashMap却可以

  - ```java
    // 当在并发情况下，有两个线程分别在操作map容器，此时线程1在运行以上代码，当线程1运行到代码1与代码2中间时，刚好有另外一个线程2执行了map.remove(key)操作，此时继续运行代码2时，依然会返回null值。而此时的null实际上是map中真实的不存在该key值，应该throw new KeyNotPresentException()的。所以为了保证线程安全，这两个Map容器是不允许key和value为null。
    
    // 而HashMap是非线程安全的，不存在以上我们所说的并发情况  
    if (map.containsKey(key)) {//代码1
       return map.get(key);//代码2
    } else {
       throw new KeyNotPresentException(); 
    }
    ```

    



## 线程池

- 在 HotSpot VM 的线程模型中，Java 线程被一对一映射为内核线程。Java 线程的创建与销毁将会消耗一定的计算机资源，从而增加系统的性能开销。
- 根据自己的业务场景，从“N+1”和“2N”两个公式中选出一个适合的，计算出一个大概的线程数量，之后通过实际压测，逐渐往“增大线程数量”和“减小线程数量”这两个方向调整
- 在平常的应用场景中，我们常常遇不到这两种极端情况，此时我们可以参考以下公式来计算线程数:
  - 线程数 =N（CPU 核数）*（1+WT（线程等待时间）/ST（线程时间运行时间））
  - 我们可以通过 JDK 自带的工具 VisualVM 来查看 WT/ST 比例
- Amdahl's定律指出优化串行是优化系统性能的关键，我们应该从算法入手，减少程序中串行的部分，而不是增加线程数来提高系统的并发处理能力





## 数据的强、弱一致性

- Java 采用共享内存模型来实现多线程之间的信息交换和数据同步
- 如果两个线程同时运行count++，两个线程的变量的值可能会出现以下三种结果：11 12 21
  - 堆内存和方法区的数据是线程共享的。而堆内存中的共享变量在被不同线程操作时，会被加载到自己的工作内存中，也就是CPU 中的高速缓存。
  - 如果是多核 CPU 运行多线程，每个核都有一个 L1 缓存，如果多个线程运行在不同的内核上访问共享变量时，每个内核的 L1 缓存将会缓存一份共享变量。
- Java 的内存模型
  - 在不影响运算结果的前提下，编译器有可能会改变顺序代码的指令执行顺序，特别是在一些可以优化的场景。
  - 编译器为了尽可能地减少寄存器的读取、存储次数，会充分复用寄存器的存储值。
  -  JVM 要是能对它们进行任意排序的话，也可能会给并发编程带来一系列的问题，其中就包括了一致性的问题。
  - 为了解决这个问题，Java 提出了 Happens-before 规则来规范线程的执行顺序
    - 严格一致性（强一致性）
      - 所有的读写操作都按照全局时钟下的顺序执行，且任何时刻线程读取到的缓存数据都是一样的，Hashtable 就是严格一致性；
    - 顺序一致性
      - 多个线程的整体执行可能是无序的，但对于单个线程而言执行是有序的
      - volatile 可以阻止指令重排序，所以修饰的变量的程序属于顺序一致性
    - 弱一致性
      - 不能保证任何一次读都能读到最近一次写入的数据，但能保证最终可以读到写入的数据
      - 单个写锁 + 无锁读，就是弱一致性的一种实现。